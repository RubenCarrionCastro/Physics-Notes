\documentclass[11pt, oneside]{book}
\usepackage{textcomp}
\usepackage{pdfpages}
% \usepackage{graphicx} % Required for inserting images
\usepackage{feynmp-auto} % Activa metapost
\usepackage{blindtext} % Package to generate dummy text throughout this template 
% \usepackage{float}
\usepackage[table,xcdraw]{xcolor}
% \usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
 % Line spacing - Palatino needs more space between lines
\usepackage{cancel} % 'left' option added here
\usepackage{euler}
\usepackage{multirow}
\usepackage{braket}
\usepackage{graphicx}
\usepackage[spanish]{babel} % Language hyphenation and typographical rules
\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} % Document margins
\usepackage[hang, small,labelfont=bf,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{lettrine} % The lettrine is the first enlarged letter at the beginning of the text
\usepackage{enumerate} % Customized lists
\usepackage{titlesec} % Allows customization of titles
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{} % Change the look of the section titles
\titleformat{\subsection}[block]{\large}{\thesubsection.}{1em}{} % Change the look of the section titles
\usepackage{fancyhdr} % Headers and footers
 % All pages have headers and footers
\fancyhead[R]{$\hspace{2mm}$} % Blank out the default header

 % Blank out the default footer
% Custom header text
\usepackage{amsmath, amsthm, amssymb}
\usepackage{hyperref} % For hyperlinks in the PDF
\usepackage{mathtools}
\usepackage{physics}
\usepackage{array, multirow, multicol}
\usepackage{longtable}
\usepackage{footnote}
\usepackage{tcolorbox}
\usepackage{enumitem}
\usepackage{dsfont}
\usepackage{simplewick}
\usepackage{slashed}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{xpatch}
\xpatchcmd{\proof}{\itshape}{\normalfont\proofnamefont}{}{}

\newenvironment{Figura}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}

%%%%%%%%%%%%%%%%
\newtheorem{propiedad}{Propiedades}[section]
\newtheorem{axiom}{Axioma}[section]
\newtheorem{thm}{Teorema}[section]
\newtheorem{theorem}{Teorema}[section]
\newtheorem{proposition}[thm]{Proposición} 
\newtheorem{lemma}[thm]{Lema}
\newtheorem{corollary}[thm]{Corolario} 
\newtheorem{conv}[thm]{Convención}
\newtheorem{defi}[thm]{Definición}
\newtheorem{definition}[theorem]{Definición}
\newtheorem{notation}[thm]{Notación} 
\newtheorem{exe}[thm]{Ejemplo}
\newtheorem{conjecture}[thm]{Conjetura} 
\newtheorem{prob}[thm]{Problema}
\newtheorem{remark}[thm]{Observación}
\newtheorem{example}[thm]{Ejemplo}
\newtheorem{note}[thm]{Nota}
\newtheorem{Trucaso}[thm]{Trucaso}

\newcommand{\brackets}[1]{\left[#1\right]}
\newcommand{\curlybraces}[1]{\left\{#1\right\}}
\newcommand{\qedh}{\hfill\hspace{5mm}\qedsymbol}
\newcommand{\scalar}[2]{\langle #1, #2 \rangle}
\newcommand{\ptensor}[2]{#1 \otimes #2}
\newcommand{\pcart}[2]{#1 \times #2}
\newcommand{\funct}[3]{#1:\hspace{1mm} #2\to #3}


\newtcolorbox[auto counter, number within=section]{mytheorem}[2][]{
  enhanced,
  breakable,
  title=Teorema~\thetcbcounter: #2,
  #1,
}
\newtcolorbox[auto counter, number within=section]{propositionbox}[2][]{
  enhanced,
  breakable,
  title=Proposition~\thetcbcounter: #2,
  #1,
}

\newtcolorbox[auto counter, number within=section]{corollarybox}[2][]{
  enhanced,
  breakable,
  title=Corollary~\thetcbcounter: #2,
  #1,
}

\newtcolorbox[auto counter, number within=section]{remarkbox}[2][]{
  enhanced,
  breakable,
  title=Remark~\thetcbcounter: #2,
  #1,
}

\newtcolorbox[auto counter, number within=section]{notebox}[2][]{
  enhanced,
  breakable,
  title=Note~\thetcbcounter: #2,
  #1,
}
\newcommand{\proofnamefont}{\bfseries}
%\setlength {\marginparwidth}{1cm}
\begin{document}

\pagestyle{empty}
\begin{minipage}[c][\textheight][t]{\textwidth}
\makebox[\textwidth]{%
  \begin{minipage}[t]{1.5cm}
     \vspace{10pt}
      \begin{picture}(50,90)
        %\put(-113,55){\includegraphics[scale=0.15]{Pictures/UGR-Logo.png}
        %\put(-40,-550){\rule[2pt]{1pt}{21cm}}
        %\put(-37,-550){\rule[2pt]{2mm}{21cm}}
        %\put(-29,-550){\rule[2pt]{1pt}{21cm}}
        %\put(-18,-550){\rule[2pt]{1pt}{21cm}}
        %\put(-15,-550){\rule[2pt]{2mm}{21cm}}
        %\put(-7,-550){\rule[2pt]{1pt}{21cm}}
        %\put(-63,53){\includegraphics[scale=0.25]{Pictures/Logo-FS.png}}
        
        \put(-113,55)
        {\includegraphics[scale=0.15]{imagenes/UGR-Logo.png}}
        \put(-40,-550){\rule[2pt]{1pt}{21cm}}
        \put(-37,-550){\rule[2pt]{2mm}{21cm}}
        \put(-29,-550){\rule[2pt]{1pt}{21cm}}
        \put(-18,-550){\rule[2pt]{1pt}{21cm}}
        \put(-15,-550){\rule[2pt]{2mm}{21cm}}
        \put(-7,-550){\rule[2pt]{1pt}{21cm}}
      \end{picture}
  \end{minipage}
  \begin{minipage}[t]{15cm}
  	\vspace{40pt}
   	\begin{picture}(400,65)
   		\put(-10,160){\rule[2pt]{16cm}{1pt}}
   		\put(-10,152){\rule[2pt]{16cm}{2mm}}
   		\put(-10,149){\rule[2pt]{16cm}{1pt}}
   		\put(40,80){
        
   		%\put(70,100){
        \begin{tabular}[t]{c}
          {\huge\textbf{UNIVERSIDAD DE GRANADA}}\\
          %{\huge\textbf{UNIVERSIDAD DE CÓRDOBA}}\\
          %{\huge\textbf{FISICA SOCIETY}}\\
             \\
           {\LARGE\textbf{\sc Facultad de Ciencias}}\\
              \\
           {\Large\textbf{Grado de F\'isica}}
        \end{tabular}}
    \end{picture}

  \begin{center}
  	{
    	\Large\bfseries 
     	Apuntes de
    	\par
    }%
    \vskip 3.5em%
    {
    	\begin{tabular}[t]{c}%
    		{\huge \textbf{TEORÍA CUÁNTICA DE CAMPOS}}\\ {\huge\textbf{Y DE PARTÍCULAS}}
     	\end{tabular} \par
    }
    \vskip 3em%
\fbox{\parbox{3cm}{\Large$(i\slashed{\partial}-m)\Psi=0$\strut}}
      \vskip 1.5em %
      {
      	\begin{tabular}[t]{c}%
      		{\Large Autor:}
      	\end{tabular} 
        \par
      }
      \vskip 1.5em
      {
      	\begin{tabular}[t]{c}%
      		{\Large Rubén Carrión Castro}
      	\end{tabular}
      	\par
      }%
      \vskip 1.5em%
	  \vskip 20pt
	  {
		  \Large
			\begin{tabular}{ll}
				Profesor de la asignatura: & Dr. Manuel María Pérez-Victoria
			\end{tabular}
		}
   \end{center}
   \vfill
   \begin{center}
     \begin{tabular}{c}
      {
          \large Cursado en la Universidad de Granada
      }
          \quad \hfill \quad {\large \today}
     \end{tabular}
   \end{center} \par%
   \[\begin{fmffile}{primerosss}
       \begin{fmfgraph*}(190,150)
           \fmfleft{l2,l1}
           \fmfright{r2,r1}
           \fmf{fermion,label=$e^-$}{l1,v1}
           \fmf{fermion,label=$e^+$}{v1,l2}
           \fmf{boson,label=$\gamma$}{v1,v2}
           \fmf{fermion,label=$e^-$}{v2,r1}
           \fmf{fermion,label=$e^+$}{r2,v2}
       \end{fmfgraph*}
   \end{fmffile}\]
\end{minipage}
}
\end{minipage}

%----------------------------------------------------------------------------------------
%	QUOTATION PAGE
%----------------------------------------------------------------------------------------
\pagestyle{empty}
\null\vfill 
\vfill\vfill\vfill\vfill\vfill\vfill\null 
\newpage
\tableofcontents
\listoffigures

\setcounter{page}{1}
\pagestyle{fancy}

\chapter{Introducción. Teoría Clásica de Campos}

Hemos estudiado tanto mecánica cuántica, con sus Hamiltonianos no relativistas, como Relatividad Especial y General empleando el Hamiltoniano con la energía cinética relativista y ultrarrelativista. Nos podemos preguntar cómo unir ambas teorías y de forma intuitiva nos sale usar el Hamiltoniano relativista con el formalismo cuántico. \\ \\
Esto mismo pensó Dirac, que para hacer una primera aproximación de la mecánica cuántica relativista habría que cambiar el Hamiltoniano del sistema por el relativista, es decir,
\[\frac{P^2}{2m}\longrightarrow\sqrt{\vec{p}^2+m^2}\]
Pero esta construcción genera varios problemas:
\begin{itemize}
    \item Implica creación y destrucción de partículas de forma esporádica.
    \item No explica la situación de las partículas idénticas y el por qué los espines enteros corresponden a \textbf{bosones} y los espines semienteros corresponden a \textbf{fermiones}. Esto se denomina \textbf{paradoja de espín-estadística}.
    \item Genera problemas en la causalidad y simetrías de Lorentz.
\end{itemize}
Nos centramos en este último apartado.
\newpage
\section{Problemas con causalidad y simetría Lorentz}
Podemos representar un cono de luz, mostrado en la Figura \ref{Fig1-1}.
\begin{Figura}
    \centering
    \includegraphics[width=0.7\textwidth]{imagenes/ConoDeLuz.png}
    \label{Fig1-1}
    \captionof{figure}{Cono de luz.}
\end{Figura}
Todos los sucesos $(y)$ tienen un cono de luz propio, luego los sucesos se 'representan' en el centro de cono de luz. Todo el eje $ct$ positivo es el futuro del suceso y el negativo, el pasado. El cono de luz limita trayectorias posibles espacio-temporales. Dentro del propio cono, tenemos geodésicas permitidas de tipo tiempo $(ds^2>0)$; son las trayectorias de las partículas con masa. En el límite del cono de luz, tenemos geodésicas tipo nulas $(ds^2=0)$; son las trayectorias de las partículas sin masa. Fuera del cono de luz tenemos geodésicas tipo espacio $(ds^2<0)$, que requeriría de velocidades superiores a la de la luz para poder recorrerlas. La caracterización de un punto en el diagrama espacio-temporal viene dada por
\[x^{\mu}=(x^0,x^1,x^2,x^3)\equiv(ct,x,y,z)=(ct,\vec{x})\equiv(t,\vec{x})\equiv x\]
donde usamos unidades atómicas $(c=1, \hbar=1, \dots)$ y podemos quitar el superíndice.\\ \\
Tomamos una partícula que se propaga desde $y$ a $x$, tal que
\begin{Figura}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/propagacion1.png}
    \captionof{figure}{Representación de la propagación de una partícula. $J_E$ y $J_D$ representan emisores y receptores de partículas, respectivamente.}
    \label{fig1-2}
\end{Figura}
Luego, la amplitud de probabilidad será,
\begin{equation}
    A=J_EJ_D\bra{\vec{y}}e^{-iH(y_0-x_0)}\ket{\vec{x}}
\end{equation}
donde $e^{-iH(x_0-y_0)}$ es el operador propagador, donde el Hamiltoniano será el relativista.
\[(...)\]
Una vez hecho los cálculos, tenemos varias situaciones:
\begin{enumerate}
    \item Si $y,x$ están separados por un intervalo tipo tiempo no hay problemas relevantes.
    \item Si $y,x$ están separados por un intervalo tipo espacio, entonces la probabilidad no está bien definida, ya que, debido a la relatividad, existen observadores para los cuales el evento en $x$ ocurre antes que el evento en $y$, y viceversa. Esto sugiere que la interpretación causal estándar de la propagación de partículas se vuelve problemática, ya que algunos observadores podrían interpretar la propagación como un viaje hacia el pasado. Se intentó solucionar añadiendo una función escalón $\Theta(x^0-y^0)$ a la amplitud, pero ocasiona que tengamos distintos observadores que miden distintas probabilidades, porque para algunos la función escalón anula la amplitud de probabilidad y para otros no, cosa que carece de sentido físico.
\end{enumerate}
Para solucionar esto, se postuló que tanto el punto inicial $('y')$, como el punto final $('x')$ son emisores y receptores de partículas, es decir, $J_E+J_D\equiv J$. Teniendo así
\begin{Figura}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/propagacion2.png}
    \captionof{figure}{Representación de la propagación de una partícula que puede darse en ambos sentidos.}
    \label{fig1-3}
\end{Figura}
donde la amplitud de probabilidad queda,
\begin{equation}
    A=J\cdot J\left[\bra{\vec{y}}e^{-iH(x_0-y_0)}\ket{\vec{x}}\Theta(x^0-y^0)+\bra{\vec{x}}e^{-iH(y_0-x_0)}\ket{\vec{y}}\Theta(y^0-x^0)\right]
\end{equation}
donde $J=J_E+J_D$. Con esta interpretación, distintos observadores obtienen la misma probabilidad, pero no sabemos realmente dónde está la partícula, pues no sabemos si recorre $y\to x$ ó $x\to y$. Esto funciona de manera 'coherente' para partículas sin carga.\\ \\
Si consideramos partículas cargadas, distintos observadores verían cargas diferentes aunque midan la misma probabilidad, cosa problemática porque no habría conservación de carga. Para solucionar esto, postulamos que existen partículas con misma masa, pero con carga opuesta; y además, las $J$ pueden absorber y emitir partículas y/o antipartículas.
\begin{Figura}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/propagacion3.png}
    \captionof{figure}{Representación de la propagación de una partícula y una antipartícula que puede darse en ambos sentidos.}
    \label{fig1-4}
\end{Figura}
Podemos considerar que las partículas se desvían por un potencial, tal que para un observador lo electrones viajen hacia el futuro (Figura \ref{fig1-5}).
\begin{Figura}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/propagacion4.png}
    \captionof{figure}{Partícula desviada por un potencial situado en el punto $z$.}
    \label{fig1-5}
\end{Figura}
Si las distancias son tipo espacio, podemos tener distintos observadores que vean cosas diferentes, por ejemplo, un observador puede ver que debido al potencial se creen pares de partícula-antipartícula desde el vacío (Figura \ref{fig1-6}).
\begin{Figura}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/propagacion5.png}
    \captionof{figure}{Generación de pares electrones-positrones.}
    \label{fig1-6}
\end{Figura}
O también, podemos tener algunos observadores que vean cómo se aniquilan pares de partículas-antipartículas (Figura \ref{fig1-7}).
\begin{Figura}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/propagacion6.png}
    \captionof{figure}{Aniquilación de pares electrón-positrón.}
    \label{fig1-7}
\end{Figura}
Entonces, vemos que distintos observadores (con intervalos tipo espacio) observan diferentes sucesos, aunque luego todas las mediciones que hacen les sale lo mismo.
\begin{note}
    En QFT, el espacio de Hilbert donde trabaja está formado por estados con número variable de partículas y todos los observables se pueden escribir en función de campos (formados por combinaciones lineales de operadores destrucción y creación), siendo operadores que dependen de la posición (y tiempo) en el espacio de operadores (que crean y destruyen partículas). Estos operadores de campo obedecen relaciones de conmutación o anticonmutación, dependiendo de si describen bosones o fermiones, respectivamente.\\ \\
    En nuestro caso, QFT respetará la invariancia Lorentz, asegurando que los observables físicos transformen correctamente bajo el grupo de Lorentz y que la estructura causal del espacio-tiempo se mantenga.
\end{note}
\section{Teoría Clásica de Campos}
\subsection{Convenios}
Tomaremos los siguientes convenios de índices:
\begin{itemize}
\item Tomaremos los cuadrivectores dentro de los campos sin índices, es decir, $\phi(t,\vec{x})=\phi(x^{\mu})\equiv\phi(x)$.
    \item Utilizaremos unidades naturales, $\hbar=c=1$, entonces las siguientes magnitudes tienen las mismas dimensiones, $[\text{longitud}]=[\text{tiempo}]=[\text{energía}]^{-1}=[\text{masa}]^{-1}$. Una relación útil es,
    \begin{equation}
        \hbar c=197.3269631(49)\text{ MeV fm}\Rightarrow 25\text{ GeV}^{-2}\approx10^{-30}\text{ m}^2=10\text{ mbarn}
    \end{equation}
    donde $1$ fm$=10^{-15}$ m (un Fermi, del orden del radio del protón) y $1\text{ barn}=10^{-24}\text{ cm}^2$.
    \item Siempre que tengamos índices en campos tendremos:
    \begin{itemize}
        \item Si tenemos índices griegos, tomaremos valores discretos del índice, es decir, $\mu=\curlybraces{0,1,2,3,\dots}$.
        \item Si tenemos índices latinos, los índices serán continuos, es decir, 
        $a\in\mathbb{R}$
    \end{itemize}
    \item Si tenemos índices en otras funciones que no sean campos, tomaremos el convenio que usamos en Relatividad General, que es:
    \begin{itemize}
        \item Los índices griegos representan las cuatro coordenadas del cuadrivector, es decir, $\mu=\curlybraces{0,1,2,3}$.
        \item Los índices latinos se referirán únicamente a las coordenadas espaciales y se usarán las letras $i,j,k=\curlybraces{1,2,3}$ para no confundirnos con los de los campos.
    \end{itemize}
   \item Vamos a trabajar con la métrica plana (de Minkowky) y la signatura que usaremos es la de (+ - - -), así el tensor métrico queda,
    \begin{equation}
        \eta_{\mu\nu}=\begin{pmatrix}
            1 & 0 & 0 & 0\\
            0 & -1 & 0 & 0\\
            0 & 0 & -1 & 0\\
            0 & 0 & 0 & -1
        \end{pmatrix}=\eta^{\mu\nu}
    \end{equation}
    Recordemos que $\eta^{\mu\nu}\eta_{\lambda\delta}=\delta_{\lambda}^{\mu}\delta_{\delta}^{\nu}$ (deltas de Kronecker).
    \item Usaremos la notación de Einstein de suma sobre índices repetidos, tal que
    \begin{equation}
        A_{\mu}B^{\mu}=\eta_{\mu\nu}A^{\mu}B^{\nu}=\sum_{\mu=0}^4\eta_{\mu\nu}A^{\mu}B^{\mu}=A^0B^0-A^1B^1-A^2B^2-A^3B^3
    \end{equation}
    donde se han usado los índices \textit{contravariantes} $A^{\mu}=(A^0,\vec{A})=(A^0,A^1,A^2,A^3)$ e índices \textit{covariantes} $A_{\mu}=(A_0,-\vec{A})=(A_0,-A_1,-A_2,-A_3)$.
\end{itemize}
\subsection{¿Qué es un campo?}
Un campo es una función de las coordenadas con propiedades de transformación bien definidas bajo el grupo de Lorentz. En general, si las coordenadas se transforman como
\begin{equation}
    x^{\mu}\to x^{'\mu}=\Lambda^{\mu}_{\nu}x^{\nu}\hspace{4mm}(\text{infinitesimalmente: }x^{'\mu}=x^{\mu}+\delta x^{\mu})
\end{equation}
un campo $\phi(x)$ (que puede tener o no índices Lorentz u otros) se transforma como
\begin{equation}
    \phi(x)=\phi'(x')
\end{equation}
Sabemos que en Mecánica Cuántica el tiempo y la posición van por separado, pues el tiempo es un parámetro y la posición un operador; mientras que en Relatividad General, el espacio-tiempo es un todo y se interpreta como si fueran lo mismo. Entonces, el paso lógico sería unificar el tiempo y la posición en el formalismo de Mecánica Cuántica; la opción más sencilla es interpretar la posición como un parámetro, pues interpretar el tiempo como un operador es mucho más difícil, y además, escoger un buen operador de posición tampoco es trivial. Entonces, para nosotros, tanto tiempo como posición serán parámetros. Nuestros campos serán de la forma siguiente,
\begin{equation}
    \phi_a(t,\vec{x})=\phi_a(x^{\mu})\equiv\phi_a(x)
\end{equation}
donde el índice $a$ es continuo. Esto quiere decir que estamos trabajando con un sistema con un infinito número de grados de libertad; al menos uno por cada punto $\vec{x}$ en el espacio.
\begin{example}[El campo electromagnético]
    Los ejemplos de campos clásicos que nos son más familiares, son el campo eléctrico, $\vec{E}(t,\vec{x})$ y el campo magnético, $\vec{B}(t,\vec{x})$. Ambos campos son vectores 3-dimensionales espaciales. Usando el formalismo covariante, podemos obtener ambos campos de un único cuadrivector, $A^{\mu}(t,\vec{x})=(\phi,\vec{A})$, donde $\mu=0,1,2,3$ indica que este campo es un vector en el espacio-tiempo. De forma que los campos eléctricos y magnéticos vienen dados por
    \begin{equation}
        \vec{E}=-\nabla\phi-\frac{\partial\vec{A}}{\partial t};\hspace{5mm}\vec{B}=\nabla\times\vec{A}
    \end{equation}
    lo que garantiza que dos de las ecuaciones de Maxwell, $\nabla\cdot\vec{B}=0$ y $\frac{d\vec{B}}{dt}=-\nabla\times\vec{E}$, se cumplan inmediatamente como identidades.\label{ej1.2.1}
\end{example}
\section{Formalismo Lagrangiano}
Introducimos una acción dependiente de todos los campos, tal que
\begin{equation}
    S[\phi]=\int_{t_1}^{t_2}dtL(t)
\end{equation}
donde $L(t)$ será el Lagrangiano del sistema. La dinámica de los campos viene dada por el Lagrangiano, que es una función de $\phi(x)$, $\dot{\phi}(x)$ y $\nabla\phi(x)$. De forma que, el Lagrangiano lo definiremos a partir de la \textbf{densidad Lagrangiana}, $\mathscr{L}$ (que nombraremos como Lagrangiano también), tal que
\begin{equation}
    L(t)=\int d^3x\mathscr{L}(\phi(x),\dot{\phi}(x),\nabla\phi(x))
\end{equation}
La acción queda,
\begin{equation}
    S[\phi]=\int_{t_1}^{t_2}dt\int d^3x\mathscr{L}(\phi(x),\dot{\phi}(x),\nabla\phi(x))=\int d^4x\mathscr{L}(\phi(x),\dot{\phi}(x),\nabla\phi(x))
\end{equation}
Remarcar que en teoría clásica, el Lagrangiano siempre depende de las coordenadas generalizadas, $q$, y sus derivadas temporales, $\dot{q}$, nunca de derivadas superiores. En Teoría de Campos, nuestras 'coordenadas generalizadas' son los campos $\phi(x)$ y sus 'derivadas temporales', serán los $\dot{\phi}(x)$. Aparentemente, no hay nada que nos impida una dependencia en derivadas espaciales de orden superior, $\nabla^2\phi(x),\dots$. Sin embargo, echando un ojo al invariancia de Lorentz, solo consideraremos Lagrangianos dependientes de $\nabla\phi(x)$ y no de derivadas superiores. Luego, el Lagrangiano será de la forma,
\begin{equation}
    \mathscr{L}(\phi,\dot{\phi},\nabla\phi)=\mathscr{L}(\phi,\partial_{\mu}\phi)
\end{equation}
donde hemos agrupado las derivadas espaciales y temporales.
\\ \\
Podemos obtener las ecuaciones de Euler-Lagrange para campos, fijando dos campos, $\phi_a(t_1,\vec{x}),\phi_a'(t_2,\vec{x})$, y viendo cómo es su variación, $\delta\phi_a=\phi_a'-\phi_a$. Luego, variamos la acción, 
\begin{equation}
    \begin{array}{rcl}
        \delta S[\phi] & = & \delta\left(\int d^4x\mathscr{L}\right)=\int d^4x\delta\mathscr{L}(\phi_a,\partial_{\mu}\phi_a)
    \end{array}
\end{equation}
aplicando la regla de la cadena,
\begin{equation}\small
    % \begin{array}{rcl}
        \delta S[\phi]  =  \int d^4x\brackets{\frac{\partial\mathscr{L}}{\partial\phi_a}\delta\phi_a+\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_a)}\delta(\partial_{\mu}\phi_a)}
        =\int d^4x\curlybraces{\brackets{\frac{\partial\mathscr{L}}{\partial\phi_a}-\partial_{\mu}\left(\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_a)}\right)}\delta\phi_a+\partial_{\mu}\left(\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_a)}\delta\phi_a\right)}
    % \end{array}
    \label{eq1.15}
\end{equation}
Podemos tomar las condiciones de contorno de forma que el último sumando se anule, de forma que al ser una derivada total se anule para algún $\delta\phi_a(t,\vec{x})$ que decaiga en el infinito espacial y cumpla que $\delta\phi_a(t_1,\vec{x})=\delta\phi_a(t_2,\vec{x})=0$.\\ \\
Para obtener las ecuaciones de Euler-Lagrange, deberemos imponer que la acción se conserve, es decir, que para ciertos campos $\bar{\phi}$, la variación de la acción se anule, tal que
\begin{equation}
    \delta S[\bar{\phi}]=\int d^4x\curlybraces{\brackets{\frac{\partial\mathscr{L}}{\partial\bar{\phi}_a}-\partial_{\mu}\left(\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\bar{\phi}_a)}\right)}\delta\bar{\phi}_a}=0
\end{equation}
por tanto, las ecuaciones de Euler-Lagrange para campos; o ecuación del movimiento de los campos, será
\begin{tcolorbox}[title=Ecuaciones de Euler-Lagrange]
\begin{equation}
    \frac{\partial\mathscr{L}}{\partial\bar{\phi}_a}-\partial_{\mu}\left(\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\bar{\phi}_a)}\right)=0
    \label{eq1.17}
\end{equation}
\end{tcolorbox}
\begin{note}
    Veamos en detalle la obtención de la ecuación \ref{eq1.15}.
    \begin{equation*}
    \begin{array}{rcl}
        \delta S[\phi] & = & \int d^4x\brackets{\frac{\partial\mathscr{L}}{\partial\phi_a}\delta\phi_a+\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_a)}\delta(\partial_{\mu}\phi_a)}
    \end{array}
\end{equation*}
Aplicamos la identidad,
\begin{equation*}
    \delta(\partial_{\mu}\phi_a)=\partial_{\mu}(\delta\phi_a)
\end{equation*}
permitiendo reescribir,
\begin{equation*}
    \frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_a)}\delta(\partial_{\mu}\phi_a)=\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_a)}\partial_{\mu}(\delta\phi_a)
\end{equation*}
Aplicamos integración por partes al segundo término, tal que
\begin{equation*}
    \curlybraces{\begin{matrix}
        u=\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_a)} & du=\partial_{\mu}\left(\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_a)}\right)\\ \\
        dv=\partial_{\mu}(\delta\phi_a) & v=\delta\phi_a
    \end{matrix}}
\end{equation*}
Por tanto, queda
\begin{equation*}
    \int d^4x\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_a)}\partial_{\mu}(\delta\phi_a)=\int d^4x\brackets{\partial_{\mu}\left(\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_a)}\delta\phi_a\right)-\partial_{\mu}\left(\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_a)}\right)\delta\phi_a}
\end{equation*}
Sustituyendo y reordenando obtenemos la expresión \ref{eq1.15}
\end{note}
\begin{example}[La ecuación de Klein-Gordon]
    Consideramos un Lagrangiano de un campo real escalar, $\phi(t,\vec{x})$, de la forma
    \begin{equation*}
        \mathscr{L}=\frac{1}{2}\dot{\phi}^2-\frac{1}{2}(\nabla\phi)^2-\frac{1}{2}m^2\phi^2=\frac{1}{2}\eta^{\mu\nu}\partial_{\mu}\phi\partial_{\nu}\phi-\frac{1}{2}m^2\phi^2=\frac{1}{2}\partial_{\mu}\phi\partial^{\mu}\phi-\frac{1}{2}m^2\phi^2
    \end{equation*}
    donde $\eta^{\mu\nu}=diag[+1,-1,-1,-1]$. Aplicando las ecuaciones de Euler-Lagrange obtenemos,
    \begin{equation*}
            \frac{\partial\mathscr{L}}{\partial\bar{\phi}}=-m^2\bar{\phi};\hspace{3mm}
            \frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi)}=\frac{1}{2}\partial^{\mu}\phi+\frac{1}{2}\partial^{\mu}\phi=\partial^{\mu}\phi;\hspace{3mm}
            \partial_{\mu}\left(\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\bar{\phi}_a)}\right)=\partial_{\mu}\partial^{\mu}\bar{\phi}=\Box\bar{\phi}
    \end{equation*}
    donde $\Box\bar{\phi}$ es el D'Alembertiano del campo. Sustituyendo en \ref{eq1.17}, obtenemos
    \begin{equation}
        (\Box+m^2)\bar{\phi}=0
    \end{equation}
    que es la \textbf{ecuación de Klein-Gordon}.
    \label{ej1.2.3}
\end{example}
\begin{example}[Electromagnetismo]
    El tensor electromagnético se define como
    \begin{equation*}
        F_{\mu\nu}=\partial_{\mu}A_{\nu}-\partial_{\nu}A_{\mu}
    \end{equation*}
    con $E_i=F_{0i}$ y $B_i=-\epsilon_{ijk}F_{jk}$. Además, sabemos que la parte electromagnética de cualquier sistema cumple el Lagrangiano
    \begin{equation*}
        \mathscr{L}=-\frac{1}{4}F_{\mu\nu}F^{\mu\nu}
    \end{equation*}
    El campo dinámico del sistema será el potencial electromagnético $A_{\mu}$, por lo que debemos reescribir el Lagrangiano, tal que
    \begin{equation*}
        \mathscr{L}=-\frac{1}{4}(\partial_{\mu}A_{\nu}-\partial_{\nu}A_{\mu})(\partial^{\mu}A^{\nu}-\partial^{\nu}A^{\mu})
    \end{equation*}
    Entonces tenemos,
    \begin{equation*}
        \frac{\partial\mathscr{L}}{\partial A_{\nu}}=0;\hspace{3mm}\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}A_{\nu})}=-\frac{1}{4}\eta^{\mu\nu}2(\partial_{\mu}A_{\nu}-\partial_{\nu}A_{\mu})=-F^{\mu\nu};\hspace{3mm}\partial_{\mu}\left(\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}A_{\nu})}\right)=-\partial_{\mu}F^{\mu\nu}
    \end{equation*}
    Por tanto, sustituyendo en la ecuación de Euler-Lagrange, tenemos
    \begin{equation}
        \partial_{\mu}F^{\mu\nu}=0
        \label{eq1.19}
    \end{equation}
    siendo la ecuación de conservación de la energía del electromagnetismo para vacío (ecuación del movimiento).\\ \\
    Podemos obtener las ecuaciones de Maxwell a parir de esta ecuación. Para ello, vemos que el tensor electromagnético es de la forma,
    \begin{equation*}
        F^{\mu\nu}=\begin{pmatrix}
            0 & -E_x & -E_y & -E_z\\
            E_x & 0 & -B_z & B_y\\
            E_y & B_z & 0 & -B_x\\
            E_z & -B_y & B_x & 0
        \end{pmatrix}
    \end{equation*}
    Por tanto, aplicando la ecuación \ref{eq1.19} para $\nu=0$ tenemos,
    \begin{equation}
        \nabla\cdot\vec{E}=0
    \end{equation}
    y para $\nu=i$, tenemos
    \begin{equation}
        \nabla\times\vec{B}-\frac{\partial\vec{E}}{\partial t}=0
    \end{equation}
    Como ya dijimos en el ejemplo \ref{ej1.2.1}, las otras dos ecuaciones de Maxwell vienen dadas por $A^{\mu}(t,\vec{x})$.\\ \\
    Todo esto es para vacío, pero si queremos incluir cargas y corrientes, deberemos introducir un término extra al Lagrangiano. Este término podemos obtenerlo suponiendo que la ecuación \ref{eq1.19} no es homogénea, sino que tiene la forma
    \begin{equation}
        \partial_{\mu}F^{\mu\nu}=j^{\nu}
    \end{equation}
    donde $j^{\nu}$ lo denotamos como \textbf{cuadrivector de corrientes de carga}. Por tanto, para obtener el Lagrangiano general, deberemos obtener $j^{\nu}$; la forma más sencilla de obtener este término a partir de Euler-Lagrange será suponer que 
    \begin{equation*}
        \frac{\partial\mathscr{L}}{\partial A_{\mu}}=-j^{\mu}
    \end{equation*}
    Entonces, el Lagrangiano quedará
    \begin{equation}
        \mathscr{L}=-\frac{1}{4}F_{\mu\nu}F^{\mu\nu}-A_{\mu}j^{\mu}
    \end{equation}
\end{example}
\section{Simetrías}
Tomamos un funcional invertible que nos lleve de $\phi_a\to\phi_a'$, es decir, $f_a[\phi]=\phi_a'$. Esta transformación es una simetría si y solo si $S[\phi']=S[\phi]$ para cualquier campo $\phi$, no solo para los que cumplan Euler-Lagrange. Esto se denomina \textbf{transformación de simetría}.\\ \\
Podemos tener la operación de composición de simetrías, con un elemento neutro (siendo la identidad, $\phi\to\phi$) y al tener funcionales invertibles, tendremos elementos inversos. Es decir, \textit{las transformaciones de simetría tienen estructura de grupo}.\\ \\
Nos centraremos en ciertos subgrupos de simetrías. Estos subgrupos dan lugar a varios tipos de simetría:
\begin{itemize}
    \item Las \textbf{simetrías discretas} son aquellas formadas por grupos finitos o infinitos numerables.
    \item Las \textbf{simetrías continuas} son aquellas formadas por grupos infinitos no numerables. Dentro de estos grupos, trabajaremos con los grupos de Lie.
\end{itemize}
\begin{note}
Un grupo de Lie es un conjunto con un número infinito de elementos que tiene estructura de variedad diferencial y de grupo.
\end{note}
Si las simetrías son discretas, no podemos definir infinitésimos, pues tenemos un límite. En cambio, en las simetrías continuas sí podemos definirlos, luego podremos definir transformaciones infinitesimales, tal que
\begin{equation}
    \delta\phi_a=\epsilon F_a[\phi]
\end{equation}
Dentro de las simetrías continuas, podemos identificar:
\begin{itemize}
    \item \textbf{Simetrías globales}: todo el grupo lo podemos parametrizar con $N-$números reales, es decir, $\alpha\in\mathbb{R}^N$.
    \item \textbf{Simetrías locales}: los parámetros $\alpha$ son funciones del espacio-tiempo, es decir, $\alpha\in\mathscr{C}^{\infty}(\mathbb{R}^4\to\mathbb{R}^N)$.
\end{itemize}
\begin{note}
    Los elementos del grupo de Lie pueden etiquetarse mediante parámetros, $\alpha$. Por ejemplo, si el generador del grupo es $e^{i\alpha^aT_a}$, el parámetro $\alpha^a$ nos identifican los elementos del grupo.
\end{note}
\subsection{Teorema de Noether}
Vamos a deducir de forma intuitiva este Teorema. Tomamos una simetría global infinitesimal con un parámetro $\epsilon$ pequeño, tal que $\delta\phi_a=\epsilon F_a(x)$, donde $\epsilon$ no depende de las coordenadas espaciotemporales, siendo equivalente a decir que $\delta S=0$ para toda variación de los campos. Es decir, $\delta S=0$ si y solo si $\epsilon=cte$. \\ \\
Ahora consideramos el caso $\epsilon=\epsilon(x)$, por lo que $\delta S\neq0$, y tendrá la forma
\begin{equation}
    \delta S[\phi]=\int d^4xj^{\mu}(x)\partial_{\mu}\epsilon(x),\hspace{2mm}\forall\phi
\end{equation}
donde las $j^{\mu}(x)$ se denominan \textbf{corrientes de Noether} y $\partial_{\mu}\epsilon(x)=0$ siempre que $\epsilon=cte$, obteniendo de nuevo $\delta S=0$. Luego, hemos definido las corrientes de Noether.\\ \\
Si tomamos campos $\bar{\phi}$ que satisfagan las ecuaciones de Euler-Lagrange, entonces
\begin{equation}
    \delta S[\phi]=0=\left.\int d^4xj^{\mu}(x)\right|_{\bar{\phi}}\partial_{\mu}\epsilon(x)
\end{equation}
Como hemos supuesto un parámetro pequeño, podemos tomar $\epsilon(x)\to0$ cuando $x\to\pm\infty$. Por tanto, haciendo partes tenemos
\begin{equation}
    0=\delta S[\phi]=\left.\int d^4x\epsilon(x)\partial_{\mu}j^{\mu}(x)\right|_{\bar{\phi}}
    \label{eq1.27}
\end{equation}
cosa que nos deja que 
\begin{equation}
\left.\partial_{\mu}j^{\mu}\right|_{\bar{\phi}}=0
\end{equation}
siendo una ecuación de continuidad, que es válida solo para campos que satisfagan Euler-Lagrange. 
\begin{remark}
    Podemos definir las cargas como
    \begin{equation}
        Q(t)=\int d^3xj^0(t,\vec{x})
    \end{equation}
    para todo $\phi$. Derivamos temporalmente la carga,
    \begin{equation*}
        \left.\frac{\partial Q(t)}{\partial t}\right|_{\bar{\phi}}=\int d^3x\left.\frac{\partial j^0}{\partial t}\right|_{\bar{\phi}}=-\int d^3x\left.\nabla\cdot\vec{j}\right|_{\bar{\phi}}=0
    \end{equation*}
    Entonces $\left.Q(t)\right|_{\bar{\phi}}=cte$, por lo que se dice que tenemos una carga \textbf{conservada}.
\end{remark}
Luego, el Teorema de Noether será
\begin{tcolorbox}[title=Teorema de Noether]
    Toda simetría continua del Lagrangiano da lugar a una \textbf{corriente conservada}, $j^{\mu}(x)$, de forma que las ecuaciones del movimiento implican,
    \begin{equation}
        \partial_{\mu}j^{\mu}=0
    \end{equation}
    o, en otras palabras,
    \begin{equation}
        \frac{\partial j^0}{\partial t}+\nabla\cdot\vec{j}=0
    \end{equation}
\end{tcolorbox}
\begin{example}
Tomamos una acción 
\begin{equation*}
    S=\int d^4x\frac{1}{2}\partial_{\mu}\phi\partial^{\mu}\phi
\end{equation*}
y tomamos la simetría
\begin{equation*}
    \phi(x)\to\phi(x)+C
\end{equation*}
y queremos calcular la corriente de Noether del sistema. Para ello, hacemos el 'truco' de $C=C(x)$ y variamos la acción, tal que
\begin{equation*}
    \begin{array}{rl}
        \delta S & =\int d^4x\frac{1}{2}\partial_{\mu}(\phi(x)+C(x))\partial^{\mu}(\phi(x)+C(x))-\int d^4x\frac{1}{2}\partial_{\mu}\phi\partial^{\mu}\phi= \\
     & =\int d^4x\frac{1}{2}\brackets{\cancel{\partial_{\mu}\phi(x)\partial^{\mu}\phi(x)}+\partial_{\mu}\phi(x)\partial^{\mu}C(x)+\partial_{\mu}C(x)\partial^{\mu}\phi(x)+\cancelto{\approx0}{\partial_{\mu}C(x)\partial^{\mu}C(x)}-\cancel{\partial_{\mu}\phi(x)\partial^{\mu}\phi(x)}}=\\
     &=\int d^4\frac{1}{2}\brackets{\partial_{\mu}\phi(x)\partial^{\mu}C(x)+\partial_{\mu}\phi(x)\partial^{\mu}C(x)}=\int d^4x\partial^{\mu}\phi(x)\partial_{\mu}C(x)
    \end{array}
\end{equation*}
Comparando con la ecuación \ref{eq1.27} vemos que la corriente de Noether asociada es
\begin{equation*}
    j^{\mu}=\partial^{\mu}\phi(x)
\end{equation*}
por tanto, comprobamos si la corriente es conservada, suponiendo campos que cumplan Euler-Lagrange,
\begin{equation*}
    \left.\partial_{\mu}j^{\mu}\right|_{\bar{\phi}}=-\partial_{\mu}\partial^{\mu}\bar{\phi}=-\Box\bar{\phi}=0
\end{equation*}
dado que, comparando con el ejemplo \ref{ej1.2.3}, la parte del Lagrangiano de las derivadas nos da la ecuación del movimiento $\Box\bar{\phi}=0$.
\end{example}
\begin{proposition}
    Para espacios planos con
    \begin{equation}
        S=\int d^4x\mathscr{L}(\phi(x),\partial_{\mu}\phi(x))
    \end{equation}
    se cumple siempre la simetría,
    \begin{equation}
    \phi_a(x)\to\phi_a'(x)=\phi(x+a),\hspace{3mm}a\in\mathbb{R}^4
    \end{equation}
\end{proposition}
\begin{proof}
    Veamos primero que esta transformación es realmente una simetría de la acción, es decir, debemos ver que $\delta S=0$. Para ello, suponemos que los nuevos puntos vienen dados por $y^{\mu}=x^{\mu}-a^{\mu}$, luego, suponiendo que $a^{\mu}$ es infinitesimal, tenemos el desarrollo en serie
    \begin{equation*}
        \phi(x)\to\phi(x+a)\approx\phi(x)+a^{\mu}\partial_{\nu}\phi(x)+\dots
    \end{equation*}
    Estamos considerando variaciones donde reemplazamos el campo $\phi(x)$ con una combinación lineal del campo y sus derivadas evaluadas en el mismo punto $x$. El punto $x$ no cambia. Nuestras coordenadas no cambian. Luego, tenemos la ley de transformación
    \begin{equation}
        \frac{\delta\phi}{\delta a^{\nu}}=\partial_{\nu}\phi
    \end{equation}
    aplicada a cualquier campo. Esto se aplica también al Lagrangiano, tal que
    \begin{equation}
        \frac{\delta\mathscr{L}}{\delta a^{\nu}}=\partial_{\nu}\mathscr{L}
    \end{equation}
    Al ser una derivada total, vemos que
    \begin{equation}
        \delta S=\int d^4x\delta\mathscr{L}=a^{\nu}\int d^4x\partial_{\nu}\mathscr{L}=0
    \end{equation}
    tomando $a^{\nu}\to0$. Esta es la razón por la que hablamos a veces de que son simetrías de la acción y no simetrías del Lagrangiano.
\end{proof}
\begin{remark}
    Dada esta simetría, podemos calcular las corrientes de Noether asociadas, que serán 4, una para cada componente de $\nu$. Para ello, calculamos la variación del Lagrangiano como,
    \begin{equation}
       \partial_{\nu}\mathscr{L}= \frac{\delta\mathscr{L}(\phi(x),\partial\phi(x))}{\delta a^{\nu}}=\partial_{\mu}\left(\sum_n\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi)}\frac{\delta\phi}{\delta a^{\nu}}\right)=\partial_{\mu}\left(\sum_n\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi)}\partial_{\nu}\phi\right)=0
    \end{equation}
    donde hemos usado la regla de la cadena. Se iguala a cero porque $\delta S=0$. Entonces, las corrientes de Noether son las cuatro componentes de $\nu$ de la expresión interna del paréntesis, es decir, para un $i$ fijo, tendremos
    \begin{equation}
        j_{\mu i}=\sum_n\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi)}\partial_i\phi
    \end{equation}
    que formará un tensor cuadridimensional denominado \textbf{tensor de energía-momento}, tal que
    \begin{equation}
        T_{\mu\nu}=\sum_n\frac{\partial\mathscr{L}}{\partial(\partial_{\nu}\phi)}\partial_{\nu}\phi
    \end{equation}
    Otra forma equivalente de este tensor es sumarle una constante, tal que
    \begin{equation}
        T_{\mu\nu}=\sum_n\frac{\partial\mathscr{L}}{\partial(\partial_{\nu}\phi)}\partial_{\nu}\phi-\eta_{\mu\nu}\mathscr{L}
    \end{equation}
    A partir de este tensor podemos definir cuatro cargas conservadas, de la forma
    \begin{equation}
        Q_{\nu}=\int d^3xT_{0\nu}
    \end{equation}
    Las componentes de $Q_{\nu}$ son la energía total y momentos del sistema, que son independientes del tiempo, es decir, $\partial_tQ_{\nu}=0$ seguido de $\partial_tT_{\mu\nu}=0$. Esta simetría (invariancia de la teoría bajo traslaciones espacio-temporales) quiere decir la física es independiente del lugar del universo en el que suceda el experimento. El Teorema de Noether nos dice que esta simetría es el \textit{por qué} la energía y el momento se conservan. Así tenemos que,
    \begin{equation}
        E=Q_{0}=\int d^3xT_{00};\hspace{4mm}P_i=Q_{i}=\int d^3xT_{0i}
        \label{eq1.42}
    \end{equation}
\end{remark}
\begin{Trucaso}
    Una de las razonas por las que querríamos un tensor de energía-momento simétrico, sería para conectar con la Relatividad General. De hecho, esta observación proporciona una vía rápida y sencilla de determinar un tensor de energía-momento simétrico. Primero, consideremos acoplar la teoría a un espacio-tiempo curvo, introduciendo una métrica arbitraria $g_{\mu\nu}(x)$ en lugar de $\eta_{\mu\nu}$ y reemplazamos los términos cinéticos por derivadas covariantes adecuadas mediante el "acoplamiento mínimo". Por tanto, un tensor simétrico de energía-momento en el espacio plano vendrá dado por
    \begin{equation}
        \Theta^{\mu\nu}=-\left.\frac{2}{\sqrt{-g}}\frac{\partial(\sqrt{-g}\mathscr{L})}{\partial g_{\mu\nu}}\right|_{g_{\mu\nu}=\eta_{\mu\nu}}
    \end{equation}
    donde $g\equiv|g_{\mu\nu}|$.
\end{Trucaso}
\begin{Trucaso}
    Existe un método rápido para determinar las corrientes conservadas asociadas a una simetría interna $\delta\phi=\alpha\phi$ para la que el Lagrangiano es invariante. Aquí, $\alpha\in\mathbb{R}$. Ahora consideremos realizar la transformación anterior, pero $\alpha$ dependerá del espacio-tiempo: $\alpha=\alpha(x)$. La acción ya no es invariante. Sin embargo, el cambio deberá ser de la forma
    \begin{equation}
        \delta\mathscr{L}=(\partial_{\mu}\alpha)h^{\mu}(\phi)
    \end{equation}
    El cambio en la acción será,
    \begin{equation}
        \delta S=\int d^4x\delta\mathscr{L}=-\int d^4x\alpha(x)\partial_{\mu}h^{\mu}
    \end{equation}
    que significa que cuando las ecuaciones de Euler-Lagrange se satisfacen, $\delta S=0$, tenemos
    \begin{equation}
        \partial_{\mu}h^{\mu}=0
    \end{equation}
    Vemos que podemos asociar las funciones $h^{\mu}=j^{\mu}$ como corrientes conservadas. Esta forma de verlo enfatiza que son los términos de derivadas, y no los términos de potencial, en la acción los que contribuyen a la corriente.\\ \\
    Este truco es el que hemos usado para determinar las corrientes de Noether en esta misma sección.
\end{Trucaso}
\section{Formalismo Hamiltoniano}
La conexión entre el formalismo lagrangiano y la teoría cuántica es la integral de camino. Nos centraremos en la cuantización canónica. Para ello, necesitamos el \textbf{formalismo Hamiltoniano} de teoría de campos. Tomamos el Lagrangiano $L[\phi(t),\dot{\phi}(t)]$, con la transformación $\phi(t)\to\phi(t)(\vec{x})=\phi(t,\vec{x})$. Empezamos definiendo el \textbf{momento} $\pi^a(x)$ asociado al campo $\phi_a(x)$, tomando la derivada del funcional, tal que
\begin{equation}
    \pi^a(t)=\frac{\partial L}{\partial\dot{\phi}_a(t)}
\end{equation}
El momento conjugado $\pi^a(t)$. No debemos confundirlo con el momento total $P^i$ definido en la ecuación \ref{eq1.42}. Definimos el Hamiltoniano como
\begin{equation}
    H[\phi(t),\dot{\phi}(t)]=\dot{\phi}(t)\pi(t)-L[\phi(t),\dot{\phi}(t)]
\end{equation}
Definimos la \textbf{densidad Hamiltoniana} como,
\begin{equation}
    H=\int d^3x\mathscr{H}[\phi(t,\vec{x}),\pi(t,\vec{x}),\nabla\phi(t,\vec{x})]
\end{equation}
Podemos obtener las ecuaciones de movimiento del formalismo hamiltoniano, que serían las equivalentes a Euler-Lagrange en el formalismo lagrangiano. Que son,
\begin{tcolorbox}[title=Ecuaciones del movimiento de Hamilton]
    \begin{equation}
        \dot{\phi}_a(x)=\frac{\partial\mathscr{H}}{\partial\pi^a};\hspace{5mm}\dot{\pi}^a(x)=-\frac{\partial\mathscr{H}}{\partial\phi_a(x)}+\partial_i\left(\frac{\partial\mathscr{H}}{\partial(\partial_i\phi_a(x))}\right);\hspace{2mm}i=1,2,3
    \end{equation}
    es decir, $\phi_a(x)$ depende del tiempo y el espacio.
\end{tcolorbox}
\section{Corchetes de Poisson (de Lie)}
Los corchetes de Poisson para campos (corchetes de Lie) son la generalización en campos de los corchetes de Poisson de mecánica clásica y de los conmutadores de mecánica cuántica. Estos corchetes se definen a partir de dos campos, luego, sean dos funcionales $f[\phi,\pi]$, $g[\phi,\pi]$ tenemos
\begin{equation}
    \brackets{f,g}_{PP}=\frac{\delta f}{\delta\phi}\cdot\frac{\delta g}{\delta\pi}-\frac{\delta f}{\delta\pi}\cdot\frac{\delta g}{\delta\phi}
\end{equation}
Además, los corchetes pueden actuar directamente sobre campos, y si tomamos directamente $\phi_a(x)$ y $\pi^b(x)$, tendremos
\begin{equation}
    \brackets{\phi_a(\vec{x}),\pi^b(\vec{y})}_{PP}=\delta_{ab}\delta^{(3)}(\vec{x}-\vec{y}); \hspace{3mm}\brackets{\phi_a(\vec{x}),\phi_b(\vec{y})}=\brackets{\pi^a(\vec{x}),\pi^b(\vec{y})}=0
\end{equation}
Notar que hemos perdido el camino de invariancia de Lorentz desde que hemos separado el espacio $\vec{x}$ y el tiempo $t$. Estamos trabajando en la imagen de Schrödinger donde los operadores $\phi_a(\vec{x})$ y $\pi^a(\vec{x})$ no dependen del tiempo, pues toda la dependencia temporal decae en la ecuación de Schrödinger.\\ \\ 
Otra ventaja de esta notación es que podemos reescribir las ecuaciones de Hamilton como,
\begin{equation}
    \frac{df(t)}{dt}=\brackets{f,\mathscr{H}}_{PP}
\end{equation}
\chapter{Simetría de Poincaré}
Es una simetría del espacio-tiempo plano. Será una combinación lineal de la simetría Lorentz y de las traslaciones espaciotemporales. Por ello, comenzaremos estudiando el grupo de Lorentz.
\section{Introducción}
El grupo de Lorentz es el $SL(2,\mathbb{C})$, correspondiente con un grupo de matrices complejas $2x2$ con determinante igual a 1.\\ \\
En Relatividad General tenemos el intervalo
\begin{equation}
    ds^2=\eta_{\mu\nu}dx^{\mu}dx^{\nu}
\end{equation}
donde $\eta_{\mu\nu}$ es una dos-forma, denominada métrica de Minkowski. Este intervalo es invariante bajo transformaciones del tipo
\begin{equation}
    (\Lambda,a):\mathscr{M}\to\mathscr{M}
\end{equation}
tal que
\begin{equation}
    x^{\mu}\to x^{'\mu}=\Lambda_{\nu}^{\mu}x^{\nu}+a^{\mu}\equiv(\Lambda,a)
\end{equation}
donde $a^{\mu}$ es un cuadrivector constante y $\Lambda_{\nu}^{\mu}\in O(1,3)$ es una matriz $4x4$ que satisface que
\begin{equation}
    \Lambda^T\eta\Lambda=\eta\to\Lambda_{\nu}^{\mu}\Lambda_{\sigma}^{\rho}\eta_{\mu\rho}=\eta_{\nu\sigma}
\end{equation}
Estas transformaciones son las isométricas del espacio de Minkowski. Forman un grupo con la composición. Se denominan \textbf{transformaciones de Poincaré}.\\ \\
Se dice que $\Lambda$ pertenece al grupo $O(1,3)$, que es un grupo no conexo con $(det\Lambda)^2=1$, luego $det\Lambda=\pm1$; además, se cumple que $(\Lambda_0^0)^2-(\Lambda_0^i)^2=1$, por tanto, $|\Lambda_0^0|\geq1$, luego, $sgn\Lambda_0^0=\pm1$. Entonces, tenemos 4 posibilidades para los $\Lambda_{\nu}^{\mu}$. Por tanto, para las 4 posibilidades corresponderán 4 'piezas' disjuntas en $O(1,3)$.\\ \\
La única pieza que forma un subgrupo es la que contiene la identidad $(\mathds{1},0)$, siendo las $\Lambda_{\nu}^{\mu}$ con $det\Lambda=1$ que forman el subgrupo $SO(1,3)$ que no es conexo; si además $\Lambda_0^0>0$, entonces tenemos el subgrupo $\tilde{L}=SO(1,3)^{\uparrow}$, tal que
\begin{equation}
    SO(1,3)^{\uparrow}:=\curlybraces{\Lambda\in O(1,3);det(\Lambda)=1;\Lambda_0^0>0}
\end{equation}
cuyas propiedades son:
\begin{itemize}
    \item Es un grupo de Lie con propiedades topológicas.
    \item No es compacto, es decir, no es cerrado y/o no es acotado.
    \item Es conexo.
    \item No es simplemente conexo, que da lugar a representaciones proyectivas que dan problemas.
\end{itemize}
Usualmente al subgrupo $\tilde{L}:=SO(1,3)^{\uparrow}$ se le denomina \textbf{grupo de Lorentz} (ortocrono). Reservaremos este nombre para otro grupo (relacionado).\\ \\
Podemos encontrar un subgrupo de $SO(1,3)^{\uparrow}$, el denominado $SO(3)$, que es el grupo de las rotaciones espaciales y $SU(2)$ es su recubridor universal.
\begin{note}
\[\hspace{1mm}\]
    \begin{itemize}
        \item Las rotaciones son matrices bloques de la forma
        \begin{equation}
            \Lambda(R)=\begin{pmatrix}
                1 & 0\\
                0 & R
            \end{pmatrix}
        \end{equation}
        donde $R$ es una matriz $3x3$, es decir, $R$ es una matriz $SO(3)$.
    \item Los boosts son $\Lambda\notin SO(3)$ dados en una dirección $\hat{n}$. Por ejemplo, para $\hat{n}=\hat{z}$ tenemos,
    \begin{equation}
        \Lambda_{\hat{z}}(\eta)=\begin{pmatrix}
            \cosh\eta & 0 & 0 & \sinh\eta\\
            0 & 0 & 0 & 0\\
            0 & 0 & 0 & 0\\
            \sinh\eta & 0 & 0 & \cosh\eta
        \end{pmatrix}
    \end{equation}
    donde $\eta$ se denomina \textit{rapidity}, que es el conjunto de elementos que no están en las rotaciones. Además, como los cosenos y senos hiperbólicos no están acotados, los boosts hacen que el grupo de Lorentz no sea compacto.
    \end{itemize}
\end{note}
Como $SO(1,3)^{\uparrow}$ no es compacto ni simplemente conexo, trabajaremos con su recubridor universal, que definimos como $L\to\tilde{L}=L/Ker(\pi)$, con $\pi:L\to\tilde{L}$ homomorfismo de grupo y analítico, $\mathscr{C}^{\infty}$.\\ \\
Vemos que la \textbf{composición de transformaciones} es
\begin{equation}
    (\Lambda_1,a_1)\circ(\Lambda_2,a_2)=(\Lambda_1\cdot\Lambda_2,a_1+\Lambda_1a_1)
\end{equation}
Tenemos dos subgrupos importantes formados por:
\begin{itemize}
    \item Los elementos de la forma $(\Lambda,0)$. Siendo un grupo isomorfo a $O(1,3)$.
    \item Los elementos de la forma $(\mathds{1},a)$, que son traslaciones espacio-temporales.
\end{itemize}
Para este curso, el \textbf{grupo de Lorentz} será el recubridor universal de $\tilde{L}$, dado por \\$L=Spin(1,3)$. Esto significa que existe un homomorfismo analítico, tal que
\begin{equation}
    \pi:L\to\tilde{L},\hspace{4mm}\text{con}\hspace{4mm}\tilde{L}\sim L /Ker\pi
\end{equation}
Resulta que $L\sim SL(2,\mathbb{C})$, el grupo de matrices $2\times2$ complejas con determinante 1, como vimos antes.\\ \\
Así, directamente denominaremos \textbf{grupo de Lorentz} a $L=SL(2,\mathbb{C})$.

\section{Grupo de Lorentz}
Como ya hemos definido antes, el grupo de Lorentz es $L=SL(2,\mathbb{C})$, que  es conexo, simplemente conexo y no compacto; tal que $L=\curlybraces{N\in GL(2,\mathbb{C})/detN=1}$, que es de dimensión 6, pues tenemos 8 parámetros reales y 2 ecuaciones de la condición $detN=1$. Además, el grupo $GL(2,\mathbb{C})$ es el grupo general lineal de matrices $2x2$ invertibles. Nos va a interesar estudiar la relación de $SL(2,\mathbb{C})$ con $SO(1,3)^{\uparrow}$.\\ \\
Definimos $(\sigma_{\mu})_{\dot{\alpha}\alpha}\equiv\sigma_{\mu}=(I,\vec{\sigma})_{\mu}$ y $(\bar{\sigma}_{\mu})^{\dot{\alpha}\alpha}\equiv\bar{\sigma}_{\mu}=(I,-\vec{\sigma})_{\mu}$, donde $\vec{\sigma}$ son las matrices de Pauli. Además, $\sigma_{\mu}$ forma una base real del espacio de todas las matrices hermíticas $2x2$.
\begin{proposition}
    Podemos relacionar los subgrupos $\sigma_{\mu}$ y $\bar{\sigma}_{\mu}$ con la métrica de Minkowski, tal que
    \begin{equation}
        \eta_{\mu\nu}=\frac{1}{2}Tr(\bar{\sigma}_{\mu}\sigma_{\nu})
    \end{equation}
\end{proposition}
\begin{proof}
    Para demostrar esta proposición lo hacemos por partes. Primero, sabemos que $\sigma_0=\bar{\sigma}_0=I$, por tanto, $\bar{\sigma}_0\sigma_0=I$. Ahora, para la parte 'espacial', sabemos que $\sigma_i=\sigma^i$ y $\bar{\sigma}_i=-\sigma^i$, donde las $\sigma^i$ corresponden la $i-$ésima coordenada del vector $\vec{\sigma}$, mientras que las $\sigma_i$ y $\bar{\sigma}_i$ corresponden al tensor. Las propiedades de las matrices de Pauli nos dicen que $Tr(\sigma^i)=0$, $Tr(I)=2$ y $Tr(\sigma^i\sigma^j)=2\delta^{ij}$. Por tanto, tenemos que
    \[\left.\begin{array}{rl}
         I & \text{si }\mu=\nu=0,  \\
        -\sigma^i & \text{si }\mu=i,\nu=0\\
        \sigma^j & \text{si }\mu=0,\nu=j\\
        -\sigma^i\sigma^j & \text{si }\mu=i,\nu=j
    \end{array}\right\rbrace\]
    Por tanto, tendremos
    \[\begin{array}{rl}
    Tr(\bar{\sigma}_{\mu}\sigma_{\nu})&=Tr(\bar{\sigma_0}\sigma_0)+Tr(\bar{\sigma_0}\sigma_j)+Tr(\bar{\sigma_i}\sigma_0)+Tr(\bar{\sigma_i}\sigma_j)=  \\
         & =Tr(\sigma^0\sigma^0)+Tr(\sigma^0\sigma^j)+Tr(-\sigma^i\sigma^0)+Tr(-\sigma^i\sigma^j)=\\
         &=Tr(I)+Tr(\sigma^j)+Tr(-\sigma^i)+Tr(-\sigma^i\sigma^j)=\\
         &=2+0+0-2\delta^{ij}
         \end{array}\]
         Luego, tenemos que
         \[Tr(\bar{\sigma}_{\mu}\sigma_{\nu})=\begin{pmatrix}
             2 & 0 & 0 & 0\\
             0 & -2 & 0 & 0\\
             0 & 0 & -2 & 0\\
             0 & 0 & 0 & -2
         \end{pmatrix}=2\eta_{\mu\nu}
    \]
    Por tanto, tenemos que $\eta_{\mu\nu}=\frac{1}{2}Tr(\bar{\sigma}_{\mu}\sigma_{\nu})$.
\end{proof}
\begin{remark}
    Podemos asociar cuadrivectores con matrices hermíticas $2\times 2$, tal que
    \begin{equation}
             x^{\mu}\to\hat{x}=x^{\mu}\sigma_{\mu}
    \end{equation}
    Este mapa es biyectivo, cuya inversa viene dada por,
    \begin{equation}
             x^{\mu}=\frac{1}{2}Tr(\bar{\sigma}^{\mu}\hat{x})
    \end{equation}
    donde para cada $x^{\mu}$ existe un único $\hat{x}$.\\ \\
    Además, puede comprobarse que
    \begin{equation}
        det\hat{x}=x^{\mu}x_{\mu}
    \end{equation}
\end{remark}

Vamos a estudiar $L=SL(2,\mathbb{C})$. Para todas $N\in L$, tenemos una transformación lineal 
\begin{equation}
    \hat{x}\to\hat{x}'=N\hat{x}N^{\dagger}
\end{equation}
donde si $\hat{x}$ es hermítico, entonces $\hat{x}'$ también lo será. Por tanto, se podrá escribir de forma única,
\begin{equation}
    \hat{x}'=x^{'\mu}\sigma_{\mu}
\end{equation}
Luego, $\hat{x}\rightsquigarrow x^{\mu}\Rightarrow \hat{x}'=x^{'\mu}\sigma_{\mu}\rightsquigarrow x^{'\mu}$, entonces estamos haciendo una transformación lineal de vectores. Además, vemos que
\begin{equation}
    det\hat{x}'=det(N\hat{x}N^{\dagger})=\cancelto{1}{det(N)}\cdot det(\hat{x})\cdot\cancelto{1}{det(N^{\dagger})}=det\hat{x}
\end{equation}
es decir, se preserva la longitud de los vectores, por tanto
\begin{equation}
    x^{'\mu}x'_{\mu}=x^{\mu}x_{\mu}
\end{equation}
Concluimos que
\begin{equation}
    x^{'\mu}=\Lambda_{\nu}^{\mu}x^{\nu}
\end{equation}
con $\Lambda\in O(1,3)$, tal que
\begin{equation}
    \begin{array}{rrcl}
        \pi: & SL(2,\mathbb{C}) & \to & O(1,3) \\
         & N & \mapsto & \Lambda(N)
    \end{array}
\end{equation}
siendo un homomorfismo de grupo.\\ \\
Como $SL(2,\mathbb{C})$ es conexo, todos los elementos pueden conectarse. Como uno de los posibles $\Lambda$ es la identidad, $\Lambda(\mathds{1})=\mathds{1}_{\varphi}\in SO(1,3)^{\uparrow}$, entonces, de forma local, podemos tomar que $\Lambda(N)\in SO(1,3)^{\uparrow}$ y
\begin{equation}
    \pi:SL(2,\mathbb{C})\to \tilde{L}=SO(1,3)^{\uparrow}
\end{equation}
que no es biyectivo y $\Lambda(N_1,N_2)=\Lambda(N_1)\Lambda(N_2)$. En efecto, $\Lambda(-N)=\Lambda(N)$, dado que $det(-N)=det(N)=1$. De hecho,
\begin{equation}
    \Lambda(N)=\mathds{1}\Longrightarrow\hat{x}=N\hat{x}N^{\dagger},\forall\hat{x}\text{ hermítica}
\end{equation}
En particular, $\mathds{1}=NN^{\dagger}$, así $\Lambda(N)=\mathds{1}$, entonces $N^{\dagger}=N^{-1}$. Ahora,
\begin{equation}
    \hat{x}=N\hat{x}N^{-1},\forall\hat{x}\text{ hermítica}
\end{equation}
Luego, $N\propto\mathds{1}$ y como $det N=1$, entonces $N=\pm\mathds{1}$. Lo contrario también es cierto, es decir, si $N=\pm\mathds{1}$, entonces $\Lambda(N)=\mathds{1}$. Por lo tanto,
\begin{equation}
    Ker\pi=\curlybraces{\mathds{1},-\mathds{1}}\sim\mathbb{Z}_2
\end{equation}
Sabemos que $N\hat{x}N^{\dagger}=\hat{x}$ y que $\Lambda(N)=\Lambda(-N)$, por lo que tenemos dos elementos por cada $\Lambda$. Luego, como por cada $N,-N$ tenemos un $\Lambda$, entonces $SO(1,3)^{\uparrow}=SL(2,\mathbb{C})/\mathbb{Z}_2$, siendo el \textit{recubrimiento doble} del grupo.
\begin{note}
    En mecánica cuántica, usamos el grupo $SO(3)$, que satisface $SO(3)=SU(2)/\mathbb{Z}_2$.
\end{note}
\subsection{Álgebra de Lorentz}
Hemos estudiado el grupo de Lorentz, $L=SL(2,\mathbb{C})$, y queremos estudiar el \textbf{álgebra de Lorentz}, $sl(2,\mathbb{C})$ (las álgebras se denotan como los grupos pero en minúsculas).\\ \\
La transformación de Lorentz, $N\in SL(2,\mathbb{C})$, pueden descomponerse de forma infinitesimal, tal que
\begin{equation}
    N\approx\mathds{1}+M+O(M^2)\approx e^M+O(M^2)
\end{equation}
Sabemos que $detN=1=e^{TrM}$, por lo que $TrM=0$. Luego, $M$ es una matriz compleja $2x2$ sin traza. Ésta tiene 6 parámetros reales (pues tiene 8 parámetros, pero le restamos 2 por la condición de $TrM=0$), tal que
\begin{equation}
    sl(2,\mathbb{C})=\curlybraces{M\in gl(2,\mathbb{C})/TrM=0}
\end{equation}
donde $gl(2,\mathbb{C})$ es el álgebra del grupo general lineal de matrices $2\times2$ complejas sin traza.\\ \\
Como un álgebra de Lie compleja, una base del espacio vectorial de las matrices $M$ vendrá dada por,
\begin{equation}
    \curlybraces{\frac{\sigma_j}{2};j=1,2,3}
\end{equation}
siendo una base compleja de 3 parámetros complejos, que equivalen a 6 parámetros reales.
Luego, podemos redefinirla como
\begin{equation}
    \curlybraces{\frac{\sigma_j}{2},i\frac{\sigma_j}{2};j=1,2,3}
\end{equation}
siendo una base real. \\ \\
Por notación escribiremos la base compleja como
\begin{equation}
    \curlybraces{i\frac{\sigma_j}{2};j=1,2,3}
\end{equation}
Tenemos que,
\begin{equation}
    \brackets{\frac{\sigma_i}{2},\frac{\sigma_j}{2}}=i\epsilon_{ijk}\sigma_k
\end{equation}
La base real será,
\begin{equation}
    \curlybraces{iJ_j,iK_j;~j=1,2,3}
\end{equation}
donde $J_j=\frac{\sigma_j}{2}$, unitaria, y $K_j=i\frac{\sigma_j}{2}$, antiunitaria. Las reglas de conmutación que describen la base real serán
\begin{equation}
    \brackets{J_i,J_j}=i\epsilon_{ijk}J_k;\hspace{4mm}\brackets{J_i,K_j}=i\epsilon_{ijk}K_k;\hspace{4mm}\brackets{K_i,K_j}=-i\epsilon_{ijk}J_k
\end{equation}
Otra forma más compacta de agrupar estas reglas de conmutación es definir un vector antiunitario simétrico, $J_{\mu\nu}=-J_{\nu\mu}$, tal que
\begin{equation}
    J_{\mu\nu}=\left\lbrace\begin{matrix}
        J_{0i}=K_i\\
        J_{ij}=\epsilon_{ijk}J_k
    \end{matrix}\right.
\end{equation}
De aquí se obtienen los conmutadores anteriores. Debemos ver los casos posibles para encontrar la forma general, tal que
\begin{equation}
    \begin{array}{lll}
        -\textbf{\text{Para }}\mathbf{J_{0i},J_{0j}}: & \brackets{J_{0i},J_{0j}}&=\brackets{K_i,K_j}=-i\epsilon_{ijk}J_k=-iJ_{ij} \\
        -\textbf{\text{Para }}\mathbf{J_{ij},J_{kl}}: & \brackets{J_{ij},J_{kl}}&=\brackets{\epsilon_{ijk}J_k,\epsilon_{klm}J_m}=i(\delta_{ik}J_{jl}+\delta_{jl}J_{ik}-\delta_{il}J_{jk}-\delta_{jk}J_{il})\\
        -\textbf{\text{Para }}\mathbf{J_{ij},J_{0k}}:&\brackets{J_{ij},J_{0k}}&=\brackets{\epsilon_{ijm}J_m,K_k}=i(\delta_{ik}J_{0j}-\delta_{jk}J_{0i})
    \end{array}
\end{equation}
Por tanto, la expresión general puede agruparse como combinación de métricas de Minkowski, tal que
\begin{tcolorbox}[title=Reglas de conmutación del grupo de Lorentz]
\begin{equation}
\brackets{J_{\mu\nu},J_{\rho\sigma}}=i(\eta_{\nu\rho}J_{\mu\sigma}-\eta_{\mu\rho}J_{\nu\sigma}+\eta_{\mu\sigma}J_{\nu\rho}-\eta_{\nu\sigma}J_{\mu\rho})
\end{equation}
\end{tcolorbox}
\begin{proof}
    Veamos como obtener la segunda expresión:
    \begin{equation*}
    \begin{array}{ll}
        \brackets{\epsilon_{ijk}J_k,\epsilon_{klm}J_m}&=\epsilon_{ijk}J_k\epsilon_{klm}J_m-\epsilon_{klm}J_m\epsilon_{ijk}J_k=\epsilon_{ijk}\epsilon_{klm}J_kJ_m-\epsilon_{klm}\epsilon_{ijk}J_mJ_k=\\ \\
        &=\curlybraces{\text{Usando que }\epsilon_{ijk}\epsilon_{klm}=\epsilon_{klm}\epsilon_{ijk}}=\epsilon_{ijk}\epsilon_{klm}(J_kJ_m-J_mJ_k)=\epsilon_{ijk}\epsilon_{klm}\brackets{J_k,J_m}\\ \\
        &=i\epsilon _{ijk}\epsilon_{klm}\epsilon_{kmn}J_n=\curlybraces{\text{Usando que }\epsilon_{ijk}\epsilon_{klm}=\delta_{il}\delta_{jm}-\delta_{im}\delta_{jl}}=\\ \\
        &=i\epsilon_{kmn}(\delta_{il}\delta_{jm}-\delta_{im}\delta_{jl})J_n=i\epsilon_{kmn}\delta_{il}\delta_{jm}J_n-i\epsilon_{kmn}\delta_{im}\delta_{jl}J_n=\\ \\
        &=\curlybraces{\text{Usando que }\delta_{jm}\epsilon_{kmn}=\epsilon_{kjn}\text{ y }\delta_{jl}\epsilon_{kmn}=\epsilon_{kin}}=\\ \\
        &=i\delta_{il}\epsilon_{kjn}J_n-i\delta_{im}\epsilon_{kin}J_n=\curlybraces{\text{Usando la contracción de índices }J_{ab}=\epsilon_{abc}J_c}=\\ \\
        &=i\delta_{il}J_{kj}-i\delta_{im}J_{ki}=\curlybraces{\text{Dado que }J_{ab}\text{ es antisimétrico, aparecerán dos términos extra}}=\\ \\
        &=i(\delta_{ik}J_{jl}+\delta_{jl}J_{ik}-\delta_{il}J_{jk}-\delta_{jk}J_{il})
    \end{array}
    \end{equation*}
\end{proof}
\begin{proof}
    Vemos como obtener la tercera expresión:
    \begin{equation*}
        \begin{array}{rl}
            \brackets{\epsilon_{ijm}J_m,K_k} & =\epsilon_{ijm}J_mK_k-K_k\epsilon_{ijm}J_m=\epsilon_{ijm}(J_mK_k-K_kJ_m)= \\ \\
             & =\epsilon_{ijm}\brackets{J_m,K_k}=i\epsilon_{ijm}\epsilon_{kmn}K_n=i(\delta_{ik}\delta_{jn}-\delta_{in}\delta_{jk})K_n=i(\delta_{ik}K_j-\delta_{jk}K_i)=\\ \\
             &=\curlybraces{\text{Usando que }K_i=J_{0i}}=i(\delta_{ik}J_{0j}-\delta_{jk}J_{0i})
        \end{array}
    \end{equation*}
\end{proof}
\begin{note}
    La base de $su(2)$, siendo un subálgebra, es
    \begin{equation}
        \curlybraces{J_i,i=1,2,3}
    \end{equation}
    y cumple que $\brackets{J_i,J_j}=i\epsilon_{ijk}J_k$
\end{note}
\noindent Por otro lado, todo elemento del grupo no compacto, $N\in SL(2,\mathbb{C})$, puede escribirse como 
\begin{equation}
    N=e^M
\end{equation}
de forma única, donde $M\in sl(2,\mathbb{C})$. La única excepción es la superficie 2D de elementos,
\begin{equation}
    \begin{pmatrix}
        -1-ab & a^2\\
        -b^2 & -1+ab
    \end{pmatrix}
\end{equation}
donde $a,b\in\mathbb{C}$. El conjunto
\begin{equation}
    \curlybraces{e^M,M\in sl(2,\mathbb{C})}
\end{equation}
es denso en $SL(2,\mathbb{C})$, es decir, cualquier elemento de $SL(2,\mathbb{C})$ puede aproximarse arbitrariamente por elementos de la forma $e^M$, donde $M\in sl(2,\mathbb{C})$.
\begin{note}
    Si $N\in SL(2,\mathbb{C})$, entonces $N$ ó $-N$ podrán escribirse como $e^M$, con $M\in sl(2,\mathbb{C})$.
\end{note}
Sin embargo, el grupo no es compacto pero sí puede escribirse bajo ciertas propiedades y extender la definición. Escribimos entonces,
\begin{equation}
    N=e^M=e^{\frac{1}{2}i\omega_{\mu\nu}J^{\mu\nu}}=e^{i\brackets{\vec{\Theta}\cdot{\vec{J}+\vec{\beta}\cdot\vec{K}}}}
\end{equation}
donde $\vec{\Theta}$ y $\vec{\beta}$ son parámetros reales. $N$ no es unitaria. La transformación queda definida por 6 parámetros reales, los $\Theta_i,\beta_i$. Las $J_i$ generan las rotaciones alrededor del eje $\hat{x}_i$, mientras que las $K_i$ generan los boosts sobre la dirección $\hat{x}_i$.\\ \\
Si $\beta_i=0$, entonces estamos en el grupo $SU(2)$, mientras que si $\Theta_i=0$, estaremos en el grupo de los boosts. Notamos que $J_i$ son hermíticas, pero $K_i$ son antihermíticas. Por tanto, para $\vec{\beta}\neq0$, entonces $N$ no será unitaria.\\ \\
El álgebra de $sl(2,\mathbb{C})$ y $so(1,3)^{\uparrow}$ son isomorfas. Esto significa que podemos representar los generadores de Lorentz en términos de matrices $2\times2$ complejas, lo que permite estudiar sus representaciones mediante elementos de $SL(2,\mathbb{C})$.
\section{Representaciones de grupos}
Veamos como los elementos de un grupo actúan sobre los vectores, es decir, sobre espacios vectoriales. Para ello, asociaremos los elementos con funciones.\\ \\
El grupo $SL(2,\mathbb{C})$ (y por tanto $SO(1,3)$) es simple y no compacto. Un teorema nos dice que esto no tiene representaciones no triviales finitas unitarias. Otro teorema nos dice que todas las representaciones son completamente reducibles. Así, solo bastará estudiar representaciones irreducibles.\\ \\
Estudiaremos el grupo de Lorentz, $L=SL(2,\mathbb{C})$, en el espacio vectorial complejo $V=\mathbb{C}^2$, denominado \textbf{espacio de espinores}, cuya base es
\begin{equation}
    B_{\mathbb{C}^2}=\curlybraces{\begin{pmatrix}
        1\\
        0
    \end{pmatrix},\begin{pmatrix}
        0\\
        1
    \end{pmatrix}}
\end{equation}
De forma general, una representación $\rho$ será un homomorfismo que asocie a cada elemento $N$ del grupo una matriz de la forma,
\begin{equation}
    \rho(N)=e^{i\brackets{\theta_i\rho(J_i)+\alpha_i\rho(K_i)}}
\end{equation}
es decir, construimos representaciones $\rho(N)$ a partir de la representación fundamental de $SL(2,\mathbb{C})$. Además, deben de cumplir que
\begin{equation}
    \rho(N_1N_2)=\rho(N_1)\rho(N_2)
\end{equation}
es decir, que satisface las propiedades de homomorfismo.
\begin{note}
     Podemos entender $\rho(N)$ como una especie de 'matriz $\times$ vector'.
\end{note}
Tendremos varios tipos de representaciones dependiendo de los parámetros y de cómo $\rho$ actúa:
\begin{itemize}
    \item Podemos definir la representación \textbf{trivial}, tal que
    \begin{equation}
        \rho_0(N)=\mathds{1}
    \end{equation}
    donde todos los generadores se envían a la matriz identidad o al cero.
    \item Otras representaciones no triviales serán,
    \begin{equation}
        \rho(N)=N;\hspace{3mm}\rho'(N)=(N^T)^{-1};\hspace{3mm}\bar{\rho}(N)=N^*;\hspace{3mm}\bar{\rho}'(N)=(N^{\dagger})^{-1}
        \label{eq2.29}
    \end{equation}
\end{itemize}
Se puede comprobar que este es el espacio más pequeño con representaciones no triviales.
\subsection{Representación reducible/irreducible}
Una representación $R$ se llama \textit{reducible} si posee un subespacio invariante, es decir, si la acción de cualquier operador lineal $D_R(g)$ sobre los vectores del subespacio proporciona otro vector del subespacio. Por el contrario, una representación con ningún subespacio invariante se denomina \textit{irreducible}.\\ \\
De forma sencilla, decimos que las representaciones reducibles pueden descomponerse en matrices diagonales de bloques, mientras que las representaciones irreducibles solo se descomponen en un único bloque no trivial.\\ \\
El caso que estamos estudiando es el irreducible. Podemos definir un tensor antisimétrico, $\mathscr{E}_{\alpha\beta}=-\mathscr{E}_{\beta\alpha}$ y $\mathscr{E}^{\alpha\beta}=-\mathscr{E}^{\beta\alpha}$, cuyos índices son los espinoriales, tal que
\begin{equation}
    \mathscr{E}^{12}=1\Rightarrow\mathscr{E}=\begin{pmatrix}
        0 & 1\\
        -1 & 0
    \end{pmatrix};\hspace{3mm}\mathscr{E}_{12}=-1\Rightarrow\mathscr{E}^{-1}=\begin{pmatrix}
        0 & -1\\
        1 & 0
    \end{pmatrix}
\end{equation}
Son la inversa del otro, así,
\begin{equation}
    \mathscr{E}^{\alpha\beta}\mathscr{E}_{\alpha\gamma}=\delta_{\gamma}^{\beta}
\end{equation}
Luego,
\begin{equation}
    \mathscr{E}\mathscr{E}^{-1}=\begin{pmatrix}
        0 & 1\\
        -1 & 0
    \end{pmatrix}\begin{pmatrix}
        0 & -1\\
        1 & 0
    \end{pmatrix}=\begin{pmatrix}
        1 & 0\\
        0 & 1
    \end{pmatrix}=\mathds{1}
\end{equation}
Consideremos elementos $N\in SL(2,\mathbb{C})$, con $detN=1$, por lo tanto, debe cumplirse que
\begin{equation}
    N_{\alpha}^{\gamma}N_{\beta}^{\delta}\mathscr{E}_{\gamma\delta}=\mathscr{E}_{\alpha\beta}\hspace{4mm}\text{ó}\hspace{4mm}\mathscr{E}^{\gamma\delta}(N^{-1})_{\gamma}^{\alpha}(N^{-1})_{\delta}^{\beta}=\mathscr{E}^{\alpha\beta}
\end{equation}
esto significa que $\mathscr{E}_{\alpha\beta}$ y $\mathscr{E}^{\alpha\beta}$ son invariantes bajo transformaciones de $SL(2,\mathbb{C})$, cosa análoga a la métrica $\eta_{\mu\nu}$ y $\eta^{\mu\nu}$ de Minkowski, que es invariante bajo transformaciones de Lorentz en el grupo $O(1,3)$.\\ \\
Podemos usar $\mathscr{E}$ y $\mathscr{E}^{-1}$ para subir o bajar índices, es decir,
\begin{equation}
    \Psi^{\alpha}=\mathscr{E}^{\alpha\beta}\Psi_{\beta};\hspace{4mm}\Psi_{\alpha}=\mathscr{E}_{\alpha\beta}\Psi^{\beta}
\end{equation}
Recordando las representaciones anteriores (ecuación \ref{eq2.29}), podemos comprobar que las dos primeras son representaciones \textbf{equivalentes} (ver definición formal del apéndice B). Ya que podemos escribir también el $det N=1$ como,
\begin{equation}
    (N^{-1})_{\beta}^{\alpha}=\mathscr{E}^{\alpha\gamma}N_{\gamma}^{\delta}\mathscr{E}_{\delta\beta}\text{, esto es, }(N^{-1})^T=\mathscr{E}N\mathscr{E}^{-1}
    \label{eq2.33}
\end{equation}
Esto es una relación de semejanza, la cuál implica que (mientras $\mathscr{E}$ no dependa de $N$) que $\rho$ y $\rho'$ son representaciones equivalentes.\\ \\
Tenemos el espinor,
\begin{equation}
    \varphi\in\mathbb{C}^2=\begin{pmatrix}
        \varphi_1\\
        \varphi_2
    \end{pmatrix}
\end{equation}
La acción de $\rho(N)$ sobre este espinor, $\varphi\in\mathbb{C}^2$, será
\begin{equation}
    \brackets{\rho(N)\varphi}_\alpha =N_{\alpha}^{\beta}\varphi_{\beta}
\end{equation}
Diremos que $\varphi$ con esta transformación es un \textit{espinor 'left-handed'}. Esto implica que
\begin{equation}
    \begin{array}{rl}
        \brackets{\rho'(N)\varphi}^{\alpha} &=\varphi^{\beta}(N^{-1})_{\beta}^{\alpha}=((N^{-1})^{T})^{\alpha}_{\beta}\varphi^{\beta} 
    \end{array}
\end{equation}
Luego, vemos que $\rho(N)$ y $\rho'(N)$ son equivalentes, la única diferencia es que sube o baja el índice del $\mathscr{E}$, pues comprobamos con la ecuación \ref{eq2.33}.\\ \\
Por notación, para distinguir $\bar{\rho}(N)$ y $\bar{\rho}'(N)$, usamos la notación compleja, i.e., se emplean índices con punto, es decir, usamos $\dot{\alpha}_i$, tal que, tomando el espinor $\chi^{\dot{\alpha}}$, con $\mathscr{E}^{\dot{\alpha}\dot{\beta}}$ y $\mathscr{E}_{\dot{\alpha}\dot{\beta}}$, tenemos
\begin{equation}
    \chi^{\dot{\alpha}}=\mathscr{E}^{\dot{\alpha}\dot{\beta}}\chi_{\dot{\beta}}
\end{equation}
\begin{note}[\textbf{IMPORTANTE}]
    Nunca contraemos índices con punto con índices sin punto, se contraen solo entre ellos porque si no, nos saldríamos del espacio vectorial.
\end{note}
\noindent La acción de $\bar{\rho}(N)$ es,
\begin{equation}
    \brackets{\bar{\rho}(N)\bar{\chi}}_{\dot{\alpha}} =(N^*)_{\dot{\alpha}}^{\dot{\beta}}\bar{\chi}_{\dot{\beta}}
\end{equation}
Diremos que $\bar{\chi}$ con esta transformación es un \textit{espinor 'right-handed'}. Al igual que para $\rho$ y $\rho'$, ocurre que $\bar{\rho}$ y $\bar{\rho}'$ son equivalentes. La acción de $\bar{\rho}'(N)$ sobre $\bar{\chi}$ es
\begin{equation}
    \begin{array}{rl}
                \brackets{\bar{\rho}'(N)\bar{\chi}}^{\dot{\alpha}} &=((N^{\dagger})^{-1})^{\dot{\alpha}}_{\dot{\beta}}\bar{\chi}^{\dot{\beta}} 
    \end{array}   
\end{equation}
Estas representaciones son consistentes con el uso de $\mathscr{E}$ y $\mathscr{E}^{-1}$ para subir y bajar índices, lo cuál hace el cambio $\rho\longleftrightarrow\rho'$ ó $\bar{\rho}\longleftrightarrow\bar{\rho}'$, gracias a la invariancia de $\mathscr{E}$.\\ \\
 Tenemos 4 representaciones, siendo equivalentes dos a dos. Resumiendo, tenemos dos tipos de espinores dependiendo de cómo transformen.
\begin{tcolorbox}[title=Tipos de espinores]
    \begin{equation}
        \left.\begin{array}{rl}
        \brackets{\rho(N)\varphi}_\alpha &=N_{\alpha}^{\beta}\varphi_{\beta}  \\
        \brackets{\rho'(N)\varphi}^{\alpha} &=\varphi^{\beta}(N^{-1})_{\beta}^{\alpha}=((N^{-1})^{T})^{\alpha}_{\beta}\varphi^{\beta} 
    \end{array}\right\rbrace
    \end{equation}
    Los denominamos \textbf{espinores levógicos}, $(L)$ (\textit{left hand})
    \begin{equation}
        \left.\begin{array}{rl}
        \brackets{\bar{\rho}(N)\bar{\chi}}_{\ddot{\alpha}} &=(N^*)_{\dot{\alpha}}^{\dot{\beta}}\bar{\chi}_{\dot{\beta}}  \\
        \brackets{\bar{\rho}'(N)\bar{\chi}}^{\dot{\alpha}} &=((N^{\dagger})^{-1})^{\dot{\alpha}}_{\dot{\beta}}\bar{\chi}^{\dot{\beta}} 
    \end{array}\right\rbrace
    \end{equation}
    Los denominamos \textbf{espinores dextrógicos}, $(R)$ (\textit{right hand}).
\end{tcolorbox}
\begin{note}
    La siguiente identidad es extremadamente útil
    \begin{equation}
        \mathscr{E}^{\alpha\beta}\mathscr{E}_{\beta\gamma}=\delta^{\alpha}_{\gamma}
    \end{equation}
\end{note}
\begin{note}
 Obviamente, si $\varphi$ transforma con $\rho$ (o $\rho'$) y $\bar{\chi}$ transforma con $\bar{\rho}$ (o $\bar{\rho}'$), entonces, el complejo conjugado corresponderá con poner puntos en los índices sin puntos y quitar los puntos en los índices con puntos.
\end{note}
\noindent Estas representaciones son las más fieles y sencillas no triviales, pues no pierden información. Podremos construir otras representaciones a partir de ellas, pues podemos formar representaciones reducibles a partir de representaciones irreducibles.\\ \\
El producto tensorial de $\rho$, $\rho'$, $\bar{\rho}$ y $\bar{\rho}'$, se denomina \textbf{tensor espinorial}, que son también representaciones de $SL(2,\mathbb{C})$. Tal que
\begin{equation}
(\psi')^{\dot{\alpha}_1\dot{\alpha}_2\dots\dot{\alpha}_n}_{\alpha_1\alpha_2\dots\alpha_m}=N_{\alpha_1}^{\beta_1}N_{\alpha_2}^{\beta_2}\dots N_{\alpha_m}^{\beta_m}((N^{\dagger})^{-1})^{\dot{\alpha}_1}_{\dot{\beta}_1}((N^{\dagger})^{-1})^{\dot{\alpha}_2}_{\dot{\beta}_2}\dots ((N^{\dagger})^{-1})^{\dot{\alpha}_n}_{\dot{\beta}_n}\psi^{\dot{\beta}_1\dot{\beta}_2\dots\dot{\beta}_n}_{\beta_1\beta_2\dots\beta_m}
\end{equation}
Podemos ver que $\tilde{\rho}(N_1N_2)=\tilde{\rho}(N_1)\tilde{\rho}(N_2)$ forma un grupo. En esta ocasión, la representación \textbf{NO ES IRREDUCIBLE}, solo es reducible para $m=n=1$, mientras que para $m>1$ y $n>1$, estas representaciones son reducibles. Por ejemplo, si $\varphi^{\dot{\alpha}\dot{\beta}}_{\alpha\beta}$ es un tensor y lo escribimos como $\varphi=\varphi^1+\varphi^2$, con
\begin{equation}
    \begin{array}{rl}
        (\varphi^1)^{\dot{\alpha}\dot{\beta}}_{\alpha\beta} &=\frac{1}{2}\mathscr{E}^{\dot{\alpha}\dot{\beta}}\chi_{\alpha\beta}\Rightarrow\chi_{\alpha\beta}=\mathscr{E}_{\dot{\gamma}\dot{\delta}}\varphi^{\dot{\gamma}\dot{\delta}}_{\alpha\beta} \\ \\
        (\varphi^2)^{\dot{\alpha}\dot{\beta}}_{\alpha\beta} &=\varphi^{\dot{\alpha}\dot{\beta}}_{\alpha\beta}-\frac{1}{2}\mathscr{E}^{\dot{\alpha}\dot{\beta}}\chi_{\alpha\beta}=\chi^{(\dot{\alpha}\dot{\beta})}_{\alpha\beta} 
    \end{array}
\end{equation}
donde ($a$ $b$ $c$ $\dots$) indica la simetrización de los índices $a,b,c,\dots$ Pueden reducirse contrayendo índices con $\mathscr{E}^{\alpha\beta}$ y $\mathscr{E}_{\dot{\alpha}\dot{\beta}}$, es decir, a partir del tensor espinorial y del tensor antisimétrico $\mathscr{E}$, podemos construir un nuevo tensor con índices contraídos. $\chi^1$ y $\chi^2$ también son tensores. Y $\chi$ es un tensor con $n=0$ y $m=2$. Además, $\chi$ y $\varphi^2$ se han transformado en tensores del mismo tipo, formando así subespacios invariantes. Como podemos escribir el tensor como suma y resta de este nuevo tensor, el tensor puede descomponerse en 'trozos' más sencillos y decimos que es \textit{reducible}.\\ \\
Los tensores de la forma,
\begin{equation}
    \psi^{(\dot{\alpha}_1\dot{\alpha}_2\dots\dot{\alpha}_n)}_{(\alpha_1\alpha_2\dots\alpha_m)}
\end{equation}
 se transforman en tensores de la misma forma y no pueden reducirse, es decir, son \textit{irreducibles}. Así, formarán los espacios vectoriales de las representaciones irreducibles de $SL(2,\mathbb{C})$. Como los índices están simetrizados y los índices con punto y sin punto no se mezclan, tendremos $\frac{m}{2}-$índices sin punto y $\frac{n}{2}-$índices con punto. Luego, la representación vendrá dada por,
\begin{equation}
    \left(\frac{m}{2},\frac{n}{2}\right)
\end{equation}
con $m,n$ enteros. Las matrices de estas representaciones irreducibles se obtienen por la simetrización de $m-$productos de $N$ y $n-$productos de $(N^{\dagger})^{-1}$. La misma notación se emplea para las representaciones equivalentes con subida o bajada de índices.\\ \\
La representación \textbf{conjunto conjugado} de $\left(\frac{m}{2},\frac{n}{2}\right)$ será $\left(\frac{n}{2},\frac{m}{2}\right)$, cuyo tensor espinorial es $\psi^{(\alpha_1\alpha_2\dots\alpha_m)}_{(\dot{\alpha}_1\dot{\alpha}_2\dots\dot{\alpha}_n)}$. Además, a la transformación,
\begin{equation}
    \varphi^{\dot{\alpha}_1,\dots,\dot{\alpha}_n}_{\beta_1,\dots,\beta_m}\to\varphi^{*\dot{\beta}_1,\dots,\dot{\beta}_m}_{\alpha_1,\dots,\alpha_n}
\end{equation}
la denominamos \textbf{Conjugación de Carga}.\\ \\
En particular, podemos coger una representación que sea $\left(\frac{n}{2},\frac{n}{2}\right)$, y aplicando la conjugación de carga nos saldrá, o bien la misma representación, siendo una representación \textit{real}, es decir, podemos escribir las matrices con números reales; o bien, una representación equivalente a la real, que es una representación \textit{pseudo-real}, pues volviendo a aplicar conjugación de carga y una transformación de semejanza volvemos a obtener la misma representación.\\ \\
Si tenemos $\varphi_{\dot{\gamma}}^{\alpha\beta}\chi_{\beta\delta}$, tenemos una contracción de índices, conservando la covariancia. Luego, es un tensor que tiene estructura de los índices que no están contraídos, es decir, $\varphi_{\dot{\gamma}\delta}^{\alpha}$. Además, el tensor $\varphi_{\dot{\gamma}}^{\alpha\beta}\chi_{\alpha\beta}^{\dot{\gamma}}$ será un invariante.
\subsection{Representaciones Finitas}
Tendremos varias representaciones irreducibles de dimensión finita. Veámoslo:
\begin{itemize}
    \item La representación escalar:
    \begin{equation}
        \left(0,0\right)
    \end{equation}
    es una representación unitaria.
    \item Las representaciones \textit{left handed} y \textit{right handed},
    \begin{equation}
        \left(\frac{1}{2},0\right)_{LH}\hspace{5mm}\left(0,\frac{1}{2}\right)_{RH}    \end{equation}
    son representaciones que no conservan paridad por separado, por lo que podemos combinarlas linealmente y obteniendo así una representación irreducible que conserve paridad,
    \begin{equation}
        \left(\frac{1}{2},0\right)\oplus\left(0,\frac{1}{2}\right)
    \end{equation}
    que es la denominada \textbf{representación de Dirac}, que es reducible y pseudo-real. Podemos pasar de una representación $LH$ a una $RH$, y viceversa, haciendo la conjugación de carga.
    \item La representación vectorial también es finita e irreducible,
    \begin{equation}
        \left(\frac{1}{2},\frac{1}{2}\right)
    \end{equation}
    siendo una representación vectorial del grupo de Lorentz, pues es la representación que se usa para definir los vectores, ya que a cada matriz hermítica le podemos asociar un vector, tal que
    \begin{equation}
        \varphi_{\alpha\dot{\alpha}}\doteq\varphi^{\mu}(\sigma_{\mu})_{\alpha\dot{\alpha}}
    \end{equation}
    donde $(\sigma_{\mu})_{\alpha\dot{\alpha}}$ y $(\bar{\sigma}_{\mu})_{\alpha\dot{\alpha}}$ son las matrices de Pauli. Además, por la definición de $\Lambda(N)$, tenemos que
    \begin{equation}
        \sigma_{\mu}=N\sigma_{\nu}N^{\dagger}\Lambda(N^{-1})^{\nu}_{\mu}=\Lambda(N)_{\mu}^{\nu}N\sigma_{\nu}N^{\dagger}
    \end{equation}
    que puede interpretarse como la invariancia de $\sigma$ en $SL(2,\mathbb{C})$, cuya transformación viene dada por lo índices $(\sigma_{\mu})_{\alpha\dot{\alpha}}$. También tendremos invariancia en $\bar{\sigma}$, que viene dado por
    \begin{equation}
        (\bar{\sigma}_{\mu})^{\dot{\alpha}\alpha}=\mathscr{E}^{\dot{\alpha}\dot{\beta}}\mathscr{E}^{\alpha\beta}(\sigma_{\mu})_{\beta\dot{\beta}}
    \end{equation}
    Algunas identidades útiles para $\sigma$ y $\bar{\sigma}$ son,
    \begin{equation}
        \begin{array}{cc}
            \left(\sigma_{\mu}\bar{\sigma}_{\nu}+\sigma_{\nu}\bar{\sigma}_{\mu}\right)_{\alpha}^{\beta}=2\eta_{\mu\nu}\delta_{\alpha}^{\beta}; & \left(\bar{\sigma}_{\mu}\sigma_{\nu}+\bar{\sigma}_{\nu}\sigma_{\mu}\right)_{\alpha}^{\beta}=2\eta_{\mu\nu}\delta_{\alpha}^{\beta}; \\
           Tr(\sigma_{\mu}\bar{\sigma}_{\nu})=2\eta_{\mu\nu};  & (\sigma^{\mu})_{\alpha\dot{\alpha}}(\bar{\sigma}_{\mu})^{\dot{\beta}\beta}=2\delta_{\alpha}^{\beta}\delta_{\dot{\alpha}}^{\dot{\beta}}
        \end{array}
    \end{equation}
    Ahora, los vectores de la representación $(\frac{1}{2},\frac{1}{2})$ tendrán la forma $\varphi_{\dot{\alpha}\alpha}$. Les asociaremos los vectores de Lorentz, tal que
    \begin{equation}
        \varphi^{\mu}=\frac{1}{2}\left(\bar{\sigma}^{\mu}\right)^{\dot{\alpha}\alpha}\varphi_{\alpha\dot{\alpha}}
    \end{equation}
    tal que
    \begin{equation}
        \varphi_{\dot{\alpha}\alpha}=\varphi^{\mu}(\sigma_{\mu})_{\alpha\dot{\alpha}}
    \end{equation}
    Bajo $N\in SL(2,\mathbb{C})$, 
    \begin{equation}
        \varphi_{\alpha\dot{\alpha}}\to\varphi'_{\alpha\dot{\alpha}}=N_{\alpha}^{\beta}N^{*\dot{\beta}}_{\dot{\alpha}}\varphi_{\beta\dot{\beta}}=(N\varphi N^{\dagger})_{\alpha\dot{\alpha}}
    \end{equation}
    Entonces, de la definición de $\Lambda(N)$, tenemos que
    \begin{equation}
        \varphi^{\mu}\to\varphi^{'\mu}=\Lambda(N)^{\mu}_{\nu}\varphi^{\nu}
    \end{equation}
    y $\varphi^{\mu}$ transforma como un vector de Lorentz. Las matrices $\Lambda(N)$ son reales.
\end{itemize}
\begin{note}
    Las representaciones $LH$ y $RH$ vienen dadas por $N$, que son matrices complejas $2x2$ con $detN=1$, por lo que \textbf{no son unitarias}.
\end{note}
Como hemos construido todas las posibles representaciones irreducibles de dimensión finita, pero no son representaciones unitarias (salvo la trivial). De hecho, ningún grupo de Lie simple y no compacto no tendrá representaciones unitarias no triviales de dimensión finita. Por lo que el hacer cuántica se complica, pues los operadores de la mecánica cuántica son unitarios. Por lo que tendremos que ver las representaciones infinitas para intentar encontrar representaciones unitarias.
\begin{tcolorbox}[title=Sentido físico de las representaciones.]
Las representaciones irreducibles unitarias son las que se asocian con las partículas, que son de dimensión infinita; mientras que las representaciones irreducibles no unitarias serán las asociadas a los campos, que podrán ser de dimensión finita o infinita. Podremos relacionar ambas representaciones, encontrando así un camino para pasar de campos a partículas, y viceversa.
\end{tcolorbox}
\subsection{Representaciones finitas del álgebra de Lorentz}
Se derivan fácilmente de las representaciones del grupo cercanas a la identidad. Para la representación $\left(\frac{1}{2},0\right)$, los generadores son
\begin{equation}
    J_j\doteq\frac{\sigma_j}{2};\hspace{5mm}K_j\doteq i \frac{\sigma_j}{2}
\end{equation}
Para la representación $\left(0,\frac{1}{2}\right)$, usando $\bar{\rho}'$ tenemos
\begin{equation}
    N=e^{i\omega_jT_j}\Rightarrow (N^{\dagger})^{-1}=e^{i\omega_jT_j^{\dagger}}
\end{equation}
luego,
\begin{equation}
    J_j\doteq\frac{\sigma_j}{2};\hspace{5mm}K_j=-i\frac{\sigma_j}{2}
\end{equation}
Las representaciones del álgebra asociadas a las representaciones de tensores espinoriales son productos directos de las anteriores. Por ejemplo, para $\left(\frac{1}{2},\frac{1}{2}\right)$, tenemos
\begin{equation}
    J_j\doteq\frac{\sigma_j}{2}\otimes\mathds{1}_2+\mathds{1}_1\otimes\frac{\sigma_j}{2}
\end{equation}
\begin{equation}
    K_j\doteq \frac{i\sigma_j}{2}\otimes\mathds{1}_2+\mathds{1}_1\otimes\frac{-i\sigma_j}{2}
\end{equation}
Para encontrar un camino alterno debemos definir la \textit{complexificación}.
\begin{definition}
Definimos las operación \textbf{complexificar} de forma que si tomamos un álgebra $\mathscr{H}(2,\mathbb{R})$ real y al aplicar las complexificación, obtenemos un álgebra $\tilde{\mathscr{H}}(2,\mathbb{C})$ complejo.
\end{definition}
Un camino alternativo para encontrar las representaciones irreducibles del álgebra de Lorentz es el siguiente:
\begin{itemize}
    \item Complexificamos $sl(2,\mathbb{C})$, obteniendo $sl(2,\mathbb{C})_{\mathbb{C}}\sim sl(2,\mathbb{C})\oplus isl(2,\mathbb{C})$.
    \item Encontramos las representaciones irreducibles de cada $sl(2,\mathbb{C})$, tratado como un álgebra compleja. Estas son las álgebras usuales del momento angular. De hecho, $sl(2,\mathbb{C})\sim su(2)_{\mathbb{C}}$ y el procedimiento estándar para encontrar las representaciones irreducibles del álgebra real $su(2)$ es por su complexificación (pensando en los operadores escalera, los cuales son combinaciones lineales complejas).
    \item Las representaciones irreducibles del álgebra compleja $sl(2,\mathbb{C})_{\mathbb{C}}$ son $(j_1,j_2)$, siendo el producto directo de las representaciones de spin $j_1$ y spin $j_2$ de $su(2)_{\mathbb{C}}$.
    \item Finalmente, las representaciones irreducibles de $sl(2,\mathbb{C})$, que es una forma real de $sl(2,\mathbb{C})_{\mathbb{C}}$, están en correspondencia biyectiva (se pueden asociar de forma única) con las representaciones irreducibles del álgebra compleja $sl(2,\mathbb{C})_{\mathbb{C}}$, por lo que también son $(j_1,j_2)$, con $j_1$ y $j_2$ representaciones irreducibles de estos espines del álgebra real $su(2)$.
\end{itemize}
\begin{remark}
    En la mayoría de textos esto se trata de forma más simplificada, pues directamente se dice que $sl(2,\mathbb{C})\sim su(2)\oplus su(2)$. El problema de esto es que \textbf{¡esta afirmación es falsa!}
\end{remark}
Seamos más explícitos. Definimos
\begin{equation}
    J_j^{\pm}=J_i\pm iK_j
\end{equation}
donde $J^{\pm}_j\in sl(2,\mathbb{C})_{\mathbb{C}}$ y
\begin{equation}
    \curlybraces{J_j^+,J_j^-;j=1,2,3}
\end{equation}
es una base compleja de $sl(2,\mathbb{C})_{\mathbb{C}}$. Tenemos que
\begin{equation}
    \brackets{J_i^{\pm},J_j^{\pm}}=i\epsilon_{ijk}J_k^{\pm};\hspace{5mm}\brackets{J_i^{\pm},J_j^{\mp}}=0
\end{equation}
Entonces, $\curlybraces{J_i^{+};i=1,2,3}$ y $\curlybraces{J_i^{-};i=1,2,3}$ son bases complejas de $su(2)_{\mathbb{C}}$.\\ \\
Sea $M_{(j)}$ una representación irreducible de $su(2)_{\mathbb{C}}$ (que es también una representación real irreducible de $su(2)$). Definimos,
\begin{equation}
    M_{(j_1,j_2)}(J_i)=M_{(j_1)}(J_i^-)\otimes\mathds{1}_{2j_2+1}+\mathds{1}_{2j_1+1}\otimes M_{(j_2)}(J_i^*)
\end{equation}
\begin{equation}
    M_{(j_1,j_2)}(K_i)=i\brackets{M_{(j_1)}(J_i^-)\otimes\mathds{1}_{2j_2+1}+\mathds{1}_{2j_1+1}M_{(j_2)}(J_i^+)}
\end{equation}
tal que
\begin{equation}
    M_{(j_1,j_2)}\left(a_iJ_i+b_iK_i\right)=a_iM_{(j_1,j_2)}(J_i)+b_iM_{(j_1,j_2)}(K_i)
\end{equation}
para $a_i,b_i\in\mathbb{R}$.\\ \\
Entonces, $M_{(j_1,j_2)}$ es una representación irreducible del álgebra real $sl(2,\mathbb{C})$ sobre un espacio complejo de dimensión $(2j_1+1)(2j_2+1)$. Las representaciones irreducibles $(j_1,j_2)$ son simplemente las representaciones irreducibles $\left(\frac{m}{2},\frac{n}{2}\right)$ anteriormente descritas.

% \noindent Tomamos el álgebra $\mathscr{H}(2,\mathbb{C})$, que debemos \textit{descomplexificar} (operación inversa a la complexificación), para obtener álgebras reales que representan espacios vectoriales. Esta descomplexificación nos dará dos álgebras reales (una por cada número real de un número complejo).
% \begin{example}
%     Un álgebra compleja es $J_i^{\pm}=\frac{1}{2}\left(J_i\pm K_i\right)$, cuyas relaciones de conmutación son 
%     \[\brackets{J_i^+,J_j^-}=0\]
%     por tanto, este álgebra tiene forma de suma directa de las álgebras reales $J^+$ y $J^-$, es decir, $JU(2)_\mathbb{C}\oplus JU(2)_{\mathbb{C}}$, tal que
%     \[\brackets{J_i^{\pm},J_j^{\pm}}=i\epsilon_{ijk}J_k^{\pm}\]
%     que se parece al álgebra del momento angular descomplexificado.
% \end{example}
\section{Grupo de Poincaré}
(Propuesto por primera vez por Minkowski)\\ \\
El grupo de Poincaré, $\mathscr{P}$, está formado por elementos de la forma $(N,a)$, donde \\$N\in SL(2,\mathbb{C})=L$ y $a\in\mathbb{R}^4$ cuadrivector. La regla de composición de los elementos del grupo será
\begin{equation}
    (N_1,a_1)\cdot(N_2,a_2)=(N_1\cdot N_2,a_1+\Lambda(N_1)a_2)
\end{equation}
y la inversa de $(N,a)$ es
\begin{equation}
    \left(N^{-1},-\Lambda(N)^{-1}a\right)
\end{equation}
\begin{note}
    Este formalismo se inspiró a causa de las isométricas del espacio de Minkowski, mencionadas en la introducción, pero por definición solo incluiremos los elementos conectados con la identidad y que vivan en el recubridor $L$.
\end{note}
$\mathscr{P}$ tiene estructura de producto semi-directo y se escribe $\mathscr{P}=SL(2,\mathbb{C})\propto\mathbb{R}^4$, es 'semi' debido a $\Lambda(N)$, que aparece en la operación del grupo anterior. Recordamos que $SO(1,3)^{\uparrow}$ es esencialmente igual a $SL(2,\mathbb{C})$ a nivel local (a nivel global difieren), por lo que si tratamos los elementos de forma local, podemos trabajar con $SO(1,3)^{\uparrow}$. Así, cerca de la identidad, podremos asociar matrices $5\times5$ a cada elemento del grupo,
\begin{equation}
    (N,a)\to\left(\begin{array}{c|c}
        \Lambda(N) & a \\ \hline
        0 & \mathds{1}
    \end{array}\right)_{5x5}
\end{equation}
Entonces, la conmutación del grupo se escribirá como multiplicaciones de matrices.\\ \\
Obviamente, los elementos $(N,0)$ forman un subgrupo isomorfo a $SL(2,\mathbb{C})$. El elemento neutro del grupo de Poincaré será el elemento $(\mathds{1},0)$, que forma un subgrupo isomorfo a $\mathbb{R}^4$, siendo el subgrupo de traslaciones espacio-temporales. Esto es abeliano y normal,
\begin{equation}
    (N,a)\cdot(\mathds{1},b)\cdot(N,a)^{-1}=(\mathds{1},c)
\end{equation}
Los elementos del grupo los podremos dividir de la forma,
\begin{equation}
    (N,a)\to(N,0);(\mathds{1},a)
\end{equation}
\subsection{Álgebra de Poincaré}
Podremos encontrar las relaciones de conmutación del álgebra de Lie directamente de la regla del producto, viendo $g_1g_2g_1^{-1}g_2^{-1}$ cerca de la identidad. Alternativamente, podemos escribir los generadores de forma explícita en la representación matricial anterior. Tomamos los elementos del álgebra de la forma 
\begin{equation*}
    (N,a)\to\left(\begin{array}{c|c}
        \Lambda(N) & a \\ \hline
        0 & \mathds{1}
    \end{array}\right)_{5x5}\equiv\Theta
\end{equation*}
Desarrollamos esto cerca de la identidad, tal que $\Theta=\mathds{1}+\delta\Theta$, de forma que
\begin{equation}
    \left\lbrace\begin{array}{lll}
         \Lambda=\mathds{1}+\delta\Lambda & \Rightarrow & \delta\Lambda=\omega  \\
        a=\mathds{1}+\delta a & \Rightarrow & \delta a=\epsilon\\
        \mathds{1}=\mathds{1}+\delta\mathds{1} & \Rightarrow & \delta\mathds{1}=0
    \end{array}\right.
\end{equation}
Por tanto,
\begin{equation}
    \delta\Theta=\left(\begin{array}{c|c}
        \omega & \epsilon \\ \hline
        0 & 0
    \end{array}\right)
\end{equation}
con $\omega_{\mu\nu}=-\omega_{\nu\mu}$.
\begin{note}
    El convenio de signos será,
    \begin{equation}
        (1,\mathscr{E})=(1,0)-i\mathscr{E}^{\mu}P_{\mu}
    \end{equation}
\end{note}
Para la $J$ tenemos,
\begin{equation}\small
    J_{\mu\nu}\doteq\left(\begin{array}{c|c}
        \tilde{J}_{\mu\nu} & 0 \\ \hline
        0 & 0
    \end{array}\right); \hspace{2mm}P_o\doteq\left(\begin{array}{c|c}
        0 & \begin{matrix}
            1\\
            0\\
            0\\
            0
        \end{matrix}\equiv e^0 \\ \hline
       0  & 0
    \end{array}\right);\hspace{2mm}P_1\doteq\left(\begin{array}{c|c}
       0  & \begin{matrix}
           0\\
           1\\
           0\\
           0
       \end{matrix}\equiv e^1 \\ \hline
        0 & 0
    \end{array}\right);\hspace{2mm}P_2\doteq\left(\begin{array}{c|c}
       0  & \begin{matrix}
           0\\
           0\\
           1\\
           0
       \end{matrix}\equiv e^2 \\ \hline
        0 & 0
    \end{array}\right);\hspace{2mm}P_3\doteq\left(\begin{array}{c|c}
       0  & \begin{matrix}
           0\\
           0\\
           0\\
           1
       \end{matrix}\equiv e^3 \\ \hline
        0 & 0
    \end{array}\right)
\end{equation}
donde $\tilde{J}_{\mu\nu}$ es el generador (antisimétrico) de $L$ en la representación vectorial. Para este grupo las reglas de conmutación son,
\begin{equation}
    \brackets{P_{\mu},P_{\nu}}=0;\hspace{4mm}\brackets{P_{\mu},J_{\rho\sigma}}=-i\left(\eta_{\mu\rho}P_{\sigma}-\eta_{\mu\sigma}P_{\rho}\right);\hspace{4mm}\brackets{J_{\mu\nu},J_{\rho\sigma}}=i\left(\eta_{\nu\rho} J_{\mu\sigma}-\eta_{\mu\rho} J_{\nu\sigma}+\eta_{\mu\sigma} J_{\nu\rho}-\eta_{\nu\sigma} J_{\mu\rho}\right)
\end{equation}
donde $P_{\mu}$ transforma como cuadrivector bajo transformaciones de Lorentz. Demostremos estas reglas:
\begin{proof}
    Vamos a demostrar la primera regla, $\brackets{P_{\mu},P_{\nu}}=0$:
    \begin{equation*}
        \begin{array}{rl}
            \brackets{P_{\mu},P_{\nu}} &=P_{\mu}P_{\nu}-P_{\nu}P_{\mu}=\left(\begin{array}{c|c}
       0  & e^{\mu} \\ \hline
        0 & 0
    \end{array}\right)\left(\begin{array}{c|c}
       0  & e^{\nu} \\ \hline
        0 & 0
    \end{array}\right)-\left(\begin{array}{c|c}
       0  & e^{\nu} \\ \hline
        0 & 0
    \end{array}\right)\left(\begin{array}{c|c}
       0  & e^{\mu} \\ \hline
        0 & 0
    \end{array}\right)= \\ \\
             & =\left(\begin{array}{c|c}
       0 \cdot 0 + 0\cdot e^{\mu} & 0\cdot e^{\nu}+e^{\mu}\cdot 0 \\ \hline
        0\cdot 0+0\cdot 0 & 0\cdot e^{\nu}+0\cdot 0
    \end{array}\right)+\left(\begin{array}{c|c}
       0 \cdot 0 + 0\cdot e^{\nu} & 0\cdot e^{\mu}+e^{\nu}\cdot 0 \\ \hline
        0\cdot 0+0\cdot 0 & 0\cdot e^{\mu}+0\cdot 0
    \end{array}\right)=0
        \end{array}
    \end{equation*}
\end{proof}
\begin{proof}
    Vamos a demostrar ahora la segunda regla, $\brackets{P_{\mu},J_{\rho\sigma}}=-i\left(\eta_{\mu\rho}P_{\sigma}-\eta_{\mu\sigma}P_{\rho}\right)$:
    \begin{equation*}
        \begin{array}{rl}
        \brackets{P_{\mu},J_{\rho\sigma}} &=P-{\mu}J_{\rho\sigma}-J_{\rho\sigma}P_{\mu}=\left(\begin{array}{c|c}
       0  & e^{\mu} \\ \hline
        0 & 0
    \end{array}\right)\left(\begin{array}{c|c}
        \tilde{J}_{\rho\sigma} & 0 \\ \hline
        0 & 0
    \end{array}\right)-\left(\begin{array}{c|c}
        \tilde{J}_{\rho\sigma} & 0 \\ \hline
        0 & 0
    \end{array}\right)\left(\begin{array}{c|c}
       0  & e^{\mu} \\ \hline
        0 & 0
    \end{array}\right)= \\ \\
         &=\left(\begin{array}{c|c}
       0 \cdot \tilde{J}_{\rho\sigma}+e^{\mu}\cdot 0 & 0\cdot0+e^{\mu}\cdot0 \\ \hline
        0\cdot\tilde{J}_{\rho\sigma}+0\cdot0 & 0\cdot0+0\cdot0
    \end{array}\right)-\left(\begin{array}{c|c}
        \tilde{J}_{\rho\sigma}\cdot0+0\cdot 0 & \tilde{J}_{\rho\sigma}\cdot e^{\mu}+0\cdot0 \\ \hline
        0\cdot0+0\cdot0 & 0\cdot e^{\mu}+0\cdot0
    \end{array}\right)=\left(\begin{array}{c|c}
        0 &- \tilde{J}_{\rho\sigma}\cdot e^{\mu} \\ \hline
        0 & 0
    \end{array}\right)\\ \\
    &=\curlybraces{\text{Los generadores de Lorentz en representación vectorial son: }(J_{\rho\sigma})^{\mu}_{\nu}=i\left(\eta_{\rho\nu}\delta^{\mu}_{\sigma}-\eta_{\sigma\nu}\delta^{\mu}_{\rho}\right)}=\\ \\
    &=\left(\begin{array}{c|c}
        0 &- i\left(\eta_{\rho\mu}\delta^{\nu}_{\sigma}-\eta_{\sigma\mu}\delta^{\nu}_{\rho}\right)\cdot e^{\nu} \\ \hline
        0 & 0
    \end{array}\right)=\left(\begin{array}{c|c}
        0 &- i\left(\eta_{\mu\rho}e^{\sigma}-\eta_{\mu\sigma}e^{\rho}\right) \\ \hline
        0 & 0
    \end{array}\right)=-i\left(\eta_{\mu\rho}P_{\sigma}-\eta_{\mu\sigma}P_{\rho}\right)
    \end{array}
    \end{equation*}
\end{proof}
\begin{proof}
    Vamos a demostrar ahora $\brackets{J_{\mu\nu},J_{\rho\sigma}}=i\left(\eta_{\nu\rho} J_{\mu\sigma}-\eta_{\mu\rho} J_{\nu\sigma}+\eta_{\mu\sigma} J_{\nu\rho}-\eta_{\nu\sigma} J_{\mu\rho}\right)$:
    \begin{equation*}
        \begin{array}{rl}
             \brackets{J_{\mu\nu},J_{\rho\sigma}}&=J_{\mu\nu}J_{\rho\sigma}-J_{\rho\sigma}J_{\mu\nu}=\left(\begin{array}{c|c}
        \tilde{J}_{\mu\nu} & 0 \\ \hline
        0 & 0
    \end{array}\right)\left(\begin{array}{c|c}
        \tilde{J}_{\rho\sigma} & 0 \\ \hline
        0 & 0
    \end{array}\right)-\left(\begin{array}{c|c}
        \tilde{J}_{\rho\sigma} & 0 \\ \hline
        0 & 0
    \end{array}\right)\left(\begin{array}{c|c}
        \tilde{J}_{\mu\nu} & 0 \\ \hline
        0 & 0
    \end{array}\right)= \\ \\ 
             & =\left(\begin{array}{c|c}
        \tilde{J}_{\mu\nu}\tilde{J}_{\rho\sigma} & 0 \\ \hline
        0 & 0
    \end{array}\right)-\left(\begin{array}{c|c}
        \tilde{J}_{\rho\sigma}\tilde{J}_{\mu\nu} & 0 \\ \hline
        0 & 0
    \end{array}\right)=\left(\begin{array}{c|c}
        \tilde{J}_{\mu\nu}\tilde{J}_{\rho\sigma}-\tilde{J}_{\rho\sigma}\tilde{J}_{\mu\nu} & 0 \\ \hline
        0 & 0
    \end{array}\right)=\left(\begin{array}{c|c}
       \brackets{ \tilde{J}_{\mu\nu},\tilde{J}_{\rho\sigma}} & 0 \\ \hline
        0 & 0
    \end{array}\right)=\\ \\
    &=\curlybraces{\text{Sabemos que }\brackets{ \tilde{J}_{\mu\nu},\tilde{J}_{\rho\sigma}}=i\left(\eta_{\nu\rho} \tilde{J}_{\mu\sigma}-\eta_{\mu\rho} \tilde{J}_{\nu\sigma}+\eta_{\mu\sigma} \tilde{J}_{\nu\rho}-\eta_{\nu\sigma} \tilde{J}_{\mu\rho}\right)}=\\ \\
    &=\left(\begin{array}{c|c}
       i\left(\eta_{\nu\rho} \tilde{J}_{\mu\sigma}-\eta_{\mu\rho} \tilde{J}_{\nu\sigma}+\eta_{\mu\sigma} \tilde{J}_{\nu\rho}-\eta_{\nu\sigma} \tilde{J}_{\mu\rho}\right) & 0 \\ \hline
        0 & 0
    \end{array}\right)=i\left(\eta_{\nu\rho} J_{\mu\sigma}-\eta_{\mu\rho} J_{\nu\sigma}+\eta_{\mu\sigma} J_{\nu\rho}-\eta_{\nu\sigma} J_{\mu\rho}\right)
        \end{array}
    \end{equation*}
\end{proof}
\noindent Distinguiremos la parte temporal como $P^0=H$, y la parte espacial formará el \textbf{subálgebra del momento angular}, cuyas reglas de conmutación son las usuales del momento angular,
\begin{equation}
    \brackets{J_i,J_j}=i\epsilon_{ijk}J_k;\hspace{4mm}\brackets{J_i,K_j}=i\epsilon_{ijk}K_k;\hspace{4mm}\brackets{K_i,K_j}=-i\epsilon_{ijk}J_k
\end{equation}
donde los $K_i$ actúan como trivectores. Este álgebra es la conocida \textbf{álgebra de Lorentz}.\\ \\
Juntando la parte temporal al álgebra de Lorentz, tenemos los reglas de conmutación
\begin{equation}
    \brackets{P_i,P_j}=0;\hspace{3mm}\brackets{J_i,P_j}=i\epsilon_{ijk}P_k;\hspace{3mm}\brackets{K_i,P_j}=i\delta_{ij}H;\hspace{3mm}\brackets{P_i,H}=0;\hspace{3mm}\brackets{J_i,H}=0;\hspace{3mm}\brackets{K_i,H}=iP_i
\end{equation}
Todas estas conmutaciones caracterizan el álgebra de Poincaré.
\subsection{Operadores de Casimir}
\noindent Los operadores de Casimir son objetos en cualquier representación que conmutan con todos los generadores del álgebra. Por ejemplo, $J^2$ conmuta con los generadores del momento angular, luego es un operador de Casimir.\\ \\
Un operador de Casimir será $P_{\mu}P^{\mu}$, pues es invariante Lorentz y conmuta. Si $P_{\mu}P^{\mu}$ es semidefinido positivo, entonces el $sign(H)$ es invariante, por lo que el $sign(H)$ será también un operador de Casimir. Por último, $-W_{\mu}W^{\mu}$ es también un operador de Casimir, pues $W^{\mu}$ es el vector de Pauli-Lubanski, que viene dado por
\begin{equation}
    W_{\mu}=-\frac{1}{2}\epsilon_{\mu\nu\rho\sigma}J^{\nu\rho}P^{\sigma}
\end{equation}
y sus propiedades son:
\begin{itemize}
    \item $W_{\mu}P^{\mu}=0$
    \item $\brackets{W_{\mu},P^{\mu}}=0$
    \item $\brackets{J_{\mu\nu},W_{\rho}}=i\left(\eta_{\mu\nu}W_{\rho}-\eta_{\nu\rho}W_{\mu}\right)$
    \item $\brackets{W_{\mu},W_{\nu}}=i\epsilon_{\mu\nu\rho\sigma}W^{\rho}P^{\sigma}$
\end{itemize}
\begin{note}
Dado que trabajamos con una representación matricial, podemos interpretar los operadores de Casimir como productos de matrices en cualquier representación del álgebra. Aunque su forma explícita depende de la representación, su valor propio es el mismo en cada representación irreducible, ya que conmutan con todos los generadores del álgebra.
\end{note}
Hemos visto que para el álgebra de Lorentz, quitando la representación trivial, todas las representaciones irreducibles no son unitarias; teniendo el problema de que no se conserva la norma. Pero en mecánica cuántica, las simetrías continuas vienen dadas por operadores unitarios en el espacio de Hilbert (Teorema de Wigner). Entonces, necesitaremos considerar también representaciones infinitas. Ahora, vamos a ver dos tipos de representaciones infinitas, \textit{las representaciones de campos}, que no son unitarias, pero son útiles para construir Lagrangianos y Hamiltonianos; y \textit{las representaciones de partículas}, que sí son unitarias y se emplean para construir el propio espacio de Hilbert.
\subsection{Representaciones de campos}
Usaremos espacios vectoriales de funciones para describir esta representación. Tomamos la función,
\begin{equation}
    \begin{array}{rlll}
         \Phi:&\mathbb{R}^4&\to& V_{\left(\frac{m}{2},\frac{n}{2}\right)}  \\
         & x&\mapsto&\Phi(x)
    \end{array}
\end{equation}
donde $V_{\left(\frac{m}{2},\frac{n}{2}\right)}$ es el espacio vectorial asociado a la representación irreducible de Lorentz $\left(\frac{m}{2},\frac{n}{2}\right)$, y los $\Phi(x)$ son tensores espinoriales irreducibles.\\ \\
Trabajaremos en el espacio vectorial de dimensión infinita, formado por todas las funciones $\Phi$. A estas funciones las denominamos \textbf{campos} $\mathbf{\left(\frac{m}{2},\frac{n}{2}\right)}$.\\ \\
La representación de campos $\left(\frac{m}{2},\frac{n}{2}\right)$ se define asociando cada elemento del grupo a operadores lineales en el espacio de estas funciones, tal que
\begin{equation}
    \rho_{\left(\frac{m}{2},\frac{n}{2}\right)}(N,a)\Phi=\Phi';\hspace{4mm}\Phi'(x)=M_{\left(\frac{m}{2},\frac{n}{2}\right)}(N)\Phi\left(\Lambda^{-1}(N)(x-a)\right)
    \label{eq2.61}
\end{equation}
donde $\rho_{\left(\frac{m}{2},\frac{n}{2}\right)}$ es un operador lineal y $M_{\left(\frac{m}{2},\frac{n}{2}\right)}(N)$ es la matriz asociada a $N$ en la representación irreducible de Lorentz $\left(\frac{m}{2},\frac{n}{2}\right)$.
\begin{example}
    Si tomamos la representación trivial $(0,0)$, donde $\Phi'(x')=\Phi(x)$, tenemos que
    \[x'=\Lambda x+a\Rightarrow x=\Lambda^{-1}(x'-a)\]
    luego,
    \[\Phi'(x)=\Phi\left(\Lambda^{-1}(x'-a)\right)\]
    comparando con la ecuación \ref{eq2.61}, vemos que
    \[M_{(0,0)}(N)=\mathds{1}\]
    Esta representación nos sirve para construir campos invariantes, pues la acción
    \begin{equation*}
    S[\Phi]=\int d^4x\Phi(x),\partial\Phi(x)
    \end{equation*}
    permanece invariante, ya que 
    \[\begin{array}{rl}
         S'[\Phi]&=S[\Phi']=\int d^4x\mathscr{L}(\Phi'(x),\partial\Phi'(x))=\int d^4x\mathscr{L}\left(M\Phi(x'),M\Lambda^{-1}\partial_{x'}\Phi(x')\right)=  \\ \\
         & =\int d^4x\cancelto{1}{\left|det\Lambda\right|}\mathscr{L}\left(M\Phi(x'),M\Lambda^{-1}\partial_{x'}\Phi(x')\right)\overset{\curlybraces{M\equiv\mathds{1}}}{=}\int d^4x\mathscr{L}\left(\mathds{1}\Phi(x'),\mathds{1}\Lambda^{-1}\partial_{x'}\Phi(x')\right)=\\ \\
         &=\int d^4x\mathds{L}(\Phi(x),\partial\Phi(x))=S[\Phi]
    \end{array}\]
\end{example}
Estas representaciones son en efecto, representaciones del grupo de Poincaré, son de dimensión infinita y son irreducibles. Pero para $\left(\frac{m}{2},\frac{n}{2}\right)\neq(0,0)$ no son unitarias.\\ \\
Podemos ver algunos ejemplos:
\begin{itemize}
    \item $\Psi_{\alpha}(x)\overset{(N,a)}{\longrightarrow}\Psi'_{\alpha}(x)=N_{\alpha}^{\beta}\Psi_{\beta}\left(\Lambda(N)^{-1}(x-a)\right)$, es un campo espinorial $LH$.
    \item $A_{\alpha\dot{\alpha}}(x)\overset{(N,a)}{\longrightarrow}A'_{\alpha\dot{\alpha}}(x)=N_{\alpha}^{\beta}N^{*\dot{\beta}}_{\dot{\alpha}}A_{\beta\dot{\beta}}\left(\Lambda(N)^{-1}(x-a)\right)$, es un campo vectorial. También puede escribirse como,
    \begin{equation}
        A_{\mu}(x)\to A'_{\mu}(x)=\Lambda(N)_{\mu}^{\nu}A_{\nu}\left(\Lambda(N)^{-1}(x-a)\right)
    \end{equation}
\end{itemize}

    \begin{note}
        El tratamiento que estamos haciendo de espinores es muy específico para cuatro dimensiones. Para dimensiones superiores los detalles son distintos.
    \end{note}
    Las representaciones de campos son de dimensión infinita, luego, observando las transformaciones infinitesimales de los campos, lo mejor será usar operadores diferenciales en lugar de matrices, tal que
    \begin{equation}
        P_{\mu}\doteq -i\partial_{\mu};\hspace{4mm}J_{\mu\nu}\doteq i\left(x_{\mu}\partial_{\nu}-x_{\nu}\partial_{\mu}\right)+J_{\mu\nu}^{\left(\frac{m}{2},\frac{n}{2}\right)}
    \end{equation}
    \subsubsection{Acciones invariantes}
    Un funcional,
    \begin{equation}
        S[\Phi]=\int d^4x\mathscr{L}\left(\Phi(x),\partial\Phi(x)\right)
    \end{equation}
transforma como
\begin{equation}
    \begin{array}{rrl}
       S[\Phi]\to  & S'[\Phi]=S[\Phi'] &=\int d^4x\mathscr{L}\left(\Phi'(x),\partial_{\mu}\Phi(x)\right)= \\ \\
         & &=\int d^4x\mathscr{L}\left(M\Phi(x'),M\Lambda_{\mu}^{\nu}\partial'_{\nu}\Phi(x')\right)\leftarrow x'=\Lambda x+a\\ \\
         &&=\int d^4x|det\Lambda|\mathscr{L}\left(M\Phi(x'),M\Lambda_{\mu}^{\nu}\partial'_{\nu}\Phi(x')\right)=\int d^4x\mathscr{L}\left(M\Phi(x'),M\Lambda^{-1}\partial'\Phi(x')\right)
    \end{array}
\end{equation}
Entonces, $S=S'$ si el Lagrangiano es invariante de Lorentz, es decir, si
\begin{equation}
    \mathscr{L}\left(M\Phi(x),M\Lambda^{-1}\partial'\Phi(x)\right)=\mathscr{L}\left(\Phi(x),\partial\Phi(x)\right)
\end{equation}
     También lo podemos ver siguiendo el ejemplo anterior, pues podemos construir acciones invariantes, esto es así, pues hemos construido el Lagrangiano como invariante Lorentz,
    \begin{equation*}
        \mathscr{L}\left(M\Phi(x),M\Lambda^{-1}\partial\Phi(x)\right)=\mathscr{L}\left(\Phi(x),\partial\Phi(x)\right)
    \end{equation*}
    es decir, exigimos que todos los índices estén contraídos, por tanto, tendremos invariancia en todo el grupo de Poincaré, siempre que se cumpla la invariancia Lorentz.

    
    \subsection{Representaciones unitarias}
    Serán representaciones de dimensión infinita. Tomamos un espacio de Hilbert, $\mathscr{H}$, de dimensión infinita y queremos una representación del grupo de Poincaré que consista en asociar un operador lineal unitario del espacio de Hilbert con elementos del grupo de Poincaré, de la forma
    \begin{equation}
        U(N,a)
    \end{equation}
    donde $U$ es un operador unitario y $(N,a)$ son los elementos del grupo.\\ \\
    Tomando elementos de la forma,
    \begin{equation}
        U(I,a)=e^{-ia^{\mu}P_{\mu}}
    \end{equation}
    al ser $U$ unitario, entonces $P_{\mu}$ es hermítico, que representa el cuadrimomento, por lo que podremos formar un conjunto completo y así encontrar una base del operador momento.\\ \\
    Tomaremos una base generalizada, $\ket{p,\sigma}\in\mathscr{H}$, tal que los autoestados generalizados de $P_{\mu}$ cumplen que
    \begin{equation}
        P_{\mu}\ket{p,\sigma}=p_{\mu}\ket{p,\sigma}
    \end{equation}
    Sea 
    \begin{equation}
        V_p=\brackets{\curlybraces{\ket{p,\sigma},\sigma\in B}}
    \end{equation}
    el espacio de autovectores de $p$.
    \begin{note}
        Vamos a renombrar para que la notación sea más sencilla.
        \begin{itemize}
            \item $U(N,0)\equiv U(N)$, siendo el operador unitario asociado a las transformaciones de Lorentz.
            \item $\Lambda(N)=\Lambda$, siendo las matrices de Lorentz.
        \end{itemize}
    \end{note}
Podemos encontrar los autoestados de las transformaciones del grupo de Lorentz, tal que
\begin{equation}
    \begin{array}{rl}
        P^{\mu}U(N)\ket{p,\sigma} & =\overset{\mathds{1}}{\overbrace{U(N)U^{-1}(N)}}P^{\mu}U(N)\ket{p,\sigma}=\Lambda_{\nu}^{\mu}U(N)P^{\nu}\ket{p,\sigma}= \\
         & \Lambda_{\nu}^{\mu}U(N)p^{\nu}\ket{p,\sigma}=\Lambda_{\nu}^{\mu}p^{\nu}U(N)\ket{p,\sigma}
    \end{array}
\end{equation}
donde hemos usado que
\begin{equation}
    U^{-1}(N)P^{\mu}U(N)=\Lambda_{\nu}^{\mu}P^{\nu}
\end{equation}
que es una propiedad del grupo de traslaciones, pues tiene un subgrupo invariante, es decir, existen operaciones internas.\\ \\
Por tanto, los $U(N)\ket{p,\sigma}\in V_{\Lambda p}$, es decir, los autovalores de los estados $P^{\mu}U(N)\ket{p,\sigma}$ serán los $\Lambda_{\nu}^{\mu}p^{\nu}$.\\ \\
Queremos encontrar representaciones irreducibles. Para ello, usaremos los operadores de Casimir, que en el subespacio correspondiente serán multiplicados por la identidad. Sea el subespacio $V_{(M^2,s)}$, generado por $\ket{p,\sigma}$, tendremos los operadores de Casimir,
\begin{equation}
    P^2=P^{\mu}P_{\nu};\hspace{5mm}sign(H)=sign(P^0)
\end{equation}
El objetivo será encontrar una matriz diagonal por bloques que caracterice todo el espacio $\mathscr{H}$ y que los bloques sean irreducibles. En primer lugar, buscaremos los bloques formados por los operadores de Casimir.\\ \\
Los caracterizamos de la forma,
\begin{equation}
    P^2=P^{\mu}P_{\mu}\equiv M^2;\hspace{5mm}sign(H)=sign(P^0)\equiv s
\end{equation}
luego, el subespacio queda,
\begin{equation}
    V_{\left(M^2,s\right)}=\brackets{\curlybraces{\ket{p,\sigma}/p^2=M^2,sign(p^0)=s}}
\end{equation}
donde los corchetes significan que se trata de la envolvente lineal del espacio. Para cada uno de estos subespacios, se puede elegir un momento en particular con algún criterio, y lo denominaremos \textbf{momento estándar}, denotado por $k$, donde $k^2=M^2$ y $sign(k^0)=s$ si $M^2\geq0$. Todos los $p^2$ del espacio los podremos asociar con $k$ a través de las transformaciones de Lorentz, pues preservan la longitud. Así, $p=\Lambda(N)k$ ($N$ no es única, por lo que $\Lambda(N)$ tampoco será única) para algún $N\in SL(2,\mathbb{C})$. \\ \\
Además, para cada $p$ elegiremos una \textbf{transformación de Lorentz estándar} para ir de $p$ a $k$, denotado por $N=L(p\to k)$, dejando el estándar $k$ implícito, $L(p)$.\\ \\
Usaremos una notación simplificada, tal que $\Lambda(L(p))q:=L(p)q$, donde $q$ es un vector, luego $p=L(p)k$, y entonces tendremos que los autoestados se transforman como,
\begin{equation}
    \ket{p,\sigma}=\ket{L(p)k,\sigma}=U(L(p))\ket{k,\sigma}
\end{equation}
donde los $\sigma$ serán iguales por una elección de base, y los autoestados nuevos \\$U(L(p))\ket{k,\sigma}\in V_p$. \\ \\
Veamos la acción de un $U(N)$ genérico sobre $\ket{p,\sigma}$,
\begin{equation}
    \begin{array}{rl}
        U(N)\ket{p,\sigma} & =U(N)U(L(p))\ket{k,\sigma}=\overset{\mathds{1}}{\overbrace{U(L(\Lambda p))U^{-1}(L(\Lambda p))}}U(N)U(L(p))\ket{k,\sigma}= \\
         & =U(L(\Lambda p))U^{-1}\left(L(\Lambda p)^{-1}NL(p)\right)\ket{k,\sigma}
    \end{array}
\end{equation}
donde $L(\Lambda p)^{-1}NL(p)$ tiene una propiedad especial, pues si lo denotamos como
\begin{equation}
    W(N,p)=L(\Lambda p)^{-1}NL(p)
\end{equation}
entonces 
\begin{equation}
    \Lambda\left(W(N,p)\right)k=\left(\Lambda\left(L(\Lambda/N)p\right)^{-1}\Lambda(N)p\right)k=k
\end{equation}
por lo que se trata de una transformación de Lorentz que deja $k$ invariante, pues\\ $L(k\to q)^{-1}=L(q\to k)$.
\begin{definition}
    El conjunto de todos los elementos de $SL(2,\mathbb{C})$ que dejan invariante un vector $a$ se denomina el grupo estable de $a$, o bien, el \textbf{little group} de $a$, lo denotamos como $\mathcal{L}_a$.
\end{definition}
    En nuestro caso, el \textit{little group} será el grupo que deje invariante $k$, denotado por $\mathcal{L}_k$, que como hemos visto antes, $W(N,p)\in\mathcal{L}_k$. Ahora queremos encontrar las representaciones irreducibles de $\mathcal{L}_k$; una vez encontradas sabremos cómo actúa $U(W(N,p))$ y podremos encontrar la representación del grupo completo. Este método se conoce como \textit{método de las representaciones inducidas}.\\ \\
    Por tanto,
    \begin{equation}
        U(N)\ket{p,\sigma}=U(L(p))U^{-1}(W(N,p))\ket{k,\sigma}
    \end{equation}
con $W\in\mathcal{L}_k$, tal que
\begin{equation}
    U(W)\ket{k,\sigma}=\sum_{\sigma'}D_{\sigma'\sigma}(W)\ket{k,\sigma'}
\end{equation}
donde $U(W)$ será un operador lineal unitario y $D_{\sigma'\sigma}$ serán las matrices que formen una representación de $\mathcal{L}_k$. Uniendo todo,
\begin{equation}
    U(N)\ket{p,\sigma}=\sum_{\sigma'}D_{\sigma'\sigma}(W(N,p))U(L(\Lambda p))\ket{k,\sigma'}=\sum_{\sigma'}D_{\sigma'\sigma}(W(N,p))\ket{\Lambda p,\sigma'}
\end{equation}
    Para una transformación de Poincaré inhomogénea, $a\neq0$, tenemos
\begin{tcolorbox}[title=Representaciones unitarias generales]
    \begin{equation}
        U(N,a)\ket{p,\sigma}=e^{ia_{\mu}\Lambda_{\nu}^{\mu}(N)P^{\nu}}\sum_{\sigma'}D_{\sigma'\sigma}\left(W(N,p)\right)\ket{\Lambda p,\sigma'}
    \end{equation}
    donde la exponencial representa la traslación con $a$.
\end{tcolorbox}
Hemos usado que las traslaciones forman un grupo abeliano, por lo que los generadores pueden diagonalizarse simultáneamente. También, el subgrupo de traslaciones es normal, entonces
\begin{equation}
    U(N)^{-1}e^{-iaP}U(N)=e^{-ia'P}\hspace{3mm}\textbf{ y }\hspace{3mm}U(N)^{-1}PU(N)=\Lambda P
\end{equation}
Para especificar esta representación deberemos saber la forma de las matrices $D_{\sigma'\sigma}(W)$. Como queremos que las representaciones sean unitarias, una condición será que las matrices $D_{\sigma'\sigma}(W)$ sean unitarias. Realmente, en una notación compacta, con un vector $\ket{p}$ con componentes $\ket{p,\sigma}$, tenemos,

\begin{equation}
    \Braket{p_2|U^{\dagger}U|p_1}=\Braket{\Lambda p_2|M^{\dagger}M|\Lambda p_1}; \hspace{2mm}\forall p_1,p_2
\end{equation}
donde $\Braket{\Lambda p_2|\Lambda p_1}=\Braket{p_2|p_1}$ si tomamos un producto interno invariante Lorentz en el espacio de Hilbert.\\ \\
Además, esto es irreducible si y solo si las matrices $D(W)$ forman una representación irreducible del \textit{little group}. Entonces, para encontrar representaciones irreducibles unitarias inducidas del grupo de Poincaré bastará con encontrar las representaciones irreducibles unitarias del \textit{little group} $\mathcal{L}_k$.\\ \\
El \textit{little group} de $V_{(M^2,a)}$ dependerá sobre si $M^2$ es positivo, nulo o negativo y, para las $M^2$ no negativas, sobre si $s$ es positiva, negativa o cero. Tenemos varios casos:\\ \\
Podremos tomar cualquier momento de referencia, pero tomaremos aquel en el que las partículas estén en reposo, tal que
\begin{itemize}
    \item $\mathbf{M^2>0;\hspace{2mm}s>0}$: Tomaremos $k=(M,0,0,0)$. El \textit{little group} será el recubrimiento universal de $SO(3)$, es decir, $\overline{SO(3)}$.
    \item $\mathbf{M^2>0;\hspace{2mm}s<0}$: Tomaremos $k=(-M,0,0,0)$, con $M=\sqrt{|M^2|}$. El \textit{little group} será el recubrimiento universal de $SO(3)$, es decir, $\overline{SO(3)}$.
    \item $\mathbf{M^2=0;\hspace{2mm}s>0}$: Tomaremos $k=(E,0,0,E)$, con $E>0$. El \textit{little group} será el recubrimiento universal de $ISO(2)$, es decir, $\overline{ISO(2)}$.
    \item $\mathbf{M^2=0;\hspace{2mm}s<0}$: Tomaremos $k=(-E,0,0,E)$, con $E>0$. El \textit{little group} será el recubrimiento universal de $ISO(2)$, es decir, $\overline{ISO(2)}$.
    \item $\mathbf{M^2<0}$: Tomaremos $k=(0,0,0,M)$. El \textit{little group} será el recubrimiento universal de $SO(1,2)$, es decir, $\overline{SO(1,2)}$.
    \item $\mathbf{M^2=0;\hspace{2mm}s=0}$: Que será la trivial, con $p=(0,0,0,0)$, luego, tomaremos $k=(0,0,0,0)$. El \textit{little group} será el recubrimiento universal de $SO(1,3)$, es decir, $\overline{SO(1,3)}$.
\end{itemize}
Cuando interpretamos estas representaciones físicamente, es decir, las pasamos a estados de partículas, vemos que la $M$ representa la \textbf{masa} de las partículas, $p$ representa el \textbf{cuadrimomento} de las partículas y $s$ es la \textbf{energía}. Por tanto, los casos con $s<0$ representan estados con energía negativa, cosa que no se da en la naturaleza, luego no los estudiaremos, pues dan lugar a Hamiltonianos no acotados. El caso de $M^2<0$ representa estados de partículas con masa negativa, llamadas \textit{taquiones}, que presentan problemas en la causalidad pues viajan temporalmente, por lo que no las estudiaremos. El caso con $M^2>0$ y $s>0$ representa estados de partículas con masa positiva y energía positiva, cosa que sí se da en la naturaleza, por lo que sí lo estudiaremos. Otro caso que estudiaremos será el de $M^2=0$ y $s>0$, pues representa a los \textit{fotones}, que sí existen. Además, el caso $M^2=0$ y $s=0$ también lo estudiaremos, pues representa el vacío.\\ \\
Antes de estudiar estos casos, veamos una relación entre el vector de Pauli-Lubanski $W_{\mu}$ y el \textit{little group} $\mathcal{L}_k$ para $k\neq0$. Sea $W_{\mu}^{(k)}$ una restricción de $W_{\mu}$, tratada como un operador sobre el espacio de Hilbert, de $V_k$. Como $\left.P_{\mu}\right|_{V_k}=k_{\mu}\mathds{1}$, entonces
\begin{equation}
    W_{\mu}^{(k)}=\frac{1}
    {2}\epsilon_{\mu\nu\rho\sigma}J^{\nu\rho}k^{\sigma}
\end{equation}
con $k^{\mu}W_{\mu}^{(k)}=0$. La segunda identidad implica que $W_{\mu}^{(k)}$ tiene tres componentes independientes. De $\brackets{W_{\mu},P_{\mu}}=0$ tenemos que
\begin{equation}
    P_{\nu}W_{\mu}^{(k)}\ket{k,\sigma}=W_{\mu}^{(k)}P_{\nu}\ket{k,\sigma}=k_{\nu}W_{\mu}^{(k)}=\ket{k,\sigma}
\end{equation}
Entonces, $W_{\mu}^{(k)}\ket{k,\sigma}\in V_k$. Junto con la primera identidad anterior, esto implica que $W_{\mu}^{(k)}$ pertenece al álgebra del \textit{little group}. Las tres componentes independientes proporcionan una base de esto. Esto es consistente con la dimensionalidad del \textit{little group}, que es tres para todos los casos, excepto el último caso, que $W^{(k)}_{\mu}=0$.\\ \\
Los Casimir $W_{\mu}^{(k)}W^{(k)\mu}$ se pueden usar para clasificar representaciones irreducibles de $\mathcal{L}_k$ (en algunos casos, no completamente).\\ \\
Nos centraremos en encontrar las matrices $W$, pues representan las $D_{\sigma'\sigma}(W)$.
Comenzamos con los casos de $s>0$:
\begin{itemize}
    \item \textbf{$M^2>0$}: Sabemos que $k=(M,0,0,0)$, luego solo tenemos la componente $k^0=M$ distinta de cero. Luego,
    \begin{equation}
        k_{\alpha\dot{\alpha}}=k_{\mu}\sigma_{\alpha\dot{\alpha}}^{\mu}=M\sigma_{\alpha\dot{\alpha}}^0\Rightarrow k=M\mathds{1}
    \end{equation}
    O bien,
    \begin{equation}
        \hat{k}=k^{\mu}\sigma_{\mu}=k^0\sigma_0=M\sigma_0=M\cdot\mathds{1}_{2\times2}
    \end{equation}
    Las transformaciones $W\in LS(2,\mathbb{C})$ actúan sobre $\hat{k}$ de la forma $W\hat{k}W^{\dagger}$, donde $W\in\mathcal{L}_k$ si y solo si,
    \begin{equation}
        W\hat{k}W^{\dagger}=\hat{k}\Rightarrow W\cancel{M}\mathds{1}W^{\dagger}=\cancel{M}\mathds{1}\Rightarrow WW^{\dagger}=\mathds{1}
    \end{equation}
    Además, por la condición de unitariedad, tenemos que $detW=1$. Por tanto, tendremos que $\mathcal{L}_k=SU(2)$. Las representaciones irreducibles son las que ya nos son familiares y pueden ser etiquetadas por el spín $j=\curlybraces{0,\frac{1}{2},2,\frac{3}{2},2,\dots}$, que es uno de los recubrimientos universales de $SO(3)$. Los elementos de la base de las representaciones irreducibles de spín $j$ serán,
    \begin{equation}
        \brackets{\curlybraces{\ket{p,\sigma}_j\text{ con }p^2=M^2,p^0>0,\sigma\in\curlybraces{-j,-j+1,\dots,j-1,j}}}
    \end{equation}
    siendo el grupo que hemos visto en Mecánica Cuántica. 
    \item \textbf{$M^2=0$}: Sabemos que $k=(E,0,0,E)$ con $E>0$, luego las componentes no triviales de $k$ son $k^0=k^3=E$, por tanto,
    \begin{equation}
        \hat{k}=k^{\mu}\sigma_{\mu}=k^0\sigma_0+k^{3}\sigma_{3}=E\mathds{1}+E\begin{pmatrix}
            1 & 0\\
            0 & -1
        \end{pmatrix}=2E\begin{pmatrix}
            1 & 0\\
            0 & 0
        \end{pmatrix}
    \end{equation}
    Queremos ver los $W$ que dejan invariante $W\hat{k}W^{\dagger}=\hat{k}$. Esta solución será,
    \begin{equation}
        W=\begin{pmatrix}
            e^{i\varphi/2} & \omega\\
            0 & e^{-i\varphi/2}
        \end{pmatrix}
    \end{equation}
    con $\varphi\in[0,4\pi)$ y $\omega\in\mathbb{C}$; donde hemos usado la condición $detW=1$. Las matrices de esta forma formarán el \textit{little group}. Tendremos dos subgrupos:
    \begin{equation}
        R(\varphi)=\begin{pmatrix}
            e^{i\varphi/2} & 0\\
            0 & e^{-i\varphi/2}
        \end{pmatrix};\hspace{7mm}T(\omega)=\begin{pmatrix}
            0 & \omega\\
            0 & 0
        \end{pmatrix}
        \end{equation}
    donde $R(\varphi)$ es isomorfo con las rotaciones euclídeas de $U(1)$, formando un subgrupo abeliano, y $T(\omega)$ es isomorfo a las traslaciones euclídeas, formando un subgrupo abeliano invariante. Cualquier $W\in\mathcal{L}_k$ puede escribirse de la forma,
    \begin{equation}
        R(\varphi)T\left(e^{-i\varphi}\omega\right)=R(\varphi)T(\omega')
    \end{equation}
    El grupo $\mathcal{L}_k$ es isomorfo al espacio recubridor de $ISO(2)$.\\ \\
    Como $T(\omega)$ son 'traslaciones', usamos el método anterior y buscamos los autovectores de $T(\omega)$ para encontrar la base. Así, sea $S$ una representación unitaria de $\mathcal{L}_k$ y tomamos una base $\curlybraces{\ket{\alpha}}$, tal que
    \begin{equation}
        S(T(\omega))\ket{\alpha}=e^{-\frac{i}{2}\left(\omega\alpha+\omega^*\alpha^*\right)}=e^{-iRe(\omega\alpha)}\ket{\alpha}
    \end{equation}
    donde $T(\omega)$ forma un subgrupo abeliano. Una vez definido $S(T(\omega))$, debemos ver cómo actúa $S$ sobre $R(\varphi)$, luego
    \begin{equation}
        \begin{array}{rlll}
            S(R(\varphi))\ket{\alpha} &\Rightarrow &T(\omega)\brackets{S(R(\varphi))\ket{\alpha}}&=S(T(\omega)R(\varphi))\ket{\alpha}=S(R(\varphi)R^{-1}(\varphi)T(\omega)R(\varphi))\ket{\alpha}=  \\ \\
             & & & =S(R(\varphi)T\left(e^{-i\varphi}\omega\right))\ket{\alpha}=S(R(\varphi))S(T\left(e^{-i\varphi}\omega\right))\ket{\alpha}=\\ \\
             &&&=e^{-iRe\left(\omega e^{-i\varphi}\alpha\right)}S(R(\varphi))\ket{\alpha}
        \end{array}
    \end{equation}
    Vemos que $S(R(\varphi))\ket{\alpha}$ serán los vectores propios con autovalor $e^{i\omega e^{-i\varphi}\alpha}$ + ctes. Asumiendo que los autovalores $\alpha$ son no degenerados, tenemos que,
    \begin{equation}
        S(R(\varphi))\ket{\alpha}=C(\varphi)\ket{e^{-i\varphi}\alpha}
    \end{equation}
    con $C\in\mathbb{C}$.\\ \\
    La unitariedad de $S$ y de $S(R(\varphi))$, siendo una representación, implica que $C(\varphi)=e^{ih\varphi}$. Además, la condición de contorno $R(4\pi)=1$ requiere que $2h\in\mathbb{Z}$, luego, tenemos una cuantización con $h$.\\ \\
    Como solo sabemos una condición para $h$, para distintos $h$ tendremos distintas representaciones y denominamos a $h$ la \textbf{helicidad de la representación}.\\ \\
    Además, vemos que bajo estas transformaciones, $|\alpha|$ queda invariante, pues\\
    $-W_{\mu}W^{\mu}=E^2p^2$, con $|\alpha|=\rho\geq0$. Por lo que tendremos dos tipos de representaciones:
    \begin{itemize}
        \item $\mathbf{\rho>0:}$\\ \\
        Tenemos una representación de dimensión infinita. Puede entenderse como \textit{partículas con un continuo de valores de spín, denominadas partículas de spín continuo}, este tipo de partículas no se aprecia en la naturaleza, por lo que no las estudiaremos. (Ahora se está investigando sobre esto).
        \item $\mathbf{\rho=0:}$\\ \\
        En este caso, todos los vectores en la representación son proporcionales a $\ket{0}$, entonces formarán una representación unidimensional, la cuál es irreducible para cualquier $h$, tal que
        \begin{equation}
            S^{(h)}\left(T(\omega)\right)\ket{0}=\ket{0};\hspace{4mm}S^{(h)}\left(R(\varphi)\right)\ket{0}=e^{ih\varphi}\ket{0};\hspace{4mm}2h\in\mathbb{Z}
        \end{equation}
        Como $S^{(h)}\left(T(\omega)\right)$ actúa trivialmente, $\mathcal{L}_k$ será efectivamente $U(1)$, el grupo de las rotaciones bidimensionales, que puede pensarse como el \textit{little group} de $\alpha=0$ y es abeliano. Todas las representaciones irreducibles finitas de grupos abelianos son unidimensionales. Entonces el $\alpha$ deberá ser no degenerado, como asumimos.\\ \\
        Por lo que la helicidad $h$ será importante. Tenemos representaciones universales que etiquetamos con la helicidad, cosa que le cambia la fase al vector $S(R(\varphi))\ket{\alpha}$. \\ \\
        La $h$ servirá para clasificar las partículas. Tendremos dos tipos de fotones, aquellos con $h=+1$ y $h=-1$.\\ \\
        Como tenemos que $k=(E,0,0,E)$, estamos haciendo rotaciones alrededor del eje $z$, luego el generador de estas rotaciones será $J_3$, de forma que, en esta representación, $J_3\ket{\alpha}=h\ket{\alpha}$. En general, si tenemos una rotación cualquiera,
        \begin{equation}
            \frac{\vec{J}\cdot\vec{k}}{|\vec{k}|}\ket{\alpha}=h\ket{\alpha}
        \end{equation}
        Físicamente la helicidad se entiende como $\vec{J}\cdot\vec{k}/|\vec{k}|$.\\ \\
        Como no podemos llegar al reposo las partículas sin masa, pues son fotones, trabajamos con el formalismo de la helicidad, pues el spín dará problemas.
    \end{itemize}
\end{itemize}

\begin{tcolorbox}[width=1.12\textwidth, title=En resumen:]
    \begin{itemize}
        \item $\mathbf{M^2>0,s>0}$\\ \\
        El espacio será,
        \begin{equation}
            V_{[M^2,j]}=\brackets{\curlybraces{\ket{p,\sigma}_j;p^2=M^2,p^0>0,\sigma\in\curlybraces{-j,-j+1,\dots,j-1,j}}};\hspace{4mm}j\in\curlybraces{0,\frac{1}{2},1,\frac{3}{2},2,\dots}
        \end{equation}
        Los elementos del grupo transformarán como,
        \begin{equation}
            U^{[m^2,j]}(N,a)\ket{p,\sigma}_j=e^{-ia_{\mu}\Lambda_{\nu}^{\mu}(N)P^{\nu}}\sum_{\sigma'}D^{(j)}_{\sigma\sigma'}\left(W(N,p)\right)\ket{\Lambda p,\sigma'}_j
        \end{equation}
        \item $\mathbf{M^2=0,s>0}$\\ \\
        El espacio será,
        \begin{equation}
            V_{[0,h]}=\brackets{\curlybraces{\ket{p}_h;p^2=0,p^0>0}}
        \end{equation}
        Los elementos del grupo transformarán como,
        \begin{equation}
            U^{[0,h]}(N,a)\ket{p}_h=e^{-a_{\mu}\Lambda_{\nu}^{\mu}(N)P^{\nu}}e^{ih\varphi}\ket{\Lambda(N)p}_h
        \end{equation}
        donde $\varphi$ dependerá del momento y del eje de giro.
    \end{itemize}
\end{tcolorbox}
Para completar la discusión, veamos la relación de estas representaciones irreducibles con el vector de Pauli-Lubanski, en ambos casos:
\begin{itemize}
    \item Para $\mathbf{M^2>0}$ tenemos $k=(M,0,0,0)$. Luego,
    \begin{equation}
        W_{\mu}^{(h)}=\frac{1}{2}\epsilon_{\mu\nu\rho\sigma}J^{\nu\rho}k^{\sigma}=\frac{M}{2}\epsilon_{\mu\nu\rho\sigma}J^{\nu\rho}=\left\lbrace\begin{matrix}
              0, & \mu=0 \\
            MJ_i, & \mu=i\in\curlybraces{1,2,3}
        \end{matrix}\right.
    \end{equation}
    Vemos que $W_i^{(h)}$ son los generadores de $\mathcal{L}_k=SU(2)$, y el casimir $-W_{\mu}W^{\mu}$ es esencialmente igual a $J^2$ de $\mathcal{L}_k$ y etiqueta las representaciones irreducibles,
    \begin{equation}
        -W_{\mu}W^{\mu}\ket{p,\sigma}_j=M^2j(j+1)\ket{p,\sigma}_j
    \end{equation}
    \item Para $\mathbf{M^2=0}$ tenemos $k=(E,0,0,E)$. Luego,
    \begin{equation}
        W_{\mu}^{(h)}=\frac{1}{2}\epsilon_{\mu\nu\rho\sigma}J^{\nu\rho}k^{\sigma}=\frac{E}{2}\epsilon_{\mu\nu\rho0}J^{\nu\rho}-\frac{E}{2}\epsilon_{\mu\nu\rho3}J^{\nu\rho}
    \end{equation}
    Por tanto,
    \begin{equation}
        W_0^{(h)}=-EJ_3;\hspace{4mm}W_1^{(h)}=E(J_1+K_2);\hspace{4mm}W_2^{(h)}=E(-J_2+K_1);\hspace{4mm}W_3^{(h)}=EJ_3
    \end{equation}
    Podemos usar $\curlybraces{T_1,T_2,J_3}$ como una base del álgebra de $\mathcal{L}_{k_3}$ con 
    \begin{equation}
        T_{1,2}=\frac{1}{E}W_{1,2}^{(h)}
    \end{equation}
    Tendremos las reglas de conmutación,
    \begin{equation}
        \brackets{T_1,T_2}=0;\hspace{4mm}\brackets{J_3,T_1}=-iT_2;\hspace{4mm}\brackets{J_3,T_2}=iT_1
    \end{equation}
    Usando la representación definida por las matrices de Pauli de $SL(2,\mathbb{C})$, vemos que
    \begin{equation}
        T_1\doteq\frac{\sigma_1}{2}+i\frac{\sigma_2}{2}=\begin{pmatrix}
            0 & 1\\
            0 & 0
        \end{pmatrix};\hspace{4mm}T_2\doteq iT_1\doteq\begin{pmatrix}
            0 & i\\
            0 & 0
        \end{pmatrix}
    \end{equation}
    Por lo que $T_1$ y $T_2$ son los generadores de las traslaciones $T(\omega)$, mientras que $J_3$ es el generador de las rotaciones $R(\varphi)$. Así,
    \begin{equation}
        \begin{array}{l}
             \brackets{\mathds{1}-i\omega_1\tilde{S}(T_1)-i\omega_2\tilde{S}(T_2)}\ket{\alpha}=S\left(\mathds{1}-i\omega_1T_1-i\omega_2T_2\right)\ket{\alpha}=  \\ \\
            =S\left(T(\omega_2-i\omega_1)\right)\ket{\alpha}=e^{-\frac{i}{2}\brackets{(\omega_2-i\omega_1)\alpha+(\omega_2+i\omega_1)\alpha^*}}\ket{\alpha}=   \\ \\
            =\left(1-i\omega_2Re(\alpha)-i\omega_1Im(\alpha)\right)\ket{\alpha}
        \end{array}
    \end{equation}
    Por comparación, vemos que
    \begin{equation}
        \tilde{S}(T_1)\ket{\alpha}=Im(\alpha)\ket{\alpha};\hspace{4mm}\tilde{S}(T_2)\ket{\alpha}=Re(\alpha)\ket{\alpha}
    \end{equation}
    El operador de Casimir $-W_{\mu}W^{\mu}$ restringido a $V_k$ es
    \begin{equation}
        -W_{\mu}^{(k)}W^{(k)\mu}=E^2(T_1^2+T_2^2)
    \end{equation}
    Por lo que,
    \begin{equation}
        -\tilde{S}\left(W_{\mu}^{(k)}\right)\tilde{S}\left(W^{(k)\mu}\right)\ket{\alpha}=E^2|\alpha|^2\ket{\alpha}
    \end{equation}
    Entonces, los vectores en la representación $\rho$ son los autovectores del operador de Casimir $-\tilde{S}\left(W_{\mu}^{(k)}\right)\tilde{S}\left(W^{(k)\mu}\right)$ con autovalores $\bar{\rho}^2=E^2\rho^2$.\\ \\
    A causa de que $-W_{\mu}W^{\mu}$ sea un operador de Casimir de Poincaré, también tenemos que
    \begin{equation}
        \tilde{U}^{(\rho,k)}\left(-W_{\mu}W^{\mu}\right)\ket{p,\alpha}=\bar{\rho}^2\ket{p,\alpha}
    \end{equation}
    por lo que $\bar{\rho}$, que tiene dimensión (algo), es un mejor clasificador para las representaciones irreducibles. Notemos también que
    \begin{equation}
        \tilde{U}^{(0,h)}(J_3)\ket{p}=h\ket{p}
    \end{equation}
\end{itemize}
\begin{tcolorbox}[title=RESUMEN]
    Las representaciones unitarias irreducibles no triviales con interés físico del grupo de Poincaré actúan en el espacio de Hilbert $V_{\brackets{M^2,\tau}}$, cuya base generalizada es
    \begin{equation}
        \curlybraces{\ket{p,\sigma};p^2=M^2\geq0,p^0>0,\sigma\in B_{\tau}}
    \end{equation}
    con
    \begin{equation}
        U^{\brackets{M^2,\tau}}(N,a)\ket{p,\sigma}=e^{-ia_{\mu}\Lambda_{\nu}^{\mu}P^{\nu}}\sum_{\sigma'}D^{(\tau)}_{\sigma'\sigma}\left(W(N,p)\right)\ket{\Lambda p,\sigma'}
    \end{equation}
donde
\begin{itemize}
    \item Para $M^2>0$, tenemos que $\tau=j\in\curlybraces{0,\frac{1}{2},1,\frac{3}{2},\dots}$,\\ con $B_j=\curlybraces{-j,-j+1,\dots,j-1,j}$, y las $D^{(j)}_{\sigma'\sigma}$ son las matrices estándar de rotación de spín $j$.
    \item Para $M^2=0$ con $\tau=(0,h):=h$,$2h\in\mathbb{Z}$, tenemos que $B_h=\curlybraces{0}$, unidimensional. Además, $D^{(h)}\left(T(\omega)\right)=1$ y $D^{(h)}\left(R_{\hat{k}}(\varphi)\right)=e^{ih\varphi}$.
    \item Para $M^2=0$ con $\tau=(\rho,h)$, $\rho\in\mathbb{R}^+$, $h\in\curlybraces{0,\frac{1}{2}}$; tenemos que \\$B_{(\rho,h)}=\curlybraces{\Theta\in\brackets{0,2\pi}}$. Además,
    \begin{equation}
        \begin{matrix}
            D^{(\rho,h)}\left(T(\omega)\right)\ket{k,\Theta}=e^{-i\rho Re\left(\omega e^{i\Theta}\right)}\ket{k,\Theta}\\ \\
            D^{(\rho,h)}\left(R_{\hat{k}}(\varphi)\right)\ket{k,\Theta}=e^{ik\varphi}\ket{k,\Theta-\varphi}
        \end{matrix}
    \end{equation}
\end{itemize}
De hecho, estas últimas representaciones no existen en nuestra descripción de la naturaleza, por lo que no las usaremos en este curso.
    
\end{tcolorbox}
\includepdf[pages=-]{Entregable2_QFT.pdf}
\chapter{Partículas}
\section{Estados de una partícula}
Usamos la representación irreducible unitaria $(N,a)$ descrita en el capítulo anterior.
\begin{definition}
    Definimos una \textbf{partícula} como un subsistema que puede estar en cualquier estado asociado a un subespacio invariante de una representación irreducible.
\end{definition}
Tomamos la aplicación,
\begin{equation}
    e_n:(N,a)\to U(N,a)|_{V_n}
\end{equation}
donde el $n$ es una etiqueta de la partícula. Además, $V_n=V_{[M^2,j/h,\dots]}$, donde los $\dots$ indicarán información extra referente a la partícula. Podemos tomar una base generalizada de $V_n$ tal que,
\begin{equation}
    \curlybraces{\ket{p,\sigma,n};P^0>0,P^2=M^2,\sigma=\curlybraces{-j,-j+1,\dots,j-1,j}}
\end{equation}
También podremos nombrar a $\ket{p,\sigma,n}\equiv\ket{p,\sigma}_n$. Cabe recalcar que para partículas sin masa, $\sigma$ solo toma un valor, por lo que lo ignoramos. Para englobar los dos casos que nos interesan hacemos,
\begin{equation}
    m_n^2=P^2=(P^0)^2-(P^i)^2\Rightarrow P^0=\omega_{\vec{P}}=\sqrt{\vec{P}^2+m^2}\equiv\omega_P
\end{equation}
donde hemos renombrado $\omega_{\vec{P}}\equiv\omega_P$ por notación; además, $\vec{P}$ corresponde con las componentes espaciales.\\ \\
Entonces, podemos escribir indistintamente $\ket{p,\sigma,n}=\ket{\vec{p},\sigma,n}$, pues $\vec{P}$ y $P^0$ están relacionados. Además, usaremos $\ket{\vec{p},\sigma,n}$ que es más cómoda. Normalizamos,
\begin{equation}
    \Braket{\vec{p},\sigma,n|\vec{q},\tau,n'}=2\omega_P(2\pi)^3\delta_{\sigma\tau}\delta^{(3)}(\vec{p}-\vec{q})\delta_{nn'}
\end{equation}
siendo una normalización relativista. Reescribiéndolo,
\begin{equation}
    \Braket{k|k'}=\tilde{\delta}(k-k')
\end{equation}
con $k=(\vec{p},\sigma,n)$ y $\tilde{\delta}(k-k')=2\omega_P(2\pi)^3\delta_{\sigma\tau}\delta^{(3)}(\vec{p}-\vec{q})\delta_{nn'}$.\\ \\
Hacemos la normalización relativista porque da lugar a la invariancia de Lorentz.
\subsection{Relación de completitud}
La relación de completitud, al igual que en Mecánica Cuántica, la podemos definir a partir de la identidad usando los elementos de la base, tal que
\begin{equation}
    \mathds{1}_{(n)}=\sum_{\sigma=-j}^j\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_P}\ket{\vec{p},\sigma,n}\bra{\vec{p},\sigma,n}
\end{equation}
con esto, podemos escribir cualquier estado $\ket{\psi}\in V_n$, de la forma
\begin{equation}
    \ket{\psi}=\sum_{\sigma=-j}^j\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_P}\ket{\vec{p},\sigma,n}\Braket{\vec{p},\sigma,n|\psi}=\sum_{\sigma=-j}^j\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_P}\hat{\psi}_{\sigma}(\vec{p})\ket{\vec{p},\sigma,n}
\end{equation}
Típicamente, a los físicos nos interesa la evolución temporal de un sistema. Por definición, la evolución temporal está contenida en el grupo de Poincaré. Es decir, los estados anteriormente descritos son autoestados del operador de evolución temporal. Esto puede entenderse de manera intuitiva si observamos que dicho operador está relacionado con la simetría temporal de Lorentz, específicamente con los boosts temporales. Al ser una simetría de Lorentz, también forma parte del grupo de Poincaré. Por lo tanto, los estados de cualquier subespacio de $SL(2,\mathbb{C})$ respetan esta simetría y, en consecuencia, son autoestados del operador de evolución temporal.
\section{Estado de varias partículas}
Definimos el espacio de Hilbert donde trabajamos,
\begin{equation}
    \mathscr{H}_{(n)}=\mathscr{H}_{n_1}\otimes\mathscr{H}_{n_2}\otimes\dots\otimes\mathscr{H}_{n_N}=V_{n_1}\otimes V_{n_2}\otimes\dots\otimes V_{n_N}
\end{equation}
que abarca todos los vectores y sus combinaciones lineales, con $[n]=\curlybraces{n_1,n_2,\dots,n_N}$. Tomamos una base generalizada del espacio de Hilbert, que será
\begin{equation}
    \curlybraces{\ket{p_1,\sigma_1,n_1}\otimes\ket{p_2,\sigma_2,n_2}\otimes\dots\otimes\ket{p_N,\sigma_N,n_N}}=\curlybraces{\ket{p_1,\sigma_1,n_1}\ket{p_2,\sigma_2,n_2}\dots\ket{p_N,\sigma_N,n_N}}
\end{equation}
\begin{note}
Cuando un estado puede escribirse como un producto de estados pertenecientes a subespacios independientes, diremos que se trata de un \textbf{estado puro}. Es decir, si el estado que estamos estudiando no requiere una combinación (mezcla) de espacios de Hilbert monoparticulares, entonces estamos ante un estado puro. En cambio, si el estado que estamos estudiando no puede describirse como un producto de estados monoparticulares y requiere, en cambio, una combinación lineal o estadística de ellos, hablaremos de un \textbf{estado mezcla}. Es decir, el estado no pertenece a un único subespacio de Hilbert, sino que implica una mezcla (estadística o cuántica) de varios subespacios monoparticulares.
\end{note}
Podemos ver como actúan los elementos de la representación $U(N,a)$ sobre los elementos de esta base, tal que
\begin{equation}
    \begin{array}{l}
        U(N,a)\left(\ket{p_1,\sigma_1,n_1}\ket{p_2,\sigma_2,n_2}\dots\ket{p_N,\sigma_N,n_N}\right)  = \\ \\
          =\sum\limits_{\sigma'_1=-j_{n_1}}^{j_{n_1}}\sum\limits_{\sigma'_2=-j_{n_2}}^{j_{n_2}}\dots\sum\limits_{\sigma'_N=-j_{n_N}}^{j_{n_N}}D^{(j_{n_1})}_{\sigma_1'\sigma_1}\left(W(N,p_1)\right)D^{(j_{n_2})}_{\sigma_2'\sigma_2}\left(W(N,p_2)\right)\dots D^{(j_{n_N})}_{\sigma_N'\sigma_N}\left(W(N,p_N)\right)\cdot\\ \\
          \cdot \exp\left(-i\left[\sum\limits_{i=1}^N\Lambda(N)_{\nu}^{\mu}p_i^{\nu}\right]a_{\mu}\right)\ket{\Lambda(N)p_1,\sigma_1',n_1}\ket{\Lambda(N)p_2,\sigma_2',n_2}\dots\ket{\Lambda(N)p_N,\sigma_N',n_N}
    \end{array}
\end{equation}
Es decir, el operador $U$ poliparticular puede descomponerse en operadores $U^{(n_i)}$ monoparticulares, tal que
\begin{equation}
    U=U^{(n_1)}\otimes U^{(n_2)}\otimes\dots\otimes U^{(n_N)}
\end{equation}
Podemos obtener los autovalores de $P$ en esta base, pues al ser $P$ autoestado de los elementos de la base de forma individual, de forma global también será autoestado, tal que
\begin{equation}
    P\left(\ket{p_1,\sigma_1,n_1}\ket{p_2,\sigma_2,n_2}\dots\ket{p_N,\sigma_N,n_N}\right)=\left(\sum_{i=1}^Np_i\right)\left(\ket{p_1,\sigma_1,n_1}\ket{p_2,\sigma_2,n_2}\dots\ket{p_N,\sigma_N,n_N}\right)
\end{equation}
Cuando tengamos un operador $H$ que cumpla que 
\begin{equation}
    H\left(\ket{p_1,\sigma_1,n_1}\ket{p_2,\sigma_2,n_2}\dots\ket{p_N,\sigma_N,n_N}\right)=\left(\sum_{i=1}^N\omega_i\right)\left(\ket{p_1,\sigma_1,n_1}\ket{p_2,\sigma_2,n_2}\dots\ket{p_N,\sigma_N,n_N}\right)
\end{equation}
diremos que estamos en un sistema de \textbf{partículas libres}. Esto se debe a que el operador cumple que
\begin{equation}
    H=\sum_{i=1}^N\tilde{H}_i,\hspace{4mm}\text{con }\tilde{H}_i=\mathds{1}\otimes\mathds{1}\otimes\dots\otimes \tilde{H}_i\otimes\mathds{1}\otimes\dots\otimes\mathds{1}
\end{equation}
Por tanto, tendremos que las partículas no interaccionan entre sí.\\ \\
Este no será siempre el caso, pues sabemos que las partículas se afectan unas a otras.
\section{Teoría libre. Espacio de Fock}
Definimos $H_0$ como un Hamiltoniano libre, que usaremos para construir los sistemas de partículas, como primera aproximación.
\begin{definition}
    El espacio de Fock es el espacio de Hilbert preparado como suma directa de los productos tensoriales de los espacios de Hilbert de una partícula, tal que
    \begin{equation}
        \mathscr{F}_{\nu}(\mathscr{H})=\bigoplus_{n=0}^{\infty}S_{\nu}^{(n)}\mathscr{H}^{\otimes n}=\mathbb{C}\oplus\mathscr{H}\oplus S_{\nu}^{(2)}(\mathscr{H}\otimes\mathscr{H})\oplus S_{\nu}^{(3)}(\mathscr{H}\otimes\mathscr{H}\otimes\mathscr{H})\oplus\dots
    \end{equation}
    donde $S_{\nu}$ es el operador que simetriza (o antisimetriza) el espacio, de forma que el espacio de Fock describa adecuadamente a un conjunto de \textbf{bosonoes}, $\nu=+$ (o \textbf{fermiones, $\nu=-$}). $\mathscr{H}$ es el espacio de Hilbert para una sola partícula.
\end{definition}
En el espacio de Fock viven los operadores de creación y destrucción, que tienen que ver con los bosones y fermiones.\\ \\
Hemos definido los estados poliparticulares, pero nos falta introducir las partículas idénticas e indistinguibles. Al introducir este concepto, tendremos simetrías bajo intercambio, es decir, las permutaciones de partículas conducirán a nuevas simetrías.\\ \\
Denominamos $\ket{q_1\dots q_N}$ al estado poliparticular, con $q_i=(\vec{p}_i,\sigma_i,n_i)$. Si tenemos un estado caracterizado por cada uno de estos vectores $\ket{q_1\dots q_{i-1}q_iq_{i+1}\dots q_{j-1}q_jq_{j+1}\dots q_N}$ y hacemos el intercambio $q_i\leftrightarrow q_j$, tendremos $\ket{q_1\dots q_{i-1}q_jq_{i+1}\dots q_{j-1}q_iq_{j+1}\dots q_N}$. Si consideramos el caso $n=n_i=n_j$, es decir, son partículas idénticas, habremos intercambiado $\vec{p}_i\leftrightarrow\vec{p}_j$ y $\sigma_i\leftrightarrow\sigma_j$; pero si realmente son indistinguibles, ambos estados poliparticulares deberán estar relacionados, salvo una fase $\eta_n$, pues ambos estados representarán el mismo sistema. Así,
\begin{equation}
    \ket{q_1\dots q_{i-1}q_iq_{i+1}\dots q_{j-1}q_jq_{j+1}\dots q_N}=\eta_n\ket{q_1\dots q_{i-1}q_jq_{i+1}\dots q_{j-1}q_iq_{j+1}\dots q_N}
\end{equation}
Si volvemos a intercambiar $q_j\leftrightarrow q_i$, tenemos
\begin{equation}
    \ket{q_1\dots q_{i-1}q_iq_{i+1}\dots q_{j-1}q_jq_{j+1}\dots q_N}=\eta_n^2\ket{q_1\dots q_{i-1}q_iq_{i+1}\dots q_{j-1}q_jq_{j+1}\dots q_N}
\end{equation}
Pero como ambos estados son idénticos, tendremos que $\eta_n^2=1$, pero al ser $\eta_n$ una fase, es de la forma, $\eta_n=e^{i\varphi}$, por lo que $\eta_n=\pm1$.
\begin{itemize}
    \item Si $\eta_n=+1$, entonces $n$ es un bosón.
    \item Si $\eta_n=-1$, entonces $n$ es un fermión.
\end{itemize}
Podremos escribir la fase de forma general como 
\begin{equation}
    \eta_n=(-1)^{F_n};\hspace{4mm}\text{con }F_n=\left\lbrace\begin{array}{ll}
        1 & \text{si } n \text{ es un fermión} \\
        0 & \text{si } n\text{ es un bosón}
    \end{array}\right.
\end{equation}
donde $F_n$ será el número fermiónico.\\ \\
Existe la posibilidad de que $\eta_n$ dependa del camino que siguen las partículas para intercambiarse, por ello, en dimensión 2 aparece la \textit{estadística de aniones}. Pero como estamos en dimensión 4, esto no será influyente, por lo que no lo tomaremos en cuenta.\\ \\
Trabajamos en los subespacios donde los bosones idénticos están simetrizados y los fermiones idénticos, antisimetrizados (de acuerdo con el espacio de Fock). Así tendremos,
\begin{equation}
    \ket{q_1\dots q_N}=S_{\nu}\ket{q_1}\ket{q_2}\dots\ket{q_N}
\end{equation}
donde $S_{\nu}$ es un operador que simetriza todos los bosones ($\nu=+$) y antisimetriza todos los fermiones ($\nu=-$), definido como un simetrizador/antisimetrizador.
\begin{example}[Estado de dos fermiones idénticos]
    Al tener fermiones, $\eta_n=-1$ y $\nu=-$. Luego,
    \begin{equation*}
        \ket{q_1q_2}=S_-\ket{q_1}\ket{q_2}=\frac{1}{\sqrt{2}}\left(\ket{q_1}\ket{q_2}-\ket{q_2}\ket{q_1}\right)
    \end{equation*}
\end{example}
Para trabajar con esto, debemos elegir una normalización, tal que
\begin{equation}
    \Braket{q_1\dots q_N|q_1'\dots q_{N'}'}=\delta_{NN'}\sum_{\pi}\delta_{\pi}\prod_{i=1}^{N}\delta(q_i-q_{\pi' }^i)
\end{equation}
donde el $\pi$ corresponde con las \textbf{permutaciones} y $\delta_{\pi}$ será igual a $-1$ si corresponde a un número impar de permutaciones de fermiones y será igual a $+1$ en cualquier otro caso.
\begin{example}[Estado de dos bosones y dos fermiones idénticos donde permutamos los fermiones.]
    Tenemos $\ket{BB'FF'}\to\ket{BB'F'F}$, luego, como hemos hecho una permutación de fermiones, que es impar, así $\delta_{\pi}=-1$.
\end{example}
Además,
\begin{equation}
    \delta(q-q')=\delta_{nn'}\delta_{\sigma\sigma'}(2\pi)^32\omega_P\delta^{(3)}\left(\vec{p}-\vec{p}'\right)
\end{equation}
con $\omega_P=P^0=\sqrt{\vec{P}^2+m^2}$ y $q=(\vec{p},\sigma,n)$, $q'=(\vec{p}',\sigma',n')$.\\ \\
Vamos a considerar un sistema de partículas $n$ con $j_n=0$ y $m_n^2>0$; entonces el espacio de Fock para esta caso será,
\begin{equation}
    \mathscr{F}_n=\mathscr{H}^0\otimes\mathscr{H}_n\otimes\mathscr{H}_{nn}\otimes\mathscr{H}_{nnn}\otimes\dots
\end{equation}\footnote{Los espacios de Hilbert $\mathscr{H}_{n's}$ representa estados de partículas del número de $n's$ que tengan. I.e. $\mathscr{H}_n$ de una partícula, $\mathscr{H}_{nn}$, dos partículas, etc.}
donde $\mathscr{H}^0$ es un espacio de Hilbert unidimensional que representa el vacío de Fock, $\mathscr{H}^0=\curlybraces{\ket{0}}$, donde $\ket{0}$ es un invariante de Lorentz y Poincaré, que representa un estado sin partículas.\\ \\
Por definición, este vacío es invariante bajo transformaciones $U(N,a)\ket{0}=\ket{0}$ y está normalizado con $\Braket{0|0}=1$.\\ \\
Ahora definiremos los operadores de creación y destrucción:
\begin{itemize}
    \item \textbf{Creación}: El operador de creación, $a_{\vec{p}}^{\dagger}$, es un operador lineal sobre el espacio de Fock, que se define para una partícula, tal que
    \begin{equation}
        a^{\dagger}_{\vec{p}}\ket{0}=\frac{1}{\sqrt{2\omega_p}}\ket{\vec{p}}
        \label{eq3.23}
    \end{equation}
    En general,
    \begin{equation}
        a^{\dagger}_{\vec{p}}\ket{\vec{p}_1\dots\vec{p}_N}=\frac{1}{\sqrt{2\omega_p}}\ket{\vec{p}\vec{p}_1\dots\vec{p}_N}
    \end{equation}
    Es decir, crea una nueva partícula con $\vec{p}$.
    \item \textbf{Destrucción}: El operador de destrucción, $a_{\vec{p}}$, es un operador lineal sobre el espacio de Fock que se define como el operador autoadjunto del operador creación, tal que
    \begin{equation}
        a_{\vec{p}}=(a_{\vec{p}}^{\dagger})^{\dagger}
    \end{equation}
    Para una partícula se puede comprobar que cumple,
    \begin{equation}
        a_{\vec{p}}\ket{0}=0
    \end{equation}
    En general,
    \begin{equation}
        a_{\vec{p}}\ket{\vec{p}_1\dots\vec{p}_N}=(2\pi)^3\sqrt{2\omega_p}\sum_{r=1}^N\delta^{(3)}(\vec{p}-\vec{p}_r)\ket{\vec{p}_1\dots\vec{p}_{r-1}\vec{p}_{r+1}\dots\vec{p}_N}\eta_n^{r+1}
    \end{equation}
    es decir, desaparece la partícula con $\vec{p}_r$.
\end{itemize}
Las reglas de conmutación de estos operadores para \textbf{bosones}, que son,
\begin{equation}
    \brackets{a_{\vec{p}},a_{\vec{q}}}=\brackets{a_{\vec{p}}^{\dagger},a_{\vec{q}}^{\dagger}}=0;\hspace{5mm}\brackets{a_{\vec{p}},a_{\vec{q}}^{\dagger}}=(2\pi)^3\delta^{(3)}(\vec{p}-\vec{q})
\end{equation}
Para los \textbf{fermiones} tendremos las mismas reglas de conmutación, pero usando los anticonmutadores\footnote{$\curlybraces{A,B}=AB+BA$}, tal que
\begin{equation}
    \curlybraces{a_{\vec{p}},a_{\vec{q}}}=\curlybraces{a_{\vec{p}}^{\dagger},a_{\vec{q}}^{\dagger}}=0;\hspace{5mm}\curlybraces{a_{\vec{p}},a_{\vec{q}}^{\dagger}}=(2\pi)^3\delta^{(3)}(\vec{p}-\vec{q})
\end{equation}
Podemos ver cómo actúan los elementos del grupo $SL(2,\mathbb{C})$ con estos operadores, usando la ecuación (\ref{eq3.23}). Así,
\begin{equation}
    U(N,a)a_{\vec{p}}^{\dagger}U(N,a)^{-1}=e^{-i(\Lambda p)b}\sqrt{\frac{\omega_{\Lambda p}}{\omega_p}}a_{\Lambda \vec{p}}^{\dagger}
    \label{eq3.30}
\end{equation}
con $\Lambda\vec{p}=\left(\overrightarrow{\Lambda p}\right)$. Podemos ver que,
\begin{equation}
    \ket{p_1\dots p_N}=\sqrt{2\omega_{p_1}}\dots\sqrt{2\omega_{p_N}}a_{p_1}^{\dagger}\dots a_{p_N}^{\dagger}\ket{0}
    \label{eq3.31}
\end{equation}
Por tanto, si se cumple (\ref{eq3.30}), entonces (\ref{eq3.31}) transformará como un \textbf{sistema de partículas libres}, teniendo así un Hamiltoniano libre, es decir, diagonal. 
\begin{remark}
Estas definiciones de los operadores de creación y destrucción solo nos servirán para la teoría libre.
\end{remark}
Pasando al caso más general, definimos el espacio de Fock siguiente,
\begin{equation}
    \mathscr{F}=\mathscr{H}^0\bigoplus_{[n]}\mathscr{H}_{[n]}
\end{equation}
donde $[n]=\curlybraces{n_1,n_2,\dots,n_N}$ es una colección de $n$ y los $n_i$ son el número de partículas.\\ \\
Ahora, los operadores de creación y destrucción se definirán como,
\begin{equation}
    a^{\dagger}_{n\vec{p}\sigma}\ket{0}=\frac{1}{2\omega_p}\ket{\vec{p},\vec{\sigma}}_n;\hspace{5mm}a_{n\vec{p}\vec{\sigma}}=\left(a_{n\vec{p}\sigma}^{\dagger}\right)^{\dagger}
\end{equation}
Las reglas de conmutación serán,
\begin{equation}
    \brackets{a_{n\vec{p}\sigma},a_{n'\vec{p}'\sigma'}}_{\pm}=\brackets{a^{\dagger}_{n\vec{p}\sigma},a^{\dagger}_{n'\vec{p}'\sigma'}}_{\pm}=0;\hspace{4mm}\brackets{a_{n\vec{p}\sigma},a^{\dagger}_{n'\vec{p}'\sigma'}}_{\pm}=\delta_{nn'}\delta_{\sigma\sigma'}(2\pi)^3\delta^{(3)}\left(\vec{p}-\vec{p}'\right)
\end{equation}
donde el $\brackets{\cdot,\cdot}_{\pm}$ representa que $\brackets{B,B}_{\pm}=\brackets{B,B}$, $\brackets{B,F}_{\pm}=\brackets{B,F}$ y $\brackets{F,F}_{\pm}=\curlybraces{F,F}$.\\ \\
En el caso general, estos operadores transformarán como
\begin{equation}
    U(N,b)a_{n\vec{p}\sigma}^{\dagger}U(N,b)^{-1}=e^{-i(\Lambda p)b}\sqrt{\frac{\omega_{\Lambda p}}{\omega_p}}\sum_{\sigma'=-j_n}^{j_n}D_{\sigma'\sigma}^{(j_n)}\left(W(N,b)\right)a_{n\Lambda\vec{p}\sigma'}^{\dagger}
\end{equation}
 donde $D_{\sigma'\sigma}^{(j_n)}$ representa las rotaciones de cuántica en el \textit{little group}, correspondientes a la transformación que estamos haciendo y actúan sobre los operadores de creación.\\ \\
 Podemos escribir los estados de cualquier número de partículas $\ket{q_1\dots q_N}$, donde \\$q_i=(n_i,\vec{p}_i,\sigma_i)$, como
 \begin{equation}
     \ket{q_1\dots q_N}=\sqrt{2\omega_{p_1}}\dots\sqrt{2\omega_{p_N}}a_{q_1}^{\dagger}\dots a_{q_N}^{\dagger}\ket{0}
 \end{equation}
\section{Simetrías discretas: Simetría CPT}
La simetría CPT es una simetría exacta y discreta, que siempre conmutará con el Hamiltoniano del sistema.\\ \\
La simetría CPT es la simetría existente entre partículas y antipartículas, es decir, es la simetría que nos exige que debe existir una antipartícula por cada partícula existente, tal que $n\to\bar{n}$ y $\bar{\bar{n}}=n$. Además, se debe cumplir que $m_n^2=m_{\bar{n}}^2$, teniendo dos casos:
\begin{itemize}
    \item Si $m_n^2>0$, entonces los momentos de espín son iguales, $j_n=j_{\bar{n}}$.
    \item Si $m_n^2=0$, entonces las helicidades cambian de signo, $h_{\bar{n}}=-h_n$.
\end{itemize}
Además, si tenemos más números cuánticos (carga, $\dots$), entonces la antipartícula tendrá el mismo valor absoluto de los números cuánticos originales, pero con el signo opuesto ('una especie de conjugado').\\ \\
Existirán casos donde $n=\bar{n}$; por ejemplo, partículas sin carga, sin masa y con helicidad cero.\\ \\
Si tenemos el caso anterior, $m_n^2=0$ y $Q=0$, pero con helicidad distinta de cero, $h_n\neq0$, el lenguaje usual tratará a la partícula y la antipartícula como la misma partícula con dos estados de helicidad posibles, $\curlybraces{-h,h}$. Por ejemplo, el fotón no tiene antipartícula, pero es una partícula con dos estados de helicidad posibles, $h_{\gamma}=\curlybraces{-1,1}$; o el gravitón, con $h=\curlybraces{-2,2}$.\\ \\
Recalcar que esta denominación es solo lenguaje, físicamente sí tienen antipartículas, de forma que al hacer transformaciones de Lorentz no se podrán mezclar partículas con helicidad opuesta.
\begin{tcolorbox}[title=Teorema CPT]
    Suponiendo que el Hamiltoniano $H$ es invariante Lorentz y que las interacciones entre partículas se produce por medio de campos tenemos que,
    \begin{equation}
        \brackets{CPT,H}=0
    \end{equation}
    es decir, la operación combinada de paridad, conjugación de carga e inversión temporal es una simetría exacta de cualquier interacción. Como resultado de la conservación de $CPT$, las partículas y sus correspondientes antipartículas han de tener las mismas masas y vidas medias.
\end{tcolorbox}
Tendremos el operador $CPT$ que será antiunitario y actúa tal que
\begin{equation}
    CPT\ket{\vec{p},\sigma}_n=(-1)^{j_n-\sigma}\ket{\vec{p},-\sigma}_{\bar{n}}
\end{equation}
si $m_n^2>0$; cambiamos $\sigma\to-\sigma$, $n\to\bar{n}$ y aparece una fase. Para $m_n^2=0$ actuará tal que
\begin{equation}
    CPT\ket{\vec{p}}_n=(-1)^{|h|-h}\ket{\vec{p}}_{\bar{n}}
\end{equation}
para el lenguaje usual, para el lenguaje físico,
\begin{equation}
    CPT\ket{\vec{p},h}_n=(-1)^{|h|-h}\ket{\vec{p},-h}_{\bar{n}}
\end{equation}
Además, vemos que el operador $CPT^2$ actúa para partículas con masa como,
\begin{equation}
    (CPT)^2\ket{\vec{p},\sigma}_n=(-1)^{2j}\ket{\vec{p},\sigma}_{n}
\end{equation}
donde $2j$ es impar para fermiones y par para bosones, luego será equivalente escribir,
\begin{equation}
    (CPT)^2\ket{\vec{p},\sigma}_n=(-1)^F\ket{\vec{p},\sigma}_n
\end{equation}
donde $F$ es el número fermiónico, que es uno para fermiones y cero para bosones.\\ \\
Para el caso sin masa tendremos,
\begin{equation}
    (CPT)^2\ket{\vec{p}}_n=(-1)^{2h}\ket{\vec{p}}_n
\end{equation}
\subsubsection{Paridad}
Para el caso sin masa no se puede definir. La paridad $\mathcal{P}$ es un operador unitario que cumple que,
\begin{equation}
    \mathcal{P}\ket{\vec{p},\sigma}_n=\xi_n\ket{-\vec{p},\sigma}_n
\end{equation}
es decir, invierte las coordenadas espaciales de un estado físico.
\subsubsection{Inversión temporal}
Es un operador $\mathcal{T}$ antiunitario, tal que
\begin{equation}
    \mathcal{T}\ket{\vec{p},\sigma}_n=\beta_n(-1)^{j_n-\sigma}\ket{-\vec{p},-\sigma}_n
\end{equation}
es decir, invierte las coordenadas temporales de un estado físico.
\subsubsection{Conjugación de Carga}
Es un operador $\mathcal{C}$ que se define a partir de los anteriores, tal que
\begin{equation}
    \mathcal{C}=(CPT)\mathcal{T}^{-1}\mathcal{P}^{-1}
\end{equation}
donde tenemos que $antiunitario\times antiunitario=unitario$, por lo que el operador $\mathcal{C}$ será un operador unitario.\\ \\
En el mundo físico real, la única simetría exacta es $CPT$. La simetría $CP$ también es medio exacta, salvo factores pequeños que permiten dar una explicación (no del todo fundamentada) sobre la discrepancia entre la cantidad de materia y antimateria. La paridad es buena simetría para las interacciones fuertes (QCD, cromodinámica cuántica) y para el electromagnetismo (QED, electrodinámica cuántica); para las interacciones débiles no funciona.
\section{Teoría de Colisiones}
El formalismo que seguiremos será parecido al seguido en Mecánica Cuántica, pero tendremos estados con velocidades relativistas, por lo que tendremos invariancia Lorentz (en lugar de invariancia galileana) y aparecerá la creación y destrucción esporádica de partículas.\\ \\
Vamos a presentar los estados asintóticos \textit{in} y \textit{out}. Vamos a trabajar en la imagen de Heisenberg.\footnote{En la imagen de Heisenberg los estados $\ket{\alpha}_H$ son constantes y los operadores cambian con el tiempo, 
\[O(t)=e^{\frac{i}{\hbar}Ht}Oe^{-\frac{i}{\hbar}Ht}\]} Los estados \textit{in} los representamos como $\ket{\Psi^{in}_\alpha}\equiv\ket{\alpha}_{in}$. Tomamos un estado $\ket{\alpha}$ multipartícula libre y le asociamos el estado \textit{in}, tal que, para observadores con $t\to-\infty$ se cumple que
\begin{equation}
    \ket{\Psi^{in}_{\alpha}}\xrightarrow{t\to-\infty}\ket{\alpha}
\end{equation}
es decir, cuando tomamos tiempos tendiendo al menos infinito, los estados \textit{in} coinciden con los estados libres. De hecho, podemos descomponer el Hamiltoniano como $H=H_0+H_{int}$, siendo necesario que $H$ y $H_0$ tengan el mismo espectro de energías (mismos autovalores), de forma que
\begin{equation}
    H_0\ket{\alpha}=E_{\alpha}\ket{\alpha}
\end{equation}
entonces,
\begin{equation}
    H\ket{\Psi^{in}_{\alpha}}=E_{\alpha}\ket{\Psi^{in}_{\alpha}}
\end{equation}
cosa que debe cumplirse pues $E_{\alpha}$ no depende del tiempo, luego
\begin{equation}
    H\ket{\Psi^{in}_{\alpha}}\xrightarrow{t\to -\infty}H_0\ket{\alpha}=E_{\alpha}\ket{\alpha}\xrightarrow{t}E_{\alpha}\ket{\Psi^{in}_{\alpha}}
\end{equation}
Así, ambos tendrán el mismo autovalor, pero distinto autoestado. Como tenemos un espectro continuo, deberá cumplirse que
\begin{equation}
    \int d\alpha\cdot e^{-iE_{\alpha}t}g(\alpha)\ket{\Psi^{in}_{\alpha}}\xrightarrow{t\to-\infty}\int d\alpha\cdot e^{-iE_{\alpha}t}g(\alpha)\ket{\alpha}
\end{equation}
Análogamente, definimos el estado asintótico \textit{out}, $\ket{Psi^{out}_{\alpha}}\equiv\ket{\alpha}_{out}$, tal que
\begin{equation}
    \ket{\Psi^{out}_{\alpha}}\xrightarrow{t\to+\infty}\ket{\alpha}
\end{equation}
Así, obtenemos
\begin{equation}
    H_0\ket{\alpha}=E_{\alpha}\ket{\alpha}\Rightarrow H\ket{\Psi^{out}_{\alpha}}=E_{\alpha}\ket{\Psi^{out}_{\alpha}}
\end{equation}
volviendo a tener los mismos autovalores, pero distintos autoestados. Además,
\begin{equation}
    \int d\alpha\cdot e^{-iE_{\alpha}t}g(\alpha)\ket{\Psi^{out}_{\alpha}}\xrightarrow{t\to+\infty}\int d\alpha\cdot e^{-iE_{\alpha}t}g(\alpha)\ket{\alpha}
\end{equation}
La evolución temporal del sistema puede verse en la Figura \ref{Fig3-1}
\begin{Figura}
    \centering
    \includegraphics[width=0.5\textwidth]{imagenes/col.png}
    \captionof{figure}{Evolución temporal del sistema donde el círculo rojo representa la colisión.}
    \label{Fig3-1}
\end{Figura}
\noindent Dado un estado \textit{in}, la probabilidad de que corresponda con un estado \textit{out}, para $t\to+\infty$, será $\Braket{\Psi_{\beta}^{out}|\Psi^{in}_{\alpha}}$, que será lo que nos interesará calcular para comparar con lo experimentos. Viene dada por,
\begin{equation}
    \Braket{\Psi_{\beta}^{out}|\Psi^{in}_{\alpha}}=S_{\beta\alpha}
\end{equation}
donde $S_{\beta\alpha}$ corresponde con un conjunto de probabilidad y será los elementos de matriz de la matriz de colisión $S$.\\ \\
En Mecánica Cuántica distinguimos entre estados de colisión y estados estacionarios; en la teoría relativista siempre tendremos estados de colisión, por lo que no hablaremos de estados estacionarios.\\ \\
El hecho de tener una base ortonormal $\curlybraces{\ket{\alpha}}$, siendo los autoestados de $H_0$, que forma un conjunto completo, implica que $\curlybraces{\ket{\Psi^{in}_{\alpha}}}$, siendo los autoestados de $H$, que forman una base ortonormal que permite construir un conjunto completo.\\ \\
Usando la relación de completitud tenemos que
\begin{equation}
    \int d\beta S_{\beta\gamma}^*S_{\beta\alpha}=\int d\beta\Braket{\Psi^{in}_{\gamma}|\Psi^{out}_{\beta}}\Braket{\Psi^{out}_{\beta}|\Psi^{in}_{\alpha}}=\int d\beta\Braket{\Psi_{\gamma}^{in}|\mathds{1}|\Psi^{in}_{\alpha}}=\delta(\alpha-\gamma)
\end{equation}
donde tenemos la delta de Dirac, pues es un espectro continuo. Por tanto, la matriz $S$ es unitaria.\\ \\ 
Introducimos el operador $\mathcal{S}$, tal que
\begin{equation}
    \Braket{\beta|\mathcal{S}|\alpha}=S_{\beta\alpha}
\end{equation}
que nos permite trabajar con los estados multipartícula libres. Cumple que $\mathcal{S}\mathcal{S}^{\dagger}=\mathcal{S}^{\dagger}\mathcal{S}=\mathds{1}$, luego $\mathcal{S}^{\dagger}=\mathcal{S}^{-1}$, por lo que es un operador lineal unitario. Otra propiedad importante será que es invariante Lorentz, tal que
\begin{equation}
    U_0(N,a)\mathcal{S}U_0(N,a)^{-1}=\mathcal{S}
\end{equation}
cosa que nos interesa para que las probabilidades no dependan del observador. Otra forma de verlo es definiendo un operador lineal unitario $U^{in/out}$, tal que
\begin{equation}
    U^{in/out}(N,a)\ket{\Psi_{\alpha}^{in/out}}=\ket{\Psi_{\alpha'}^{in/out}}\Rightarrow\ket{\alpha'}=U_0(N,a)\ket{\alpha}
\end{equation}
Luego,
\begin{equation}
    \Braket{\Psi_{\beta}^{out}|\Psi_{\alpha}^{in}}=\Braket{\Psi_{\beta}^{out}|\left(U^{in}\right)^{\dagger}U^{in}|\Psi_{\alpha}^{in}}=\Braket{\Psi_{\beta}^{out}|\left(U^{in}\right)^{\dagger}|\Psi_{\alpha'}^{in}}=\Braket{\Psi_{\beta}^{out}|\Psi_{\alpha}^{in}}
\end{equation}
Haciendo transformaciones infinitesimales puede demostrarse que
\begin{equation}
    \brackets{H_0,\mathcal{S}}=0;\hspace{5mm}\brackets{\vec{P},\mathcal{S}}=0;\hspace{5mm}\brackets{\vec{J},\mathcal{S}}=0;\hspace{5mm}\brackets{\vec{K}_0,\mathcal{S}}=0
\end{equation}
Luego, que conmute con el Hamiltoniano implica que es invariante bajo traslaciones temporales, que conmute con $\vec{P}$ implica que sea invariante bajo traslaciones espaciales y que conmute con $\vec{J}$ y con $\vec{K}_0$, implica que sea invariante Lorentz. Además, al conmutar con todos los generadores es un operador de Casimir.\\ \\
Estudiaremos el caso $\beta\neq\alpha$, para obviar el caso trivial, donde si al ocurrir una colisión nos quedamos igual, la matriz de colisión será la identidad. Luego,
\begin{equation}
    S_{\beta\alpha}=\Braket{\beta|(\mathcal{S}-\mathds{1})|\alpha}\equiv i(2\pi)^4\delta^{(4)}(P_{\alpha}-P_{\beta})\mathcal{M}_{\beta\alpha}
\end{equation}
donde $\mathcal{M}_{\beta\alpha}$ es la \textbf{amplitud de colisión}. Además, $P_{\alpha}$ corresponde con el momento total de las partículas iniciales y $P_{\beta}$ corresponde con el momento total de las partículas finales.
\subsection{Sección eficaz}
En Teoría de Colisiones, el observable que solemos medir es la sección eficaz. Consideramos el estado inicial $\ket{\alpha}$, con dos partículas masivas, una de ellas en reposo. Tomamos $N_{\mathscr{B}}$, el número de sucesos tras la colisión, es decir, el número de partículas dispersas, con $\beta\in\mathscr{B}$ un suceso, y $\mathscr{B}$ el conjunto de probabilidades. Lo definimos como el número de partículas que inciden por unidad de superficie, tal que
\begin{equation}
    N_{\mathscr{B}}=\sigma_{\alpha\to\mathscr{B}}\cdot n
\end{equation}
donde $\sigma_{\alpha\to\mathscr{B}}$ es la sección eficaz; va del estado inicial $\ket{\alpha}$ al conjunto de probabilidades $\mathscr{B}$, y $n$ es el número de partículas incidente por unidad de área; la denominamos \textbf{luminosidad}.\\ \\
Si no lo dividimos por el área, el conjunto de sucesos $N_{\mathscr{B}}$ lo podremos calcular como el número de partículas del haz por la probabilidad de que, a partir de $\ket{\alpha}$ lleguemos a $\mathscr{B}$, tal que
\begin{equation}
    N_{\mathscr{B}}=n^opart.haz\times\mathscr{P}(\alpha\to\mathscr{B})
\end{equation}
Por otro lado, podemos definir la sección eficaz como,
\begin{equation}
    \sigma_{\alpha\to\mathscr{B}}=\frac{N_{\mathscr{B}}}{T\cdot\Phi}
\end{equation}
donde $T$ es el tiempo que dura el experimento y
\begin{equation}
    \Phi=\rho\times\text{velocidad haz incidente}
\end{equation}
donde $\rho$ es el número de partículas partido volumen, $V$. Por tanto,
\begin{equation}
    \sigma_{\alpha\to\mathscr{B}}=\frac{N_{\mathscr{B}}V}{T\left|\vec{v}_1-\vec{v}_2\right|\times\text{nº part}}=\frac{V}{T\left|\vec{v}_1-\vec{v}_2\right|}\frac{\cancel{\text{nº part}}\mathcal{P}(\alpha\to\mathscr{B})}{\cancel{\textbf{nº part}}}=\frac{V}{T\left|\vec{v}_1-\vec{v}_2\right|}\mathscr{P}(\alpha\to\mathscr{B})
\end{equation}
Tomamos la probabilidad de un conjunto, pues la probabilidad de que ocurra algo en concreto será nula. Esta probabilidad la podremos escribir en función de una densidad de probabilidad, tal que
\begin{equation}
    \mathscr{P}(\alpha\to\mathscr{B})=\int_{\mathscr{B}}d\mathscr{P}(\alpha\to\beta)
\end{equation}
Además, podemos tomar la sección eficaz diferencial, tal que
\begin{equation}
    \sigma_{\alpha\to\mathscr{B}}=\int_{\mathscr{B}}d\sigma(\alpha\to\beta)
\end{equation}
Por tanto, sustituyendo y quitando las integrales, queda
\begin{equation}
    d\sigma(\alpha\to\beta)=\frac{V}{T\left|\vec{v}_1-\vec{v}_2\right|}d\mathscr{P}(\alpha\to\beta)
\end{equation}
Recordamos que en Relatividad la velocidad de las partículas la podemos escribir como
\begin{equation}
    \vec{v}_i=\frac{\vec{p}_i}{E_i}
\end{equation}
Además, usando Mecánica Cuántica, podemos calcular la densidad de probabilidad,
\begin{equation}
    d\mathscr{P}(\alpha\to\beta)=\frac{\left|\Braket{\beta|\mathcal{S}|\alpha}\right|^2}{\left|\Braket{\alpha|\alpha}\right|\left|\Braket{\beta|\beta}\right|}d\beta
\end{equation}
pero esta normalización no está definida. Podemos calcularlo usando paquetes de ondas (forma más rigurosa), pero casi siempre, podremos simplificar todo y dejarlo en función de $\ket{\alpha}$ y $\ket{\beta}$. Nosotros lo haremos de la forma del Schwarz (menos rigurosa), pero llegaremos al mismo resultado.\\ \\
Tomamos el estado inicial como $\ket{\alpha}=\ket{\vec{p}_1,\vec{p}_2,\sigma_1,\sigma_2}\equiv\ket{\vec{p}_1,\vec{p}_2}$, no consideraremos el espín. La norma general de dos estados será,
\begin{equation}
    \Braket{\alpha|\alpha'}=\Braket{\vec{p}_1,\vec{p}_2|\vec{q}_1,\vec{q}_2}=\Braket{\vec{p}_1|\vec{q}_1}\Braket{\vec{p}_2|\vec{q}_2}=(2\pi)^3(2\pi)^32\omega_{p_1}2\omega_{p_2}\delta^{(3)}\left(\vec{p}_1-\vec{q}_1\right)\delta^{(3)}\left(\vec{p}_2-\vec{q}_2\right)
\end{equation}
donde tiene esta forma por la normalización que hemos elegido. Pero como queremos calcular la norma de $\ket{\alpha}$, tendremos
\begin{equation}
    \Braket{\alpha|\alpha}=\Braket{\vec{p}_1,\vec{p}_2|\vec{p}_1,\vec{p}_2}=(2\pi)^3(2\pi)^32\omega_{p_1}2\omega_{p_2}\delta^{(3)}\left(\vec{0}\right)\delta^{(3)}\left(\vec{0}\right)
\end{equation}
Tomando la delta de Dirac como,
\begin{equation}
    (2\pi)^3\delta^{(3)}(\vec{p})=\int e^{i\vec{p}\cdot\vec{x}}d^3x
\end{equation}
Tendremos que
\begin{equation}
    (2\pi)^3\delta^{(3)}(\vec{0})=\int d^3x\sim\int_Vd^3x=V
\end{equation}
Luego,
\begin{equation}
    \Braket{\alpha|\alpha}=2\omega_{p_1}2\omega_{p_2}V^2=2E_12E_2V^2
\end{equation}
Se hace de forma análoga para el estado final $\ket{\beta}$, pero en el estado final pueden haber más de dos partículas, luego si hay $N-$partículas,
\begin{equation}
    \Braket{\beta|\beta}=\prod_{j=1}^N\left(2\omega_{p_j}V\right)=\prod_{j=1}^N\left(2E_jV\right)
\end{equation}
Por tanto, para $\beta\neq\alpha$, tendremos
\begin{equation}
    \Braket{\beta|\mathcal{S}|\alpha}=i(2\pi)^4\delta^{(4)}(P_{\alpha}-P_{\beta})\mathcal{M}_{\beta\alpha}
\end{equation}
Por tanto,
\begin{equation}
    \begin{array}{rl}
         \left|\Braket{\beta|\mathcal{S}|\alpha}\right|^2&=\brackets{i(2\pi)^4\delta^{(4)}(P_{\alpha}-P_{\beta})\mathcal{M}_{\beta\alpha}}^2=  \\ \\
         & =-(2\pi)^4(2\pi)^4\delta^{(4)}(P_{\alpha}-P_{\beta})\delta^{(4)}(P_{\alpha}-P_\beta)|\mathcal{M}_{\beta\alpha}|^2=\\ \\
         &\curlybraces{\delta(x-y)\delta(x-y)=\delta(0)\delta(x-y);\text{ y }-\delta(x-y)=\delta(y-x)}\\ \\
         &=(2\pi)^8\delta^{(4)}(P_{\beta}-P_{\alpha)}\cancelto{VT/(2\pi)^4}{\delta^{(4)}(0)}|\mathcal{M}_{\beta\alpha}|^2=(2\pi)^4VT\delta^{(4)}(P_{\beta}-P_{\alpha})|\mathcal{M}_{\beta\alpha}|^2
    \end{array}
\end{equation}
Para que sea realmente una probabilidad, queremos que $\int d\beta=1$, donde el $d\beta$ es el diferencial de volumen en el espacio de fases, que una vez normalizado, vendrá dado por
\begin{equation}
    d\beta=\prod_{j}\left(\frac{V}{(2\pi)^3}d\vec{p}_j\right)
\end{equation}
Luego,
\begin{equation}
\begin{array}{rl}
     
    d\mathscr{P}(\alpha\to\beta)&=\frac{\delta^{(4)}(P_{\alpha}-\sum_{\beta}P_{\beta})TV(2\pi)^4}{2E_12E_2V^2}\frac{1}{\prod\limits_j(2E_jV)}|\mathcal{M}_{\beta\alpha}|^2\prod_j\frac{V}{(2\pi)^3}d^3\vec{p}_j  \\ \\
     & =\frac{T}{V}\frac{1}{2E_12E_2}|\mathcal{M}_{\beta\alpha}|^2d\Pi_{LIPS}(P_{\alpha})
\end{array}
\end{equation}
Por tanto, la sección eficaz diferencial queda,
\begin{equation}
    d\sigma(\alpha\to\beta)=\frac{1}{2E_12E_2\left|\vec{v}_1-\vec{v}_2\right|}|\mathcal{M}_{\beta\alpha}|^2d\Pi_{LIPS}^{(n)}(P_{\alpha})
\end{equation}
donde hemos considerado $n-$partículas finales; $LIPS$ se refiere al espacio de fases final que es invariante Lorentz, y
\begin{equation}
    d\Pi_{LIPS}^{(n)}(q)=\brackets{\prod_{j=1}^n\frac{d^3\vec{p}_j}{(2\pi)^32E_j}}(2\pi)^4\delta^{(4)}\left(q-\sum_{j=1}^np_j\right)
\end{equation}
\begin{example}[Obtención de la fórmula para dos partículas finales.]
    Consideramos un 'scattering' $2\to2$, es decir, colisionan dos partículas y generan otras dos. Tomamos el sistema de referencia centro de masas, 
    \begin{equation}
        p_1+p_2\to p_3+p_4
    \end{equation}
    con $\vec{p}_1=-\vec{p}_2$, $\vec{p}_3=-\vec{p}_4$ y $E_1+E_2=E_3+E_4=E_{CM}$, donde $E_{CM}$ es la energía total en el sistema centro de masas. Entonces,
    \begin{equation}
        d\Pi_{LIPS}=(2\pi)^4\delta^{(4)}(p_1+p_2-p_3-p_4)\frac{d^3p_3}{(2\pi)^3}\frac{1}{2E_3}\frac{d^3p_4}{(2\pi)^3}\frac{1}{2E_4}
    \end{equation}
    Podemos integrar en $\vec{p}_4$ usando la función delta, tal que
    \begin{equation}
        d\Pi_{LIPS}=\frac{1}{16\pi^2}d\Omega\int dp_f\frac{p_f^2}{E_3}\frac{1}{E_4}\delta(E_3+E_4-E_{CM})
    \end{equation}
    donde $p_f=|\vec{p}_3|=|\vec{p}_4|$ y $E_3=\sqrt{m_3^2+p_f^2}$ y $E_4=\sqrt{m_4^2+p_f^2}$. Hacemos ahora un cambio de variable de $p_f$ a $x(p_f)=E_3(p_f)+E_4(p_f)-E_{CM}$. El Jacobiano es
    \begin{equation}
        \frac{dx}{dp_f}=\frac{d}{dp_f}(E_3+E_4-E_{CM})=\frac{p_f}{E_3}+\frac{p_f}{E_4}=\frac{E_3+E_4}{E_3E_4}p_f
    \end{equation}
    y entonces, usando $E_3+E_4=E_{CM}$, tenemos
    \begin{equation}
        d\Pi_{LIPS}=\frac{1}{16\pi^2}d\Omega\int_{m_3+m_4-E_{CM}}^{\infty}dx\frac{p_f}{E_{CM}}\delta(x)=\frac{1}{16\pi^2}d\Omega\frac{p_f}{E_{CM}}\Theta(E_{CM}-m_3-m_4)
    \end{equation}
    donde $\Theta$ es la función escalón. Luego, la sección eficaz diferencial queda,
    \begin{equation}
        d\sigma=\frac{1}{2E_12E_2\left|\vec{v}_1-\vec{v}_2\right|}\frac{1}{16\pi^2}d\Omega\frac{p_f}{E_{CM}}|\mathcal{M}_{fi}|^2\Theta(E_{CM}-m_3-m_4)
    \end{equation}
    Usando que
    \begin{equation}
        \left|\vec{v}_1-\vec{v}_2\right|=\left|\frac{\left|\vec{p}_1\right|}{E_1}+\frac{\left|\vec{p}_2\right|}{E_2}\right|=\left|\vec{p}_i\right|\frac{E_{CM}}{E_1E_2}
    \end{equation}
    tenemos que
    \begin{tcolorbox}[title=Sección eficaz diferencial para dos partículas en el estado final]
        \begin{equation}
            \left(\frac{d\sigma}{d\Omega}\right)_{CM}=\frac{1}{64\pi^2E_{CM}^2}\frac{\left|\vec{p}_f\right|}{\left|\vec{p}_i\right|}\left|\mathcal{M}_{fi}\right|^2\Theta(E_{CM}-m_3-m_4)
        \end{equation}
        La función escalón nos dice que el proceso es imposible si la energía del estado inicial, $E_{CM}=E_1+E_2$, no es suficiente para crear las demás partículas.
    \end{tcolorbox}
    Si todas las masas son iguales, tenemos que $|\vec{p}_f|=|\vec{p}_i|$, luego
    \begin{equation}
        \left(\frac{d\sigma}{d\Omega}\right)_{CM}=\frac{1}{64\pi^2E_{CM}^2}|\mathcal{M}_{fi}|^2
    \end{equation}
\end{example}
\begin{note}
    El resultado para la sección eficaz con partículas idénticas es el mismo obtenido, pero tenemos que dividir por
    \begin{equation}
        s=\prod_{i}n_i!
    \end{equation}
    para no repetir partículas.
\end{note}
Si consideramos el estado inicial formado por una sola partículas, será un estado propio del Hamiltoniano total $H$, pues al no haber interacción, $H_{int}=0$, pero esto da lugar a un estado estacionario que no evoluciona. Las partículas inestables son desintegraciones del tipo $1\to n$. Estas partículas son estados parecidos a estados propios del Hamiltoniano pero que sí evolucionan, luego haremos esta aproximación. Tomaremos un tiempo $T$ de interacción mucho menor que el tiempo $\tau_{\alpha}$ de vida media de las partículas, es decir, $T<<\tau_{\alpha}$. Este tiempo $T$ finito conlleva una incertidumbre en la energía final, obteniendo que $E_i\neq E_f$. Realmente lo que ocurre es que al tener partículas inestables, su masa no está bien definida y por tanto, la energía inicial tampoco lo estará.\\ \\
Al tener una sola partícula que no colisiona no tiene sentido hablar de secciones eficaces; para este tipo de procesos tratamos con la \textbf{anchura diferencial de desintegración} $d\Gamma$, siendo la probabilidad de que una partícula con momento $p_{\alpha}$ se desintegre en un estado multipartícula con momento $\curlybraces{p_{\beta}}$ en el tiempo $T$, dado por
\begin{equation}
    d\Gamma(\alpha\to\beta)=\frac{1}{T}d\mathscr{P}(\alpha\to\beta)
\end{equation}
Siguiendo el mismo procedimiento de la sección eficaz pero para un sistema $1\to n$, obtenemos que
\begin{tcolorbox}[title=Anchura de desintegración diferencial]
    \begin{equation}
        d\Gamma(\alpha\to\beta)=\frac{1}{2m_{\alpha}}|\mathcal{M}_{\beta\alpha}|^2d\Pi_{LIPS}^{(n)}(m_{\alpha},\vec{0})
    \end{equation}
    siendo el decaimiento en el sistema de referencia centro de masas de la partícula inestable
\end{tcolorbox}
Integrando sobre todo el espacio de fases y sumando sobre todas las posibilidades de todos los estados finales posibles tenemos,
\begin{equation}
    \Gamma=\int d\beta\frac{d\Gamma(\alpha\to\beta)}{d\beta}
\end{equation}
siendo la \textbf{anchura de desintegración total}, con
\begin{equation}
    \tau_{\alpha}=\frac{1}{\Gamma_{\alpha}}
\end{equation}
Como discutimos antes, tanto la masa como la energía de las partículas inestables no están bien definidas, sino que tendremos una incertidumbre (de la masa) que dependerá de la anchura de desintegración, así
\begin{itemize}
    \item Si $\tau_{\alpha}\uparrow\uparrow\Rightarrow\Gamma_{\alpha}\downarrow\downarrow$, luego $m_{\alpha}$ estará bien definida.
    \item Si $\tau_{\alpha}\downarrow\downarrow\Rightarrow\Gamma_{\alpha}\uparrow\uparrow$, luego $m_{\alpha}$ no estará bien definida.
\end{itemize}
Experimentalmente en un sistema $2\to2$ se obtienen gráficas del tipo, (Figura \ref{Fig3.1})
\begin{Figura}
    \centering
    \includegraphics[width=0.6\textwidth]{imagenes/resonancia.png}
    \captionof{figure}{Gráfica obtenida de una colisión del tipo $2\to2$, donde el pico se denomina \textbf{resonancia}.}
    \label{Fig3.1}
\end{Figura}
Esta gráfica la interpretamos con el diagrama de Feynman siguiente,\\
\begin{center}
\begin{fmffile}{diagrama}
\begin{fmfgraph*}(150,100)
  \fmfleft{i1,i2}
  \fmfright{o1,o2}
  \fmf{fermion}{i1,v1}
  \fmf{fermion}{i2,v1}
  \fmf{photon}{v1,v2}
  \fmf{fermion}{v2,o1}
  \fmf{fermion}{v2,o2}
\end{fmfgraph*}
\end{fmffile}
\end{center}
Este diagrama se interpreta como la colisión de dos partículas estables (las primeras flechas), generan una partícula inestable (la onda) que se desintegra en dos partículas estables (las flechas últimas). La masa de la partícula inestable que se genera será el pico (resonancia) que se observa en la Figura \ref{Fig3.1}, cuyo ancho es el $\Gamma$ de la partícula inestable.
\subsubsection{Teorema óptico}
Nos basamos en la propiedad de que el operador $\mathcal{S}$ es unitario, $\mathcal{S}^{\dagger}\mathcal{S}=\mathcal{S}\mathcal{S}^{\dagger}=\mathds{1}$. Por lo que podremos reescribir el operador $\mathcal{S}$ como
\begin{equation}
    \mathcal{S}=\mathds{1}+i\mathcal{T}
\end{equation}
Luego, el operador $\mathcal{T}$ satisface
\begin{equation}
    i\left(\mathcal{T}^{\dagger}-\mathcal{T}\right)=\mathcal{T}^{\dagger}\mathcal{T}
\end{equation}
por la condición de unitariedad de $\mathcal{S}$. Ahora introducimos este operador $\mathcal{T}$ es un Braket de un estado inicial $\ket{i}$ y un estado final $\ket{f}$, tal que
\begin{equation}
    \Braket{f|\mathcal{T}|i}=(2\pi)^4\delta^{(4)}(P_f-P_i)\mathcal{M}_{fi}
\end{equation}
Luego, introducimos la ecuación (3.100) en el Braket,
\begin{equation}\small
    \begin{array}{ccl}
        \Braket{f|i\left(\mathcal{T}^{\dagger}-\mathcal{T}\right)|f} & = &i\Braket{i|\mathcal{T}|f}^*-i\Braket{f|\mathcal{T}|i}=i(2\pi)^4\delta^{(4)}(P_f-P_i)\left(\mathcal{M}_{if}^*-\mathcal{M}_{fi}\right)  \\ 
        || & & \curlybraces{\mathds{1}=\sum\limits_x\int d\Pi_X\ket{x}\bra{x},\text{ con }d\Pi_X=\prod\limits_{j\in X}\frac{d^3P_j}{(2\pi)^3}\frac{1}{2\omega_{P_j}}} \\
        \Braket{f|\mathcal{T}^{\dagger}\mathcal{T}|i} & = & \Braket{f|\mathcal{T}^{\dagger}\mathds{1}\mathcal{T}|i}=\Braket{f|\mathcal{T}^{\dagger}\sum\limits_x\int d\Pi_X\ket{x}\bra{x}\mathcal{T}|i}=\\ \\
        & = & \sum\limits_x\int d\Pi_X\Braket{x|\mathcal{T}|f}^*\Braket{x|\mathcal{T}|i}=(2\pi)^4\delta^{(4)}(P_f-P_i)\sum\limits_x\int d\Pi_X(2\pi)^4\delta^{(4)}(P_x-P_i)\mathcal{M}^*_{xf}\mathcal{M}_{xi}
    \end{array}
\end{equation}
Luego, comparando ambas expresiones,
\begin{equation}
    i\cancel{(2\pi)^4}\cancel{\delta^{(4)}(P_f-P_i)}\left(\mathcal{M}_{if}^*-\mathcal{M}_{fi}\right)=\cancel{(2\pi)^4}\cancel{\delta^{(4)}(P_f-P_i)}\sum\limits_x\int d\Pi_X(2\pi)^4\delta^{(4)}(P_x-P_i)\mathcal{M}^*_{xf}\mathcal{M}_{xi}
\end{equation}
donde podemos cancelar las deltas si y solo si $p_f=P_i$. Así obtenemos el \textbf{Teorema óptico generalizado},
\begin{tcolorbox}[title=Teorema óptico generalizado]
    \begin{equation}
        \left(\mathcal{M}_{fi}-\mathcal{M}_{if}^*\right)=i\sum\limits_x\int d\Pi_X(2\pi)^4\delta^{(4)}(P_x-P_i)\mathcal{M}^*_{xf}\mathcal{M}_{xi}
    \end{equation}
    siendo solo válido para $P_f=P_i$.
\end{tcolorbox}
Si los estados iniciales y finales son los mismos, es decir, $i=f\equiv A$, obtenemos el \textbf{Teorema óptico} normal,
\begin{tcolorbox}[title=Teorema óptico]
    \begin{equation}
        2Im\mathcal{M}_{AA}=\sum_X\int d\Pi_X(2\pi)^4\delta^{(4)}(P_x-P_A)|\mathcal{M}_{AA}|^2
    \end{equation}
\end{tcolorbox}
Tendremos dos casos interesantes para este último:
\begin{itemize}
    \item \textbf{A corresponde con una partícula}: Comparando con la anchura de desintegración obtenemos,
    \begin{equation}
        Im\mathcal{M}_{AA}=m_A\sum_x\Gamma(A\to x)=m_A\Gamma_{total}
    \end{equation}
    obteniendo otro método para calcular la anchura de desintegración total. De hecho, podemos tomar esta expresión como una definición más rigurosa de la anchura de desintegración total, pues no tenemos que tratar con partículas inestables ni incertidumbres.
    \item \textbf{A corresponde con dos partículas}: Comparando con la sección eficaz de $2\to2$,
    \begin{equation}
        Im\mathcal{M}_{AA}=2E_{CM}|\vec{p}_i|\sum_x\sigma(A\to x)=2E_{CM}|\vec{p}_i|\sigma_{total}(A\to\text{lo que sea})
    \end{equation}
    siendo el \textbf{Teorema óptico de Mecánica Cuántica}, pero más general, pues en cuántica solo tenemos dispersión angular, mientras que aquí pueden aparecer nuevas partículas o desaparecer, etc.
\end{itemize}
\subsection{Algunas aclaraciones}
Vimos que la matriz $\mathcal{S}$ tiene invariancia Lorentz,
\begin{equation}
    \Braket{\alpha|\mathcal{S}|\beta}=\Braket{\alpha|U_0^{-1}\mathcal{S}U_0|\beta}
\end{equation}
Pero esto es muy superficial, veámoslo más en detalle. Supongamos un número indeterminado de partículas iniciales, dadas por $q_i=\curlybraces{p_i,\sigma_i,n_i}$ y un número indeterminado de partículas finales, dadas por $q_j'=\curlybraces{p_j',\sigma_j',n_j'}$. Consideraremos el caso de partículas masivas, $m_n^2>0$. Así,
\begin{equation}
    \begin{array}{rl}
        \Braket{\alpha|\mathcal{S}|\beta} &=S_{p_1'\sigma_1'n_1',p_2'\sigma_2'n_2',\dots;p_1\sigma_1n_1,p_2\sigma_2n_2,\dots}=\Braket{\alpha|U_0^{-1}\mathcal{S}|U_0|\beta}=  \\ \\
         & =e^{ia_{\nu}\Lambda_{\mu}^{\nu}\left(\sum\limits_{i}p_i^{\mu}-\sum\limits_{j}p_j^{'\mu}\right)}\sum\limits_{\bar{\sigma}_1\bar{\sigma}_2\dots}D^{(j_1)}_{\bar{\sigma}_1\sigma_1}\left(W(N,p_1)\right)D^{(j_2)}_{\bar{\sigma}_2\sigma_2}\left(W(N,p_2)\right)\dots\times\\ \\
         &\times\sum\limits_{\bar{\sigma}_1'\bar{\sigma}_2'\dots}D^{(j_1)}_{\bar{\sigma}_1'\sigma_1'}\left(W(N,p_1')\right)^*D^{(j_2)}_{\bar{\sigma}_2'\sigma_2'}\left(W(N,p_2')\right)^*\dots S_{\Lambda p_1'\bar{\sigma}_1'n_1',\dots;\Lambda p_1\bar{\sigma}_1n_1,\dots}
    \end{array}
\end{equation}
donde recordamos que $\Lambda=\Lambda(N)$.\\ \\
Imponiendo ahora la invariancia $CPT$, que es un operador antilineal y antiunitario, tenemos que
\begin{equation}
    S_{\beta\alpha}=\Braket{\Psi_{\beta}^{out}|\Psi_{\alpha}^{in}}=\Braket{CPT\Psi_{\alpha}^{in}|CPT\Psi_{\beta}^{out}}=\Braket{\Psi_{\bar{\alpha}}^{out}|\Psi_{\bar{\beta}}^{in}}=S_{\bar{\alpha}\bar{\beta}}=S_{\bar{\beta}\bar{\alpha}}^*
\end{equation}
Por otro lado, vimos que los estados multipartícula libres son autoestados de $H_0$ y de $\vec{P}$, con autovalores
\begin{equation}
    H_0\to\sum_i\omega_{p_i};\hspace{5mm}\vec{P}\to\sum_i\vec{p}_i
\end{equation}
donde el autovalor de $H_0$ representa la energía total del sistema y el del momento representa el momento total.\\ \\
Podemos escribir de forma explícita la forma de estos operadores en la base de sus autovectores, llegando a
\begin{equation}
    H_0=\int\frac{d^3p}{(2\pi)^3}\omega_pa_{\vec{p}}^{\dagger}a_{\vec{p}}
\end{equation}
siendo para el caso de una partícula escalar. De forma general,
\begin{equation}
    H_0=\mathop{\sum\!\!\!\!\!\!\!\!\int}_q\omega_pa_{\vec{p}}^{\dagger}a_{\vec{p}}
\end{equation}
y para el momento de forma general tendremos,
\begin{equation}
    \vec{P}=\mathop{\sum\!\!\!\!\!\!\!\!\int}_q\vec{p}a_{\vec{p}}^{\dagger}a_{\vec{p}}
\end{equation}
donde $q=(p,\sigma,n)$. Además, el símbolo $\mathop{\sum\!\!\!\!\!\!\int}\limits_q$ representa un sumatorio de todos los tipos de partículas, en todos los $q$; haciendo la integral del $H_0$ monoparticular (ecuación 3.112) para cada sumando.\\ \\
Por otra parte, podemos escribir la perturbación de $H_0$ en la imagen de interacción, $H'=H-H_0$, como
\begin{equation}
    H'(t)=\int d^3x\mathscr{H}(t,\vec{x})
\end{equation}
donde $\mathscr{H}$ es la densidad Hamiltoniana. Además, para que exista invariancia Lorentz en la matriz $\mathcal{S}$, debemos introducir la propiedad siguiente,
\begin{equation}
    \brackets{\mathscr{H}(x),\mathscr{H}(y)}=0
\end{equation}
si $(z-y)^2<0$, es decir, los puntos en los que evaluamos las densidades Hamiltonianas deben tener una separación tipo espacio.
\section{Cálculos en QFT sin campos}
La invariancia Lorentz será un requisito fundamental. Para poder trabajar en el formalismo de QFT, al estar en el grupo de Poincaré, debemos trabajar con espinores. Por tanto, todos los tensores que aparecen en la teoría los escribiremos como espinores tensoriales.\\ \\
Comenzamos con el cuadrimomento $P_{\mu}$, que lo pasamos a su forma de operador $\hat{P}$, siendo una matriz hermítica, y su forma espinorial es
\begin{equation}
    P_{\mu}\to P_{\alpha\dot{\alpha}}P^{\mu}\left(\sigma_{\mu}\right)_{\alpha\dot{\alpha}}
\end{equation}
Una consecuencia importante de esta notación es
\begin{equation}
    det\hat{P}=P^{\mu}P_{\mu}=m^2
\end{equation}
es decir, el determinante de la matriz momento equivale a la masa. Ahora, si consideramos el caso sin masa $(m_n^2=0)$, tendremos que $det\hat{P}=0$. Por tanto, la matriz $\hat{P}$ no tendrá inversa y el rango de $\hat{P}$ será menor que dos, es decir, $\hat{P}\in\mathcal{M}_{2\times2}$. Además, como $rg\hat{P}<2$, podemos escribir $\hat{P}$ como,
\begin{equation}
    \hat{P}=\lambda(p)\tilde{\lambda}(p)\to P_{\alpha\dot{\alpha}}=\lambda_{\alpha}\tilde{\lambda}_{\dot{\alpha}}
\end{equation}
donde $\lambda(p)$ es un vector columna y $\tilde{\lambda}(p)$ es un vector fila; o en otras palabras, $\lambda_{\alpha}$ es un espinor $LH$ y $\tilde{\lambda}_{\dot{\alpha}}$ es un espinor $RH$.\\ \\
Si vamos al sistema de referencia del momento estándar $(p=k)$, al tener el caso \textit{massless}, sabemos que $k=(E,0,0,E)$ que podemos reescribir como,
\begin{equation}
    \hat{k}=2E\begin{pmatrix}
        0 & 0\\
        0 & 1
    \end{pmatrix}
\end{equation}
podemos renombrar $\eta=\lambda(k)$ y $\tilde{\eta}=\tilde{\lambda}(k)$, para simplificar la notación, obteniendo que
\begin{equation}
    \eta=\sqrt{2E}\begin{pmatrix}
        0\\
        1
    \end{pmatrix}\tau^{-1};\hspace{6mm}\tilde{\eta}=\sqrt{2E}\begin{pmatrix}
        0 & 1
    \end{pmatrix}\tau;\hspace{6mm}\tau\in\mathbb{C}\backslash\curlybraces{0}
\end{equation}
donde $\tau$ lo introducimos porque en algunos desarrollos puede resultar útil.\\ \\
Si tenemos un $\lambda(p)$ general, usando las transformaciones de Lorentz estándar, vamos de $k\to p$, así
\begin{equation}
    \lambda_{\alpha}(p)=L(p)_{\alpha}^{\beta}\eta_{\beta};\hspace{7mm}\tilde{\lambda}_{\dot{\alpha}}(p)=L^*(p)_{\dot{\alpha}}^{\dot{\beta}}\tilde{\eta}_{\dot{\beta}}
\end{equation}
Haciendo una transformación de helicidad, que es una rotación de ángulo $\varphi$ sobre el eje donde vaya el momento, obtenemos que
\begin{equation}
    \lambda(p)\to e^{-i\varphi/2}\lambda(p);\hspace{7mm}\tilde{\lambda}(p)\to e^{i\varphi/2}\tilde{\lambda}(p)
\end{equation}
Al ser $\hat{P}$ una matriz hermítica real, entonces $P_{\mu}\in\mathbb{R}^4$, por tanto
\begin{equation}
    \tilde{\lambda}^*(p)=\lambda(p);\hspace{5mm}\tilde{\lambda}(p)=\lambda^*(p)
\end{equation}
\begin{proof}
    \[\begin{array}{rl}
        \hat{P}&=\lambda(p)\tilde{\lambda}(p)=\hat{P}^{\dagger}=\tilde{\lambda}^{\dagger}(p)\lambda^{\dagger}(p)=\tilde{\lambda}^*(p)\lambda^*(p)
    \end{array}\]
    Como $\lambda(p)$ y $\tilde{\lambda}^*(p)$ tienen la misma dimensión (son un vector columna) y $\tilde{\lambda}(p)$ y $\lambda^*(p)$ también tienen la misma dimensión (son un vector fila), entonces podemos hacer las siguientes igualdades,
    \begin{equation*}
        \lambda(p)=\tilde{\lambda}^*(p);\hspace{5mm}\tilde{\lambda}(p)=\lambda^*(p)
    \end{equation*}
\end{proof}
Además, fijándonos en la ecuación $(3.121)$, podemos escribir de forma general,
\begin{equation}
    \lambda(p)'=\lambda(p)\tau^{-1};\hspace{5mm}\tilde{\lambda}(p)'=\tilde{\lambda}(p)\tau;\hspace{5mm}\tau\in\mathbb{C}
\end{equation}
Por tanto, para que se cumpla la igualdad $(3.123)$, hacemos la identificación,
\begin{equation}
    \tau=Ae^{-i\varphi/2};\hspace{5mm}\tau^{-1}=A^{-1}e^{i\varphi/2};\hspace{5mm}A,\varphi\in\mathbb{R}
\end{equation}
convirtiéndose $\tau$ en una \textbf{fase}.
\begin{note}
    En ocasiones será de gran utilidad, para obtener fórmulas generales, hacer todo el desarrollo con momentos complejos, $P_{\mu}\in\mathbb{C}^4$, obteniendo cualquier expresión a la que le haremos el límite para que el momento sea real, $P_{\mu}\in\mathbb{R}^4$. En los pasos intermedios donde $p_{\mu}\in\mathbb{C}^4$ no se cumplirá que $\tilde{\lambda}^*(p)=\lambda(p)$, sino que serán independientes.
\end{note}
Por otro lado, sean $\hat{p}=\lambda\tilde{\lambda}$ y $\hat{q}=\xi\tilde{\xi}$ momentos, definimos los productos antisimétricos,
\begin{equation}
    <p\:q>=\lambda_{\alpha}\xi^{\alpha};\hspace{5mm}[p\:q]=\tilde{\lambda}^{\alpha'}\tilde{\xi}_{\alpha'}
\end{equation}
Se cumplirá que
\begin{equation}
    <p\:q>[p\:q]=2p^{\mu}q_{\mu}
\end{equation}
\begin{proof}
\[\begin{array}{rl}
     
    <p\:q>[p\:q]&=\lambda_{\alpha}\xi^{\alpha}\tilde{\lambda}^{\alpha'}\tilde{\xi}_{\alpha'}=\lambda_{\alpha}\tilde{\lambda}^{\alpha'}\xi^{\alpha}\tilde{\xi}_{\alpha'}=\lambda_{\alpha}\mathscr{E}_{\beta'\alpha'}\tilde{\lambda}^{\alpha'}\xi^{\alpha}\mathscr{E}^{\beta'\alpha'}\tilde{\xi}_{\alpha'}= \\ \\
     & =\lambda_{\alpha}\tilde{\lambda}_{\beta'}\xi^{\alpha}\tilde{\xi}^{\beta'}=p_{\alpha\beta'}q^{\alpha\beta'}=Tr(\hat{p}\hat{q})=2p_{\mu}q^{\mu}
\end{array}
    \]
\end{proof}
Ahora veamos cómo transforman $\lambda(p)$ y $\tilde{\lambda}(p)$ bajo transformaciones de Lorentz:
\begin{equation}
    \begin{array}{rl}
        \lambda(p)\to &N\lambda(p)=NL(p)\eta=L(\Lambda p)\underset{W(N,p)\in\mathcal{L}_k}{\underbrace{L(\Lambda  p)^{-1}NL(p)}}\eta=L(\Lambda p)W(N,p)\eta=  \\ \\
         & =L(\Lambda p)e^{i\varphi_{N,p}/2}\eta\overset{\curlybraces{\lambda(p)=L(p)\eta}}{=}e^{i\varphi_{N,p}/2}\lambda(\Lambda p)
    \end{array}
\end{equation}
donde usamos que las traslaciones quedan invariantes ($\eta$) y las rotaciones cambian con la exponencial. Por tanto, vemos que $N\lambda(p)$ transforma a $\lambda(\Lambda p)$ más una fase.\\ \\
Análogamente, tendremos que
\begin{equation}
    \tilde{p}\to N^*\tilde{\lambda}(p)=e^{i\varphi_{N,p}/2}\tilde{\lambda}(\Lambda p)
\end{equation}

Recordando la definición de las operaciones antisimétricas $(3.127)$, podremos comprobar que transforman como,
\begin{equation}
    <p\:q>(N)=e^{-i\varphi_{N,p}/2}e^{-i\varphi_{N,q}/2}\left<\Lambda p\:\Lambda q\right>
\end{equation}
Análogamente tenemos,
\begin{equation}
    [p\: q](N)=e^{i\varphi_{N.p}/2}e^{i\varphi_{N,q}/2}\brackets{\Lambda p\:\Lambda q}
\end{equation}
Veamos un cálculo explícito con este formalismo para obtener la matriz de amplitud de una colisión. Vamos a considerar tres partículas sin masa, $q_1,q_2,q_3$, $q_i=(n_1,p_i)$, que se aniquilan y van al vacío. Antes de nada vamos a renombrar para simplificar la notación,
\begin{equation}
    h_{n_1}\equiv h_i;\hspace{5mm}\lambda(p_i)\equiv \lambda_i;\hspace{5mm}\tilde{\lambda}(p_i)\equiv\tilde{\lambda}_i;\hspace{5mm}<p_i\:p_j>\equiv<i\:j>;\hspace{5mm}i,j\in\curlybraces{1,2,3}
\end{equation}
Tenemos el sistema siguiente,
\begin{Figura}
    \centering
    \includegraphics[width=0.5\linewidth]{imagenes/col3.png}
    \captionof{figure}{Aniquilación de 3 partículas.}
    \label{Fig3.3}
\end{Figura}
Para calcular la amplitud $\mathcal{M}_{0,q_1,q_2,q_3}\equiv\mathcal{M}_{123}$, usaremos las funciones $<i\:j>$ y $[i\: j]$. Denominamos $\tilde{m}_i$ al número de veces que aparece $\tilde{\lambda}_i$, es decir, al grado de $\tilde{\lambda}_i$. Denominamos $m_i$ al grado de $\lambda_i$. Necesitaremos que se cumpla que
\begin{equation}
    \tilde{m}_i-m_i=2h_i;\hspace{4mm}i\in\curlybraces{1,2,3}
\end{equation}
Por la conservación del cuadrimomento tenemos $p_1+p_2+p_3=0$. Por otro lado,
\begin{equation}
    2p_1\cdot p_2=(p_1+p_2)^2-\cancelto{m_1^2=0}{p_1^2}-\cancelto{m_2^2=0}{p_2^2}=\cancelto{m_3^2=0}{p_3^2}=0\Rightarrow p_1\cdot p_2=0
\end{equation}
De la misma forma tenemos,
\begin{equation}
    p_2\cdot p_3=0;\hspace{5mm}p_1\cdot p_3=0
\end{equation}
Entonces, como $p_{i}p^{j}=0$, tendremos que $<i\:j>[i\:j]=0$. Luego, para cada $i$ y para cada $j$ se cumplirá que, o bien $<i\:j>=0, o bien, $[i\:j]. Veamos los casos:
\begin{itemize}
    \item \textbf{Caso 1}: $<i\:j>=0$, $\forall i,j\in\curlybraces{1,2,3}$
    \item \textbf{Caso 2}: $[i\:j]=0$, $\forall i,j\in\curlybraces{1,2,3}$
    \item \textbf{Caso 3}: $<1\:2>=<1\:3>=0$. Tenemos que $<1\:2>=0\Rightarrow\lambda_1\propto\lambda_2$ y $<1\:3>=0\Rightarrow\lambda_1\propto\lambda_3$, luego como $\lambda_1\propto\lambda_2$ y $\lambda_1\propto \lambda_3$, entonces $\lambda_2\propto\lambda_3\Rightarrow<2\:3>=0$ y volvemos al caso 1.
    \item \textbf{Caso 4}: $[1\:2]=[1\:3]=0$. Tenemos que $[1\:2]=0\Rightarrow\tilde{\lambda}_1\propto\tilde{\lambda}_2$ y $[1\:3
    ]=0\Rightarrow\tilde{\lambda}_1\propto\tilde{\lambda}_3$, luego como $\tilde{\lambda}_1\propto\tilde{\lambda}_2$ y $\tilde{\lambda}_1\propto \tilde{\lambda}_3$, entonces $\tilde{\lambda}_2\propto\tilde{\lambda}_3\Rightarrow[2\:3]=0$ y volvemos al caso 2.
    \item \textbf{Caso 5}: $<1\:2>=0$. Tenemos el caso 4, luego volvemos al caso 2.
    \item \textbf{Caso 6}: $[1\:2]=0$. Tenemos el caso 4, luego volvemos al caso 1.
\end{itemize}
Por tanto, solo tendremos los dos primeros casos, luego,
\begin{equation}
    <i\:j>[i\:j]=0\Rightarrow\left\lbrace\begin{array}{rcl}
        <i\:j>=0 & &\forall i,j\in\curlybraces{1,2,3} \\
         & ó &\\
         \left[i\:j\right]=0 & & \forall i,j\in\curlybraces{1,2,3}
    \end{array}\right.
\end{equation}
Sabemos que como $p_{\mu}\in\mathbb{R}^4$, entonces $\tilde{\lambda}^*_i=\lambda_i$, por tanto, podemos ver que
\begin{equation}
    <i\:j>=[j\:i]^*
\end{equation}
\begin{proof}
    \[<i\:j>=\lambda_i\lambda^j=\tilde{\lambda}^{*}_j\tilde{\lambda}^{*i}=[j\:i]^*\]
\end{proof}
Recordando que la definición de la amplitud de colisión $\mathcal{M}$ depende de deltas de Dirac de los momentos iniciales y finales, al tener como sistema final el vacío, que tienen helicidad nula, vemos que si las partículas iniciales tienen todas helicidad cero, $h_i=0$, entonces la amplitud de colisión será una constante, $C_{123}$; mientras que si tienen helicidad distinta de cero, $h_i\neq0$, entonces la amplitud de colisión será nula, es decir,
\begin{equation}
    \mathcal{M}_{123}=\left\lbrace\begin{array}{lcl}
        C_{123} & si & h_i=0,\:\forall i\in\curlybraces{1,2,3}  \\ \\
        0 & si & h_i\neq0,\:\forall i\in\curlybraces{1,2,3}
    \end{array}\right.
\end{equation}
Considerando ahora momentos complejos, teniendo así que $<i\:j>\neq[j\:i]^*$, por la propiedad de homogeneidad y que $\tilde{m}_i-m_i=2h_i$, la amplitud de colisión general es,
\begin{equation}
    \mathcal{M}_{123}=\left\lbrace\begin{array}{lcl}
        C_{123}<1\:2>^{h_3-h_1-h_2}<1\:3>^{h_2-h_1-h_3}<2\:3>^{h_1-h_2-h_3} & si & <i\:j>=0,\:\forall i,j\in\curlybraces{1,2,3}  \\ \\
        \tilde{C}_{123}[1\:2]^{h_3-h_1-h_2}[1\:3]^{h_2-h_1-h_3}[2\:3]^{h_1-h_2-h_3} & si & [i\:j]=0,\:\forall i,j\in\curlybraces{1,2,3}
    \end{array}\right.
\end{equation}
Como estamos con $p_{\mu}\in\mathbb{C}^4$, volvemos al límite para $p_{\mu}\in\mathbb{R}^4$, así el caso general se queda como,
\begin{equation}
    \mathcal{M}_{123}=\left\lbrace\begin{array}{lcl}
        C_{123}<1\:2>^{h_3-h_1-h_2}<1\:3>^{h_2-h_1-h_3}<2\:3>^{h_1-h_2-h_3} & si & h_1+h_2+h_3<0  \\ \\
        \tilde{C}_{123}[1\:2]^{h_3-h_1-h_2}[1\:3]^{h_2-h_1-h_3}[2\:3]^{h_1-h_2-h_3} & si & h_1+h_2+h_3>0
    \end{array}\right.
\end{equation}
Veamos algunos ejemplos para ver cómo operar.
\begin{example}[Consideramos el caso de aniquilación electrón-positrón en un fotón.]\[\hspace{1mm}\]
    \begin{center}
\begin{fmffile}{Feynman}
  \begin{fmfgraph*}(100,60)
     \fmfleft{i1,i2}
    \fmfright{o1}
    \fmf{fermion,label=$e^+$}{i1,v1}
    \fmf{fermion,label=$e^-$}{i2,v1}
    \fmf{photon,label=$\gamma$}{v1,v2}
    \fmf{phantom}{v2,o1}
    \fmflabel{2}{i1}
    \fmflabel{1}{i2}
    \fmflabel{3}{v2}
  \end{fmfgraph*}
\end{fmffile}
    \end{center}
Sabemos que la helicidad se asemeja a la tercera componente de espín, luego, como el electrón y positrón tienen espín $1/2$, podemos tomar sus helicidades como $h_1=h_2=+1/2$ (considerando que su tercera componente de espín es positiva), por otro lado, sabemos que la helicidad del fotón es $\pm1$, luego, supondremos que $h_3=+1$. Por tanto, tenemos que $h_1+h_2+h_3=2>0$, por tanto tenemos la segunda opción de $\mathcal{M}_{123}$, luego, la amplitud de colisión será,
\[\mathcal{M}_{123}=C[1\:2]^{-(1-1/2-1/2)}[2\:3]^{-(1/2-1/2-1)}[1\:3]^{-(1/2-1/2-1)}=C[1\:3][2\:3]\]
\end{example}
\begin{example}[Consideramos el caso de aniquilación electrón-positrón en un fotón, pero ahora consideramos que la tercera componente de espín del positrón es negativa.]\[\hspace{1mm}\]
    \begin{center}
\begin{fmffile}{Feynman2}
  \begin{fmfgraph*}(100,60)
     \fmfleft{i1,i2}
    \fmfright{o1}
    \fmf{fermion,label=$e^+$}{i1,v1}
    \fmf{fermion,label=$e^-$}{i2,v1}
    \fmf{photon,label=$\gamma$}{v1,v2}
    \fmf{phantom}{v2,o1}
    \fmflabel{2}{i1}
    \fmflabel{1}{i2}
    \fmflabel{3}{v2}
  \end{fmfgraph*}
\end{fmffile}
    \end{center}
Como nos dicen que la tercera componente de espín del positrón es negativa, su helicidad será $h_2=-1/2$. Las otras son iguales al ejemplo anterior, $h_1=+1/2$ y $h_3=+1$. Luego, tenemos que $h_1+h_2+h_3=1/2-1/2+1=1>0$. Así, la amplitud de colisión será,
\[\mathcal{M}_{123}=e[1\:2]^{-(1-1/2+1/2)}[2\:3]^{-(1/2+1/2-1)}[1\:3]^{-(-1/2-1/2-1)}=e[1\:2]^{-1}[1\:3]^{2}=e\frac{[1\:3]^2}{[1\:2]}\]
\end{example}
La amplitud de colisión crece muy rápido con la energía, por tanto, consideraremos que a límites de muy altas energías, la constante será nula, es decir, $\lim\limits_{E\to\infty}C_{123}=0$.\\ \\
En los ejemplos anteriores, si consideramos momentos complejos, tendremos localidad y unitariedad, por tanto podremos hacer,
\begin{center}
\begin{fmffile}{Feynman-correcto}
  \begin{fmfgraph*}(100,60)
    \fmfright{i1,i2}       % Entradas visuales (ahora serán salidas físicas)
    \fmfleft{o1}           % Salida visual (origen del vértice)

    % Flechas SALIENDO del vértice hacia la derecha
    \fmf{fermion,reverse,label=$e^+$}{v1,i1}
    \fmf{fermion,reverse,label=$e^-$}{v1,i2}

    % El fotón también sale hacia la izquierda (sin reverse)
    \fmf{photon,label=$\gamma$}{v1,v2}
    \fmf{phantom}{v2,o1}

    % Etiquetas
    \fmflabel{2}{i1}
    \fmflabel{1}{i2}
    \fmflabel{3}{v2}
  \end{fmfgraph*}
\end{fmffile}
\end{center}
que será nulo en el límite para $p_{\mu}\in\mathbb{R}^4$, por eso los fotones no se desintegran en un par electrón-positrón. Ahora, podemos juntar ambos sistemas tal que,
\begin{center}
\begin{fmffile}{caca}
\begin{fmfgraph*}(150,100)
  \fmfleft{i1,i2}
  \fmfright{o1,o2}
  \fmf{fermion,label=$e^+$}{i1,v1}
  \fmf{fermion,label=$e^-$}{i2,v1}
  \fmf{photon,label=$\gamma$}{v1,v2}
  \fmf{fermion,label=$e^+$}{v2,o1}
  \fmf{fermion,label=$e^-$}{v2,o2}
\end{fmfgraph*}
\end{fmffile}
\end{center}
Este proceso da lugar a un término con una estructura de polo en la amplitud, asociado a la propagación del fotón virtual entre los dos vértices. Dicho polo tiene la forma:
\[
\frac{1}{(p_1 + p_2)^2}
\]
y aparece como consecuencia de la conservación del cuadrimomento y de la estructura del propagador de una partícula sin masa.\\ \\
Este método se denomina \textbf{scattering amplitude} y se emplea para reemplazar el uso de espinores y hacer QFT sin la necesidad de los espinores.
\includepdf[pages=-]{Entregable3_QFT.pdf}
\chapter{Campos Escalares Libres}
\section{Introducción}
Teoría Cuántica de Campos se basa en formar una teoría que conserve tanto la probabilidad, es decir, que la matriz $S$ sea unitaria; como que exista localidad, es decir, que por causalidad, cualquier experimento que hagamos en puntos separados por distancias tipo espacio, obtengamos el mismo resultado.\\ \\
Para implementar esto a la teoría solo se conoce una forma y es escribir tanto el Hamiltoniano como los campos empleados en función de los operadores de creación y destrucción.\\ \\
Este capítulo se basará en implementar este formalismo a campos escalares libres.
\section{Campos escalares libres}
Consideremos una partícula masiva de espín cero, $q\equiv(n,p,0)$, y sean $a_{\vec{p}}$ y $a_{\vec{p}}^{\dagger}$ los operadores de destrucción y creación, respectivamente. Así podemos definir un campo escalar espacial real como,
\begin{equation}
    \phi(\vec{x})=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\left(a_{\vec{p}}e^{i\vec{p}\cdot\vec{x}}+a_{\vec{p}}^{\dagger}e^{-i\vec{p}\cdot\vec{x}}\right)
\end{equation}
de forma que $\phi$ sea un campo escalar real. Como el campo está formado por combinaciones lineales de operadores, entonces los campos serán operadores que dependen de la posición. Veamos cómo actúan:
\begin{equation}
    \Braket{\vec{q}|\phi(\vec{x})|0}=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\left(\cancelto{\overset{0}{}}{\Braket{\vec{q}|a_{\vec{p}}|0}}e^{i\vec{p}\cdot\vec{x}}-\cancelto{\overset{\delta^{(3)}(\vec{q}-\vec{p})}{}}{\Braket{\vec{q}|a_{\vec{p}}^{\dagger}|0}}\hspace{6mm}e^{-i\vec{p}\cdot\vec{x}}\right)=e^{-i\vec{x}\cdot\vec{q}}
\end{equation}
siendo la función de onda, en el espacio de momentos, de una partícula con momento $\vec{q}$ y localizada en $\vec{x}$.\\ \\
Usando la imagen de Heisenberg podemos definir los campos escalares dependientes del tiempo, donde los definiremos usando el Hamiltoniano libre, $H_0$, para tener campos escalares libres dependientes del tiempo, tal que
\begin{equation}
    \phi_0(x)\equiv\phi_0(t,\vec{x})=e^{iH_0t}\phi(\vec{x})e^{-iH_0t}
\end{equation}
Usando la definición de $\phi(\vec{x})$ tenemos,
\begin{equation}
    \phi_0(x)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}e^{iH_0t}\left(a_{\vec{p}}e^{i\vec{p}\cdot\vec{x}}-a_{\vec{p}}^{\dagger}e^{-i\vec{p}\cdot\vec{x}}\right)e^{-iH_0t}
\end{equation}
Sabiendo que $e^{iH_0t}a_{\vec{p}}^{\dagger}e^{-iH_0t}=e^{i\omega_pt}a_{\vec{p}}^{\dagger}$, tenemos que
\begin{tcolorbox}[title=Campo escalar libre]
\begin{equation}
    \phi_0(x)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\left(a_{\vec{p}}e^{-ipx}-a_{\vec{p}}^{\dagger}e^{ipx}\right)
\end{equation}
donde $p=(\omega_p,\vec{p})$ y $x=(t,\vec{x})$.
\end{tcolorbox}
Bajo una transformación de Poincaré $U(N,b)$, el campo transformará como,
\begin{equation}
    U(N,b)\phi_0(x)U(N,b)^{-1}=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\left(a_{\vec{\Lambda p}}e^{-ipx+i(\Lambda p)b}+a_{\vec{\Lambda p}}^{\dagger}e^{ipx-i(\Lambda p)b}\right)\sqrt{\frac{\omega_{\Lambda p}}{\omega_p}}\sqrt{\frac{2}{2}}
\end{equation}
con $\Lambda=\Lambda(N)$. Podemos reescribirlo de varias formas. Sabiendo que $px$ es invariante Lorentz, podemos hacer el intercambio $px\to\Lambda p\Lambda x$, tal que

\begin{equation}
\begin{array}{rl}
    U(N,b)\phi_0(x)U(N,b)^{-1}&=\int\frac{d^3p}{(2\pi)^3}\frac{\sqrt{2\omega_{\Lambda p}}}{2\omega_p}\left(a_{\vec{\Lambda p}}e^{-i(\Lambda p)(\Lambda x)+i(\Lambda p)b}+a_{\vec{\Lambda p}}^{\dagger}e^{i(\Lambda p)(\Lambda x)-i(\Lambda p)b}\right)=\\ \\
    &=\int\frac{d^3p}{(2\pi)^3}\frac{\sqrt{2\omega_{\Lambda p}}}{2\omega_p}\left(a_{\vec{\Lambda p}}e^{-i(\Lambda p)[(\Lambda x)-b]}+a_{\vec{\Lambda p}}^{\dagger}e^{i(\Lambda p)[(\Lambda x)-b]}\right)
    \end{array}
\end{equation}
Sabiendo además que $\frac{d^3p}{2\omega_p}$ es invariante Lorentz, podemos sustituir en esta expresión del campo $p\to\Lambda p$, luego
\begin{equation}
\begin{array}{rl}
    U(N,b)\phi_0(x)U(N,b)^{-1}&=\int\frac{d^3(\Lambda p)}{(2\pi)^3}\frac{\sqrt{2\omega_{\Lambda p}}}{2\omega_{\Lambda p}}\left(a_{\vec{\Lambda p}}e^{-i(\Lambda p)[(\Lambda x)-b]}+a_{\vec{\Lambda p}}^{\dagger}e^{i(\Lambda p)[(\Lambda x)-b]}\right)=\\ \\
    &=\int\frac{d^3(\Lambda p)}{(2\pi)^3}\frac{1}{\sqrt{2\omega_{\Lambda p}}}\left(a_{\vec{\Lambda p}}e^{-i(\Lambda p)[(\Lambda x)-b]}+a_{\vec{\Lambda p}}^{\dagger}e^{i(\Lambda p)[(\Lambda x)-b]}\right)=\curlybraces{\Lambda p=p'}=\\\\
    &=\int\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_{p'}}}\left(a_{\vec{p'}}e^{-i(p')[(\Lambda x)-b]}+a_{\vec{p'}}^{\dagger}e^{ip'[(\Lambda x)-b]}\right)=\\ \\
    &=\phi_0(\Lambda x-b)
    \end{array}
\end{equation}
Luego transforma como un campo escalar, pues transforma como un representación de campo donde hacemos un cambio de observador.\\ \\
El campo escalar general se define igual que el libre en la imagen de Heisenberg, pero usando el Hamiltoniano total del sistema, tal que
\begin{equation}
    \phi(x)=e^{iHt}\phi(\vec{x})e^{-iHt}
\end{equation}
Como la partícula que hemos supuesto es de espín cero y sabemos que tenemos varias definiciones para los operadores de creación y destrucción dependiendo de si se trata de un bosón o un fermión, supondremos que tenemos un \textbf{bosón}. Así, podemos calcular los conmutadores,
\begin{equation}
    \begin{array}{rl}
        \brackets{\phi(\vec{x}),\phi(\vec{y})} &=\int\int\frac{d^3p}{(2\pi)^3}\frac{d^3q}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_q}}\left(\cancelto{\overset{0}{}}{\brackets{a_{\vec{p}},a_{\vec{q}}}}e^{i(\vec{p}\cdot\vec{x}+\vec{q}\cdot\vec{y})}+\brackets{a_{\vec{p}},a_{\vec{q}}^{\dagger}}e^{i(\vec{p}\cdot\vec{x}-\vec{q}\cdot\vec{y})}+\right.\\ \\ &\left.+\brackets{a_{\vec{p}}^{\dagger},a_{\vec{q}}}e^{i(-\vec{p}\cdot\vec{x}+\vec{q}\cdot\vec{y})}+\cancelto{0}{\brackets{a_{\vec{p}}^{\dagger},a_{\vec{q}}^{\dagger}}}e^{-i(\vec{p}\cdot\vec{x}+\vec{q}\cdot\vec{y})}\right)=  \\ \\
         & =\int\int\frac{d^3p}{\cancel{(2\pi)^3}}\frac{d^3q}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_q}}\left(\cancel{(2\pi)^3}\delta^{(3)}(\vec{p}-\vec{q})e^{i(\vec{p}\cdot\vec{x}-\vec{q}\cdot\vec{y})}-\cancel{(2\pi)^3}\delta^{(3)}(\vec{q}-\vec{p})e^{i(-\vec{p}\cdot\vec{x}+\vec{q}\cdot\vec{y})}\right)=\\ \\
         &=\int\int\frac{d^3p}{\sqrt{2\omega_p}}\frac{d^3q}{(2\pi)^3}\frac{1}{\sqrt{2\omega_q}}\delta^{(3)}(\vec{p}-\vec{q})\left(e^{i(\vec{p}\cdot\vec{x}-\vec{q}\cdot\vec{y})}-e^{i(-\vec{p}\cdot\vec{x}+\vec{q}\cdot\vec{y})}\right)=\\ \\
         &=\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_p}\left(e^{i\vec{p}\cdot(\vec{x}-\vec{y})}-e^{-i\vec{p}\cdot(\vec{x}-\vec{y})}\right)\sim\int\limits_{-\infty}^{+\infty}dx\sin(x)=0
    \end{array}
\end{equation}
donde hemos usado que $\delta^{(3)}(\vec{q}-\vec{p})=\delta^{(3)}(\vec{p}-\vec{q})$.\\ \\
Análogamente,
\begin{equation}
    \brackets{\phi_0(x),\phi_0(y)}=0
\end{equation}
Tomaremos un momento generalizado del Hamiltoniano libre, $\pi_0(t,\vec{x})$, tal que
\begin{equation}
    \pi_0(t,\vec{x})=\partial_t\phi_0(t,\vec{x});\hspace{5mm}\pi(\vec{x})=\pi_0(0,\vec{x})
\end{equation}
Tenemos que
\begin{equation}
    \brackets{\phi(\vec{x}),\pi(\vec{y})}=i\delta^{(3)}(\vec{x}-\vec{y})
\end{equation}
Análogamente,
\begin{equation}
    \brackets{\phi_0(t,\vec{x}),\pi_0(t,\vec{y})}=i\delta^{(3)}(\vec{x}-\vec{y})
\end{equation}
Además, si los tiempos son distintos, $t_1\neq t_2$, tendremos
\begin{equation}
    \brackets{\phi_0(t_1,\vec{x}),\phi_0(t_2,\vec{y})}=\brackets{\phi_0(x),\phi_0(y)}=\int\frac{d^3q}{(2\pi)^3}\frac{1}{2\omega_p}\left(e^{-iq(x-y)}-e^{iq(x-y)}\right)
\end{equation}
Para encontrar la solución de esta integral deberemos analizar varios casos. Veamos el caso de $(x-y)^2<0$, es decir, tenemos los puntos separados por una distancia tipo espacio. Por tanto, siempre podremos encontrar un sistema de referencia donde algún observador vea que los tiempos son iguales. $t_1=t_2$, luego $\brackets{\phi_0(x),\phi_0(y)}=0$. Esto se conoce como \textbf{condición de microcausalidad}, que es necesaria para construir Hamiltonianos que sean capaces de formar matrices $S$ que sean invariante Lorentz.\\ \\
Para los fermiones cabría esperar que $\curlybraces{\phi_0(x),\phi_0(y)}=0$ para la condición de $(x-y)^2<0$; pero esto no se cumple, dado que el espín que hemos considerado en esta teoría es espín 0, necesitaremos sí o sí que las partículas sean bosones.\\ \\
Si recordamos el Teorema de Espín-Estadística,
\begin{theorem}[Teorema Espín-Estadística]
    Los espines enteros corresponden con \textbf{bosones} y los espines semienteros corresponden con \textbf{fermiones}. Análogo con la helicidad.
\end{theorem}
\subsection{Hamiltoniano}
El Hamiltoniano libre vendrá definido por,
\begin{equation}
    H_0=\int\frac{d^3p}{(2\pi)^3}\omega_pa_{\vec{p}}^{\dagger}a_{\vec{p}}
\end{equation}
Consideremos el siguiente operador,
\begin{equation}
    \tilde{H}_0=\frac{1}{2}\int d^3x\brackets{\pi(\vec{x})^2+\left(\nabla\phi(\vec{x})\right)^2+m^2\phi(\vec{x})}
\end{equation}
Sustituyendo los valores de $\pi(\vec{x})$ y $\phi(\vec{x})$ definidos anteriormente, obtenemos
\begin{equation}
    \tilde{H}_0=\frac{1}{2}\int\frac{d^3p}{(2\pi)^3}\omega_p\brackets{a_{\vec{p}}^{\dagger}a_{\vec{p}}+a_{\vec{p}}a_{\vec{p}}^{\dagger}}=\int\frac{d^3p}{(2\pi)^3}\omega_p\brackets{a_{\vec{p}}^{\dagger}a_{\vec{p}}+\frac{1}{2}(2\pi)^3\delta^{(3)}(\vec{0})}=H_0+\frac{1}{2}\int d^3p\omega_p\delta^{(3)}(\vec{0})
\end{equation}
donde hemos usado la regla de conmutación de los operadores de creación y destrucción. Además, el segundo sumando es una constante.\\ \\
Tenemos varias formas de hacer el cálculo:
\begin{itemize}
    \item Si estamos con teorías sin gravedad, podemos decir que sumar o restar una constante en la energía no afecta, obteniendo que $\tilde{H}_0=H_0$.
    \item Podemos definir $\tilde{H}_0$ para que dé bien usando el \textbf{ordennamiento normal}, este ordenamiento se denota por $:\cdot :$ y quiere decir que colocamos todos los operadores de creación los colocamos a la izquierda de los operadores de destrucción, es decir,
    \begin{equation}
        :a_{\vec{p}}a_{\vec{q}}^{\dagger}a_{\vec{h}}:\:=a_{\vec{q}}^{\dagger}a_{\vec{p}}a_{\vec{h}}
    \end{equation}
    Así, tenemos que
    \begin{equation}
        H_0=:\tilde{H}_0:
    \end{equation}
    por lo que el valor de $H_0$ 'no es negociable', siendo un caso sencillo de 'reorganización' en teoría de campos.
\end{itemize}
Es fácil ver que $H_0\ket{0}=0$, obteniendo que el vacío es invariante en el tiempo. Sin embargo, vemos que $\tilde{H}_0\ket{0}\neq0$, obteniendo un vacío con energía infinita, si no usamos el ordenamiento normal, pues la integral no converge.\\ \\
En teoría de colisiones el vacío es el estado con energía mínima, que no tiene por qué ser nula. Esta energía del vacío es importante solo en teorías con gravedad. Por ejemplo, en cosmología la energía del vacío provoca la aceleración de la expansión del universo, dada por la constante cosmológica, que da problemas de ajuste fino porque no se conoce su valor exacto.\\ \\
Nosotros usaremos $H_0=:\tilde{H}_0:$ y así la constante será nula.\\ \\
Podemos escribir las ecuaciones de Hamilton,
\begin{equation}
    \dot{\phi}_0=\frac{\delta H_0}{\delta\pi_0}=\pi_0;\hspace{6mm}\dot{\pi}_0=-\frac{\delta H_0}{\delta\phi_0}=-m^2\phi_0+\partial_i\partial_i\phi_0
\end{equation}
donde las $\delta$'s representan las derivadas funcionales. Además será indistinguible poner $H_0$ ó $\tilde{H}_0$, pues las constantes en las derivadas no influyen.\\ \\
Iterando las ecuaciones obtenemos que
\begin{equation}
    \partial_0^2\phi_0-\partial_i\partial_i+m^2\phi_0=0\Rightarrow\square\phi_0+m^2\phi_0=0
\end{equation}
obteniendo la ecuación de \textbf{Klein-Gordon}. Esto es una forma de ver que estamos siendo coherentes con la teoría.\\ \\
Si hacemos las transformadas siguientes,
\begin{equation}
    L_0(t)=\int d^3x\mathscr{L}_0\left(\phi_0(t,\vec{x}),\dot{\phi}_0(t,\vec{x}),\nabla\phi_0(t,\vec{x})\right)
\end{equation}
siendo
\begin{equation}
    \mathscr{L}_0=\frac{1}{2}\partial_{\mu}\phi_0\partial^{\mu}\phi_0-\frac{1}{2}m^2\phi_0^2
\end{equation}
la densidad lagrangiana. Obtenemos una acción invariante de Lorentz e invariante de traslaciones espacio-temporales usando este Lagrangiano, teniendo así una ventaja frente al formalismo Hamiltoniano, donde no se aprecia tan explícitamente, por esto mismo en teorías como el Modelo Estándar, se emplean los Lagrangianos y no los Hamiltonianos. En concreto, la acción será invariante de Poincaré, pero el Lagrangiano no lo será.
\begin{note}
Hemos definido los estados de muchas partículas y en su espacio de Fock, hemos definido los operadores de creación y destrucción, viendo cómo transforman. Por otro lado, para construir los Hamiltonianos, hemos introducido los campos cuánticos, formados por operadores de creación y destrucción, viendo que para espín cero tenemos un campo escalar, estando todo 'on-shell' al haber usado el $H_0$, es decir, se satisfacen las ecuaciones del movimiento. Luego, hemos visto a $H_0$ en términos de los operadores de creación y destrucción, pudiendo escribirlo con los campos cuánticos y sus momentos conjugados, que satisfacen las conmutaciones canónicas, siguiendo en 'on-shell'. Ahora usamos el $H_0$ 'off-shell', siendo un funcional de los campos y de los momentos. Pero si vemos las ecuaciones del movimiento para este funcional, volvemos a obtener los campos 'on-shell', tal y como los definimos. Así, hemos encontrado \textbf{un camino para ir de partículas a campos}.\\ \\
A partir de las reglas de conmutación canónicas podemos definir campos, obteniendo Lagrangianos con ecuaciones del movimiento, cuyas soluciones tienen forma de exponenciales con operadores de creación y destrucción, obteniendo estados multipartículas, en el espacio de Fock, que actúan como partículas de espín cero, al considerar campos escalares. Luego, hemos encontrado \textbf{un camino para pasar de campos a partículas}.
\end{note}
Ahora supongamos que tenemos dos partículas de espín cero y masas iguales, $(n_1,n_2)$, y definimos los campos $\phi_1$ y $\phi_2$ escalares asociados a cada partícula. Al tener dos campos reales, podemos definir un campo escalar complejo formado por estos campos reales, tal que
\begin{equation}
    \phi(x)=\frac{1}{\sqrt{2}}\brackets{\phi_1(x)+i\phi_2(x)}=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\brackets{\frac{1}{\sqrt{2}}\left(c_{1,\vec{p}}+ic_{2,\vec{p}}\right)e^{-ipx}+\frac{1}{\sqrt{2}}\left(c_{1,\vec{p}}^{\dagger}+ic_{2,\vec{p}}^{\dagger}\right)e^{ipx}}
\end{equation}
donde $c_{1,\vec{p}}$ y $c_{2,\vec{p}}$ son los operadores de destrucción de $\phi_1(x)$ y $\phi_2(x)$, respectivamente. Renombramos los operadores como,
\begin{equation}
    a_{\vec{p}}=\frac{1}{\sqrt{2}}(c_{1,\vec{p}}+ic_{2,\vec{p}});\hspace{6mm}b_{\vec{p}}=\frac{1}{\sqrt{2}}(c_{1,\vec{p}}-ic_{2,\vec{p}})
\end{equation}
Luego, el campo complejo quedará
\begin{equation}
    \phi(x)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\brackets{a_{\vec{p}}e^{-ipx}+b_{\vec{p}}^{\dagger}e^{ipx}}
\end{equation}
Obteniendo una expresión parecida al campo escalar real, pero con la diferencia de que $a_{\vec{p}}$ y $b_{\vec{p}}^{\dagger}$ son independientes.\\ \\
Al tener un campo complejo, podemos ver el adjunto del campo
\begin{equation}
    \phi^{\dagger}(x)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\brackets{b_{\vec{p}}e^{-ipx}+a_{\vec{p}}^{\dagger}e^{ipx}}
\end{equation}
Las reglas de conmutación de los operadores renombrados serán,
\begin{equation}
    \brackets{a_{\vec{p}},b_{\vec{p}'}^{\dagger}}=\brackets{b_{\vec{p}},a_{\vec{p}'}^{\dagger}}=0;\hspace{5mm}\brackets{a_{\vec{p}},a_{\vec{p}'}^{\dagger}}=(2\pi)^3\delta^{(3)}(\vec{p}-\vec{p}');\hspace{5mm}\brackets{b_{\vec{p}},b_{\vec{p}'}^{\dagger}}=(2\pi)^3\delta^{(3)}(\vec{p}-\vec{p}')
\end{equation}
con
\begin{equation}
    a_{\vec{p}}^{\dagger}\ket{0}=\frac{1}{\sqrt{2}}\frac{1}{\sqrt{2\omega_p}}\left(\ket{\vec{p}}_1-i\ket{\vec{p}}_2\right)\equiv\frac{1}{\sqrt{2\omega_p}}\ket{\vec{p}}_{n};\hspace{6mm}b_{\vec{p}}^{\dagger}\ket{0}=\frac{1}{\sqrt{2}}\frac{1}{\sqrt{2\omega_p}}\left(\ket{\vec{p}}_1+i\ket{\vec{p}}_2\right)\equiv\ket{\vec{p}}_{\bar{n}}
\end{equation}
decimos que $n$ y $\bar{n}$ son partícula y antipartícula. Luego, vemos que $\phi(x)$ crea una antipartícula y destruye una partículas, mientras que $\phi^{\dagger}(x)$ crea una partícula y destruye una antipartícula.\\ \\
Las reglas de conmutación de los campos complejos serán,
\begin{equation}
\begin{array}{rl}
    \brackets{\phi(x),\phi(y)}&=\int\int\frac{d^3p}{(2\pi)^3}\frac{d^3q}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_q}}\left(\cancelto{0}{\brackets{a_{\vec{p}},a_{\vec{q}}}}e^{i(px-qy)}+\cancelto{0}{\brackets{a_{\vec{p}},b_{\vec{q}}^{\dagger}}}e^{i(px-qy)}\right.+\\ \\
    &+\left.\cancelto{0}{\brackets{b_{\vec{p}}^{\dagger},a_{\vec{q}}}}e^{i(-px+qy)}+\cancelto{0}{\brackets{b_{\vec{p}}^{\dagger},b_{\vec{q}}^{\dagger}}}e^{-i(px+qy)}\right)=0
    \end{array}
\end{equation}
Con su conjugado será,
\begin{equation}
    \brackets{\phi(x),\phi^{\dagger}(y)}\neq0
\end{equation}
es distinto de cero en general, pero si tenemos distancias tipo espacio, $(x-y)^2<0$, sí se anula.\\ \\
Suponiendo simetría global, continua y exacta de $H_0$, teniendo una carga asociada a cada partícula que conmuta con $H_0$, tal que $n$, bajo el operador $Q$, tiene carga $q$ y $\bar{n}$, tiene carga $\bar{q}$. Luego,
\begin{equation}
    q(a_{\vec{p}}^{\dagger}\ket{0})=Q(a_{\vec{p}}^{\dagger}\ket{0})=Qa_{\vec{p}}^{\dagger}\ket{0}=\brackets{Q,a_{\vec{p}}^{\dagger}}\ket{0}+a_{\vec{p}}^{\dagger}\cancelto{0}{Q\ket{0}}\Rightarrow\brackets{Q,a_{\vec{p}}^{\dagger}}=qa_{\vec{p}}^{\dagger}
\end{equation}
donde hemos cancelado el segundo sumando porque en el vacío no hay cargas. Además, usando estados multipartículas llegamos a
\begin{equation}
    \brackets{Q,a_{\vec{p}}}=-qa_{\vec{p}}
\end{equation}
Análogamente para $\bar{n}$ llegamos a
\begin{equation}
    \brackets{Q,b_{\vec{p}}^{\dagger}}=\bar{q}b_{\vec{p}}^{\dagger};\hspace{6mm}\brackets{Q,b_{\vec{p}}}=-\bar{q}b_{\vec{p}}    
\end{equation}
Viendo $Q\phi(x)$, obtenemos un $-q$ (de $a_{\vec{p}}$) y un $\bar{q}$ (de $b_{\vec{p}}^{\dagger}$), teniendo un campo inhomogéneo, pero como queremos que sea homogéneo, imponemos que $\bar{q}=-q$, tal que
\begin{equation}
    \brackets{Q,\phi}=-q\phi;\hspace{6mm}\brackets{Q,\phi^{\dagger}}=q\phi^{\dagger}
\end{equation}
En resumen, siempre que tengamos campos escalares complejos, obtendremos dos partículas de espín cero, con la misma masa y cargas opuestas, es decir, tendremos pares partícula-antipartícula. Si obtuviéramos que las cargas son nulas siempre, tendríamos que la partícula es su propia antipartícula, teniendo que $a_{\vec{p}}=b_{\vec{p}}$.\\ \\
Veamos el Hamiltoniano,
\begin{equation}
    H_0=\int\frac{d^3p}{(2\pi)^3}\omega_p\left(a_{\vec{p}}^{\dagger}a_{\vec{p}}+b_{\vec{p}}^{\dagger}b_{\vec{p}}\right)
\end{equation}
Aplicando la transformada de Legendre, obtenemos un Lagrangiano, cuya densidad lagrangiana es,
\begin{equation} \mathscr{L}_0=\partial_{\mu}\phi^{\dagger}\partial^{\mu}\phi-m^2\phi^{\dagger}\phi
\end{equation}
Sabemos que para este tipo de Lagrangianos, las transformaciones de los campos,
\begin{equation}
    \phi'=e^{i\alpha}\phi;\hspace{6mm}\phi^{\dagger'}=e^{-i\alpha}\phi^{\dagger};\hspace{6mm}\alpha\in\mathbb{R}   
\end{equation}
dejan invariante al Lagrangiano, pues
\begin{equation}
    \begin{array}{rl}
        \mathscr{L}'_0 &=\partial_{\mu}\phi^{\dagger'}\partial^{\mu}\phi'+m^2\phi^{\dagger'}\phi'=\partial_{\mu}\left(\phi^{\dagger}e^{-i\alpha}\right)\partial^{\mu}\left(\phi e^{i\alpha}\right)-m^2\phi^{\dagger}\cancel{e^{-i\alpha}}\phi\cancel{e^{i\alpha}}= \\  \\
         & \cancel{e^{-i\alpha}}\cancel{e^{i\alpha}}\partial_{\mu}\phi^{\dagger}\partial^{\mu}\phi-m^2\phi^{\dagger}\phi=\partial_{\mu}\phi^{\dagger}\partial^{\mu}\phi-m^2\phi^{\dagger}\phi=\mathscr{L}_0
    \end{array}
\end{equation}
Podemos encontrar ahora las corrientes de Noether asociadas a esta transformación de simetría, sabiendo que para transformaciones generales del tipo, $\phi'=\phi+\delta\phi$, la corriente de Noether asociada es
\begin{equation}
    J^{\mu}=\sum_i\frac{\partial\mathscr{L}}{\partial(\partial_{\mu}\phi_i)}\delta\phi_i
\end{equation}
Luego, en nuestro caso tendremos que
\begin{equation}
    \begin{array}{rl}
        \phi' &=\phi+\delta\phi=\phi e^{i\alpha}\approx\phi+i\alpha\phi\Rightarrow\delta\phi=i\alpha\phi  \\
        \phi^{\dagger'} & =\phi^{\dagger}+\delta\phi^{\dagger}=\phi^{\dagger}e^{-i\alpha}\approx\phi^{\dagger}-i\alpha\phi^{\dagger}\Rightarrow\delta\phi^{\dagger}=-i\alpha\phi^{\dagger}
    \end{array}
\end{equation}
Por tanto, la corriente conservada será,
\begin{equation}
    J^{\mu}=\frac{\partial\mathscr{L}_0}{\partial(\partial_{\mu}\phi)}\delta\phi+\frac{\partial\mathscr{L}_0}{\partial(\partial_{\mu}\phi^{\dagger})}\delta\phi^{\dagger}=i\alpha\brackets{\phi\partial^{\mu}\phi^{\dagger}-\phi^{\dagger}\partial^{\mu}\phi}
\end{equation}
que podemos dividir en dos corrientes, una para cada campo complejo, $J^{\mu}=j^{\mu}+j^{\dagger\mu}$, tal que
\begin{equation}
    j^{\mu}=i\alpha\phi\partial^{\mu}\phi^{\dagger};\hspace{6mm}j^{\dagger\mu}=-i\alpha\phi^{\dagger}\partial^{\mu}\phi
\end{equation}
Luego, definimos las cargas como,
\begin{equation}
    Q(t)=\int d^3xj^0(t,\vec{x});\hspace{6mm}Q^{\dagger}(t)=\int d^3xj^{\dagger0}(t,\vec{x})
\end{equation}
\begin{equation}
    Q(t)=\int d^3xJ^0(t,\vec{x})
\end{equation}
Luego,
\begin{equation}
        Q(t)=  \int d^3xJ^0(x)=i\alpha\int d^3x\brackets{\underset{Q_1}{\underbrace{\phi\partial^{0}\phi^{\dagger}}}-\underset{Q_2}{\underbrace{\phi^{\dagger}\partial^0\phi}}}
\end{equation}
Luego,
\begin{equation}
\begin{array}{rl}
     
    Q_1&=\int d^3xi\alpha\phi\partial^0\phi^{\dagger}=i\alpha\int d^3x\phi\partial^0\phi^{\dagger}=i\alpha\int d^3x\phi\frac{\partial}{\partial t}\brackets{\int\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_{p'}}}\left(b_{\vec{p}'}e^{-i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}+a_{\vec{p}'}^{\dagger}e^{i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}\right)}=  \\ \\
     & =i\alpha\int d^3x\phi\brackets{\int\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_{p'}}}\left(b_{\vec{p}'}\frac{\partial}{\partial t}e^{-i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}+a_{\vec{p}'}^{\dagger}\frac{\partial}{\partial t}e^{i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}\right)}=\\ \\
     &=i\alpha\int d^3x\phi\brackets{\int\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_{p'}}}\left(b_{\vec{p}'}(-i\omega_{p'})e^{-i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}+a_{\vec{p}'}^{\dagger}(i\omega_{p'})e^{i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}\right)}=\\ \\
     &=-\alpha\omega_{p'}\int d^3x\phi\brackets{\int\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_{p'}}}\left(a_{\vec{p}'}^{\dagger}e^{ip'x'}-b_{\vec{p}'}e^{-ip'x'}\right)}=\\ \\
     &=-\alpha\omega_{p'}\int d^3x\brackets{\int\int\frac{d^3p}{(2\pi)^3}\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_{p'}}}\left(a_{\vec{p}}e^{-ipx}+b_{\vec{p}}^{\dagger}e^{ipx}\right)\left(a_{\vec{p}'}^{\dagger}e^{ip'x'}-b_{\vec{p}'}e^{-ip'x'}\right)}=\\ \\
     &=-\alpha\omega_{p'}\int d^3x\left[\int\int\frac{d^3p}{(2\pi)^3}\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_{p'}}}\left(a_{\vec{p}}a_{\vec{p}'}^{\dagger}e^{-i(px-p'x')}-\right.\right.\\ \\
     &\left.\left.-a_{\vec{p}}b_{\vec{p}'}e^{-i(px+p'x')}+b_{\vec{p}}^{\dagger}a_{\vec{p}'}^{\dagger}e^{i(px+p'x')}-b_{\vec{p}}^{\dagger}b_{\vec{p}'}e^{i(px-p'x')}\right)\right]
\end{array}
\end{equation}
y análogamente,
\begin{equation}\small
\begin{array}{rl}
     
    Q_2&=-\int d^3xi\alpha\phi^{\dagger}\partial^0\phi=i\alpha\int d^3x\phi^{\dagger}\partial^0\phi=-i\alpha\int d^3x\phi^{\dagger}\frac{\partial}{\partial t}\brackets{\int\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_{p'}}}\left(a_{\vec{p}'}e^{-i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}+b_{\vec{p}'}^{\dagger}e^{i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}\right)}=  \\ \\
     & =-i\alpha\int d^3x\phi^{\dagger}\brackets{\int\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_{p'}}}\left(a_{\vec{p}'}\frac{\partial}{\partial t}e^{-i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}+b_{\vec{p}'}^{\dagger}\frac{\partial}{\partial t}e^{i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}\right)}=\\ \\
     &=-i\alpha\int d^3x\phi^{\dagger}\brackets{\int\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_{p'}}}\left(a_{\vec{p}'}(-i\omega_{p'})e^{-i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}+b_{\vec{p}'}^{\dagger}(i\omega_{p'})e^{i(\omega_{p'} t-\vec{p}'\cdot\vec{x}')}\right)}=\\ \\
     &=\alpha\omega_{p'}\int d^3x\phi^{\dagger}\brackets{\int\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_{p'}}}\left(b_{\vec{p}'}^{\dagger}e^{ip'x'}-a_{\vec{p}'}e^{-ip'x'}\right)}=\\ \\
     &=\alpha\omega_{p'}\int d^3x\brackets{\int\int\frac{d^3p}{(2\pi)^3}\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_{p'}}}\left(b_{\vec{p}}e^{-ipx}+a_{\vec{p}}^{\dagger}e^{ipx}\right)\left(b_{\vec{p}'}^{\dagger}e^{ip'x'}-a_{\vec{p}'}e^{-ip'x'}\right)}=\\ \\
     &=\alpha\omega_{p'}\int d^3x\left[\int\int\frac{d^3p}{(2\pi)^3}\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_{p'}}}\left(b_{\vec{p}}b_{\vec{p}'}^{\dagger}e^{-i(px-p'x')}-\right.\right.\\ \\
     &\left.\left.-b_{\vec{p}}a_{\vec{p}'}e^{-i(px+p'x')}+a_{\vec{p}}^{\dagger}b_{\vec{p}'}^{\dagger}e^{i(px+p'x')}-a_{\vec{p}}^{\dagger}a_{\vec{p}'}e^{i(px-p'x')}\right)\right]
\end{array}
\end{equation}
Luego, 
\begin{equation}
    \begin{array}{rl}
        Q(t) & =Q_1+Q_2=-\alpha\omega_{p'}\int d^3x\left[\int\int\frac{d^3p}{(2\pi)^3}\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_{p'}}}\left(a_{\vec{p}}a_{\vec{p}'}^{\dagger}e^{-i(px-p'x')}-\right.\right.\\ \\
     &\left.\left.-a_{\vec{p}}b_{\vec{p}'}e^{-i(px+p'x')}+b_{\vec{p}}^{\dagger}a_{\vec{p}'}^{\dagger}e^{i(px+p'x')}-b_{\vec{p}}^{\dagger}b_{\vec{p}'}e^{i(px-p'x')}\right)-\left(b_{\vec{p}}b_{\vec{p}'}^{\dagger}e^{-i(px-p'x')}-\right.\right.\\ \\
     &\left.\left.-b_{\vec{p}}a_{\vec{p}'}e^{-i(px+p'x')}+a_{\vec{p}}^{\dagger}b_{\vec{p}'}^{\dagger}e^{i(px+p'x')}-a_{\vec{p}}^{\dagger}a_{\vec{p}'}e^{i(px-p'x')}\right)\right]=\\ \\
     &=-\alpha\omega_{p'}\int d^3x\left[\int\int\frac{d^3p}{(2\pi)^3}\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_{p'}}}\left(a_{\vec{p}}a_{\vec{p}'}^{\dagger}e^{-i(px-p'x')}+a_{\vec{p}}^{\dagger}a_{\vec{p}'}e^{i(px-p'x')}-\right.\right.\\ \\
     &\left.\left.-\cancelto{0}{\brackets{a_{\vec{p}},b_{\vec{p}'}}}e^{-i(px+p'x')}-\cancelto{0}{\brackets{a_{\vec{p}}^{\dagger},b_{\vec{p}'}^{\dagger}}}e^{i(px+p'x')}-b_{\vec{p}}^{\dagger}b_{\vec{p}'}e^{i(px-p'x')}-b_{\vec{p}}b_{\vec{p}'}^{\dagger}e^{-i(px-p'x')}\right)\right]=\\ \\
     &=-\alpha\omega_{p'}\int d^3x\left[\int\int\frac{d^3p}{(2\pi)^3}\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_{p'}}}\left(a_{\vec{p}}a_{\vec{p}'}^{\dagger}e^{-i(px-p'x')}+\left(a_{\vec{p}}a_{\vec{p}'}^{\dagger}e^{-i(px-p'x')}\right)^*-\right.\right.\\ \\
     &\left.\left.-b_{\vec{p}}^{\dagger}b_{\vec{p}'}e^{i(px-p'x')}-\left(b_{\vec{p}}^{\dagger}b_{\vec{p}'}e^{i(px-p'x')}\right)^*\right)\right]
    \end{array}
\end{equation}
Observamos que se pueden reagrupar los términos utilizando la propiedad
\begin{equation}
    X + X^* = 2\ \mathrm{Re}(X),
\end{equation}
por lo que la expresión queda como
\begin{equation}
    Q(t) = -2\alpha\omega_{p'}\int d^3x\left[\iint\frac{d^3p}{(2\pi)^3}\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_{p'}}}\left(\mathrm{Re}\left[a_{\vec{p}}a_{\vec{p}'}^{\dagger}e^{-i(px-p'x')}\right] - \mathrm{Re}\left[b_{\vec{p}}^{\dagger}b_{\vec{p}'}e^{i(px-p'x')}\right]\right)\right].
\end{equation}

La parte real de las exponenciales se puede expresar en términos de funciones coseno:
\begin{equation}
    \mathrm{Re}\left[e^{\pm i(px-p'x')}\right] = \cos(px - p'x'),
\end{equation}
por lo que la carga toma la forma
\begin{equation}
    Q(t) = -2\alpha\omega_{p'}\int d^3x\left[\iint\frac{d^3p}{(2\pi)^3}\frac{d^3p'}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\frac{1}{\sqrt{2\omega_{p'}}}\left(a_{\vec{p}}a_{\vec{p}'}^{\dagger} - b_{\vec{p}}^{\dagger}b_{\vec{p}'}\right)\cos(px - p'x')\right].
\end{equation}

La integral sobre $d^3x$ da lugar a una delta de Dirac:
\begin{equation}
    \int d^3x\ \cos(px - p'x') = (2\pi)^3\delta^3(\vec{p} - \vec{p}'),
\end{equation}
y, al aplicarla, se simplifica la carga como
\begin{equation}
    Q(t) = -2\alpha\omega_{p}\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_p}\left(a_{\vec{p}}a_{\vec{p}}^{\dagger} - b_{\vec{p}}^{\dagger}b_{\vec{p}}\right).
\end{equation}

Finalmente, escribimos
\begin{equation}
    Q(t) = -\alpha\int\frac{d^3p}{(2\pi)^3}\left(a_{\vec{p}}a_{\vec{p}}^{\dagger} - b_{\vec{p}}^{\dagger}b_{\vec{p}}\right).
\end{equation}

Utilizando las relaciones de conmutación
\begin{equation}
    [a_{\vec{p}},a_{\vec{p}'}^{\dagger}] = (2\pi)^3\delta^3(\vec{p} - \vec{p}'), \hspace{10mm} [b_{\vec{p}},b_{\vec{p}'}^{\dagger}] = (2\pi)^3\delta^3(\vec{p} - \vec{p}'),
\end{equation}
y el hecho de que
\begin{equation}
    a_{\vec{p}}a_{\vec{p}}^{\dagger} = a_{\vec{p}}^{\dagger}a_{\vec{p}} + (2\pi)^3\delta^3(0),
\end{equation}
podemos eliminar la contribución del vacío mediante el orden normal (normal ordering), obteniendo finalmente
\begin{equation}
    Q(t) = -\alpha\int\frac{d^3p}{(2\pi)^3}\left(a_{\vec{p}}^{\dagger}a_{\vec{p}} - b_{\vec{p}}^{\dagger}b_{\vec{p}}\right).
\end{equation}

Este resultado deja claro que el operador carga es proporcional a la diferencia entre el número de partículas y antipartículas. Por tanto, si definimos
\begin{equation}
    Q_1 = -\alpha\int\frac{d^3p}{(2\pi)^3}a_{\vec{p}}^{\dagger}a_{\vec{p}}, \hspace{10mm} Q_2 = +\alpha\int\frac{d^3p}{(2\pi)^3}b_{\vec{p}}^{\dagger}b_{\vec{p}},
\end{equation}
resulta evidente que
\begin{equation}
    Q_1 = - Q_2,
\end{equation}
es decir, que las partículas y antipartículas tienen cargas opuestas, tal como se anticipaba.
\section{Propagadores}
Definimos el \textbf{propagador} de un campo escalar real como,
\begin{equation}
    D(x-y)=\Braket{0|\phi_0(x)\phi_0(y)|0}
\end{equation}
donde $\Bra{0}\phi_0(x)$ destruye una partícula y $\phi_0(y)\ket{0}$ crea una partícula. Lo podemos escribir explícitamente como,
\begin{equation}
    D(x-y)=\Braket{0|\phi_0(x)\phi_0(y)|0}=\int\frac{d^3p}{(2\pi)^3}\frac{d^3q}{(2\pi)^3}\underbrace{\Braket{0|a_{\vec{p}}a_{\vec{q}}^{\dagger}|0}}_{\delta^{(3)}(\vec{p}-\vec{q})}e^{-ipx+iqy}=\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_{\vec{p}}}e^{-ip(x-y)}
\end{equation}
\begin{note}
    Si tenemos distancias tipo espacio, es decir, $(x-y)^2<0$, entonces podemos encontrar un sistema de referencia donde $t_1=t_2$, obteniendo así que los propagadores $D(x-y)=D(y-x)$.
\end{note}
Vemos que
\begin{equation}
    \Braket{0|\brackets{\phi_0(x),\phi_0(y)}|0}=D(x-y)-D(y-x)=\left\lbrace\begin{array}{lcl}
        =0 & \text{si} & (x-y)^2<0 \\
        \neq0 & \text{si} & \text{no}
    \end{array}\right.
\end{equation}
\subsection{Propagador de Feynman}
Definimos el propagador de Feynman a partir del propagador anterior, tal que
\begin{equation}
    \Delta(x-y)=\Braket{0|T\phi(x)\phi(y)|0}
\end{equation}
donde $T$ es el operador de \textbf{ordenación temporal}, y actúa como,
\begin{equation}
    TA(x)B(y)=\left\lbrace\begin{array}{lcl}
        A(x)B(y) & \text{si} & x^0>y^0\\
        B(y)A(x) & \text{si} & x^0<y^0
    \end{array}\right.
\end{equation}
es decir, coloca los tiempos posteriores a la izquierda.\\ \\
Luego, debemos distinguir estos dos casos, para ello, usamos la función escalón, tal que
\begin{equation}
    \Delta(x-y)=\Theta(x^0-y^0)D(x-y)+\Theta(y^0-x^0)D(y-x)
\end{equation}
obteniendo un operador que dependerá solo de los puntos $x$ e $y$.\\ \\
Para distancias tipo tiempo, se verá explícitamente cuál de los dos propagadores contribuye más, y para distancias tipo espacio, tendremos que los sumandos contribuirán más, o menos, dependiendo del observador, pero como $D(x-y)=D(y-x)$, entonces no veremos diferencias. Explícitamente, el operador de Feynman queda,
\begin{equation}
    \Delta(x-y)=\int_C\frac{d^4p}{(2\pi)^4}\frac{i}{p^2-m^2}e^{-ip(x-y)}
\end{equation}
donde integramos sobre la curva $C$ porque no está definido en todo el espacio-tiempo, pues para los puntos $p^2=m^2$ tendremos discontinuidades. La integral de camino sobre la curva $C$ es solo temporal, por lo que $p^2-m^2=p_0^2-\omega_p^2$ y la curva de integración es la Figura \ref{fig4.1}
\begin{Figura}
    \centering
    \includegraphics[width=0.7\textwidth]{imagenes/fig4.1.png}
    \captionof{figure}{Curva $C$.}
    \label{fig4.1}
\end{Figura}
donde esquivamos las discontinuidades de $p^0=\pm\omega_p$, también llamadas \textbf{polos simples}, usando circunferencias. Veamos la intuición que hay tras este razonamiento.
\begin{equation}
    \frac{1}{p^2-m^2}=\frac{1}{p_0^2-\omega_p^2}=\frac{1}{(p_0-\omega_p)(p_0+\omega_p)}
\end{equation}
teniendo polos simples es $p^0=\pm\omega_p$, luego, tenemos un residuo en $\pm\frac{1}{2\omega_p}$. Ahora necesitamos un contorno cerrado para hacer la integral. Usamos el truco de tomar una semicircunferencia que se va al infinito y vemos que en el infinito no contribuye, pues al tener $e^{-ip(x-y)}\to e^{-ip^0(x^0-y^0)}$ tenemos varios casos:

\begin{itemize}
    \item \textbf{Caso 1:} $x^0-y^0>0$\\ \\
    Hacemos la semicircunferencia por abajo e integramos esta curva, tal que
    \begin{equation}
        I=\int\frac{d^3p}{(2\pi)^4}(-2\pi i)\frac{i}{2\omega_p}e^{-i\omega_p(x^0-y^0)+i\vec{p}\cdot(\vec{x}-\vec{y})}=\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_p}e^{-ip(x-y)}=D(x-y)
    \end{equation}
    donde usamos $-2\pi i$, pues al estar en sentido horario va negativo y también hemos tomado $p^0=\omega_p$ para unir las exponenciales.
    \item \textbf{Caso 2:} $x^0-y^0<0$\\ \\
    Hacemos la semicircunferencia por arriba e integramos esta curva, tal que
    \begin{equation}
        I=\int\frac{d^3p}{(2\pi)^4}(2\pi i)\frac{i}{2(-\omega_p)}e^{-i(-\omega_p)(x^0-y^0)-i\vec{p}\cdot(\vec{x}-\vec{y})}=\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_p}e^{-ip(y-x)}=D(y-x)
    \end{equation}
    Luego, la solución general queda
    \begin{equation}
        I=\Theta(x^0-y^0)D(x-y)+\Theta(y^0-x^0)D(y-x)\equiv\Delta(x-y)
    \end{equation}
\end{itemize}

\begin{Figura}
    \centering
    \includegraphics[width=0.6\textwidth]{imagenes/fig4.2.png}
    \captionof{figure}{Casos}
    \label{fig4.2}
\end{Figura}
También existe otra forma para abordar el problema, (ver Figura \ref{fig4.3})
\begin{Figura}
    \centering
    \includegraphics[width=0.7\textwidth]{imagenes/fig4.3.png}
    \captionof{figure}{Otro camino.}
    \label{fig4.3}
\end{Figura}
Es decir, en esta ocasión tomamos todo el espacio-tiempo completo, pero a los polos sumamos/restamos un $\epsilon>0$ para saltarnos la discontinuidad al integral y luego hacemos el límite cuando $\epsilon\to0$, tal que
\begin{equation}
    \Delta(x-y)=\lim_{\epsilon\to0}\int\frac{d^4p}{(2\pi)^4}\frac{i}{p^2-m^2+i\epsilon}e^{-ip(x-y)}
\end{equation}
\begin{proposition}
    El propagador de Feynman es una función de Green de la ecuación de Klein-Gordon, es decir,
    \begin{equation}
        (\square+m^2)\Delta(x)=-i\delta^{(4)}(x)
    \end{equation}
\end{proposition}
\begin{proof}
    Partimos de la definición del propagador de Feynman:
    \begin{equation}
        \Delta(x-y) = \lim_{\epsilon \to 0} \int \frac{d^4p}{(2\pi)^4} \frac{i}{p^2 - m^2 + i\epsilon} e^{-ip(x-y)}
    \end{equation}
    
    Vamos a aplicar el operador de Klein-Gordon $(\square + m^2)$ sobre $\Delta(x-y)$.  
    En el espacio de coordenadas, el operador $\square$ actúa sobre la variable $x$, por lo que:
    \begin{equation}
        (\square + m^2)\Delta(x-y) = \lim_{\epsilon \to 0} \int \frac{d^4p}{(2\pi)^4} i \, ( -p^2 + m^2 ) \frac{1}{p^2 - m^2 + i\epsilon} e^{-ip(x-y)}.
    \end{equation}

    Nótese que el operador $\square$ al actuar sobre $e^{-ip(x-y)}$ da:
    \begin{equation}
        \square e^{-ip(x-y)} = -p^2 e^{-ip(x-y)}.
    \end{equation}

    Sustituyendo esto en la expresión anterior, se obtiene:
    \begin{equation}
        (\square + m^2)\Delta(x-y) = \lim_{\epsilon \to 0} \int \frac{d^4p}{(2\pi)^4} i \, \frac{-p^2 + m^2}{p^2 - m^2 + i\epsilon} e^{-ip(x-y)}.
    \end{equation}

    Observamos que:
    \begin{equation}
        -p^2 + m^2 = -(p^2 - m^2),
    \end{equation}
    por lo que:
    \begin{equation}
        (\square + m^2)\Delta(x-y) = \lim_{\epsilon \to 0} \int \frac{d^4p}{(2\pi)^4} i \cdot \frac{-(p^2 - m^2)}{p^2 - m^2 + i\epsilon} e^{-ip(x-y)}.
    \end{equation}

    Ahora, fuera del punto $p^2 = m^2$, se cumple que:
    \begin{equation}
        \frac{-(p^2 - m^2)}{p^2 - m^2 + i\epsilon} = -1.
    \end{equation}

    Pero en $p^2 = m^2$ la fracción es singular. Esta singularidad da lugar a un término proporcional a una delta de Dirac en el espacio de posiciones. El resultado es:
    \begin{equation}
        (\square + m^2)\Delta(x-y) = -i \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} = -i \delta^{(4)}(x-y),
    \end{equation}
    donde hemos usado la identidad:
    \begin{equation}
        \int \frac{d^4p}{(2\pi)^4} e^{-ip(x-y)} = \delta^{(4)}(x-y).
    \end{equation}

    Por tanto, se concluye que:
    \begin{equation}
        (\square + m^2)\Delta(x-y) = -i \delta^{(4)}(x-y)
    \end{equation}
    lo que demuestra que $\Delta(x-y)$ es efectivamente una función de Green de la ecuación de Klein-Gordon.
\end{proof}
\begin{note}
    Si integramos solo por arriba, obtenemos el \textbf{operador retardado}, que obliga que $x^0>y^0$, obteniendo solo el término $\Theta(x^0-y^0)D(x-y)$. Si solo integramos por abajo, tendremos el \textbf{operador adelantado} que obliga que $x^0<y^0$, obteniendo solo el término $\Theta(y^0-x^0)D(y-x)$.
\end{note}
\chapter{Campos con interacciones}
En el caso libre, el Lagrangiano tiene dependencia cuadrática con los campos. Para el caso interaccionante, debemos añadir términos cúbicos, etc. \\ \\
Por unitariedad, queremos que el Lagrangiano sea real, por ejemplo,
\begin{equation}
    \mathscr{L}=\partial_{\mu}\phi^{\dagger}\partial^{\mu}\phi-m^2\phi^{\dagger}\phi-\lambda_4 \left(\phi^{\dagger}\phi\right)^2-\lambda_{2n}\left(\phi^{\dagger}\phi\right)^n
\end{equation}
donde $\mathscr{L}_0\equiv\partial_{\mu}\phi^{\dagger}\partial^{\mu}\phi-m^2\phi^{\dagger}\phi$ es la parte del Lagrangiano libre y $\lambda_4,\lambda_{2n}$ son constantes de acoplamiento.\\ \\
Podemos hacer análisis dimensional, de forma que para que la acción sea adimensional, tendremos que
\[\mathscr{L}\equiv[\text{masa}]^4,\hspace{3mm}\partial_{\mu}\equiv[\text{masa}],\hspace{3mm}\phi\equiv[\text{masa}],\hspace{3mm}\lambda_4\equiv[\text{adimensional}],\hspace{3mm}\lambda_{2n}\equiv[\text{masa}]^{4-2n}\]
Cuando $n>>1$, entonces $\lambda_{2n}$ es dimensionalmente muy negativa, por lo que diremos que estos términos son irrelevantes, teniendo así teorías que no son renormalizables. Nos quedaremos con teoría renormalizables, por ejemplo, usaremos
\begin{equation}
    \mathscr{L}=\mathscr{L}_0-\lambda_4\left(\phi^{\dagger}\phi\right)^2
\end{equation}
que es una teoría $\phi^4$ y es renormalizable.
\begin{example}
 \[\hspace{1mm}\]
    \begin{itemize}
        \item QED es renormalizable, donde $\lambda_4\equiv q$.
        \item QCD es renormalizable.
        \item Modelo Estándar es renormalizable.
        \item Relatividad General es una teoría efectiva.
    \end{itemize}
\end{example}
\section{Descomposición espectral}
Tomaremos campos escalares y trabajaremos en la imagen de Heisenberg. Primero debemos presentar las funciones de Green, que las definiremos a partir de un campo real, $\phi(x)$. Denominaremos $\ket{\Omega}$ al vacío de la teoría (estado fundamental, $H\ket{\Omega}=0)$, siendo invariante bajo todas las transformaciones de Poincaré y no tiene por qué coincidir con el vacío de Fock (vacío de la teoría libre, i.e. $\ket{\Omega}\neq\ket{0}$ en general). Definimos la función de Green de $n-$puntos del espacio-tiempo como,
\begin{equation}
    G_n(x_1,x_2,\dots,x_n)=\Braket{\Omega|T\phi(x_1)\phi(x_2)\dots\phi(x_n)|\Omega}
\end{equation}
formado por el módulo de $n-$campos ordenados por el operación de ordenación temporal, $T$.\\ \\
Si conocemos todas las funciones de Green de la teoría, tendremos resuelta la teoría. Las funciones de Green nos podrán decir los elementos de la matriz $S$.\\ \\
Podremos considerar varios casos,
\begin{itemize}
    \item \textbf{Caso }$\mathbf{n=1:}$ Tendremos la función de Green de un campo, dado por
    \begin{equation}
        \Braket{\Omega|\phi(x)|\Omega}=cte\Braket{\Omega|\Omega}=0
    \end{equation}
    donde sacamos la $cte$ por ser invariante de traslaciones.
    \item \textbf{Caso }$\mathbf{n=2:}$ Este caso es el primer resultado de las funciones de Green de dos campos, denominado \textbf{descomposición espectral}, tal que
    \begin{equation}
        G_2(x,y)=\Braket{\Omega|T\phi(x)\phi(y)|\Omega}
    \end{equation}
    Si $x^0>y^0$, entonces tendremos que
    \begin{equation}
    \begin{array}{rl}
        G_2(x,y)&=\Braket{\Omega|\phi(x)\phi(y)|\Omega}=\Braket{\Omega|\phi(x)\mathds{1}\phi(y)|\Omega}=\\ \\
        &=\Braket{\Omega|\phi(x)\sum\limits_{X}\int d\Pi_Xe^{-iP_X(x-y)}\ket{X}\bra{X}\phi(y)|\Omega}=\\ \\
         & =\sum\limits_X\int d\Pi_Xe^{-iP_X(x-y)}\Braket{\Omega|\phi(x)|X}\Braket{X|\phi(y)|\Omega}=\\ \\
         &=\sum\limits_X\int d\Pi_Xe^{-iP_X(x-y)}\Braket{\Omega|e^{-ipx}\phi(x)e^{ipx}|X}\Braket{X|e^{-ipy}\phi(y)e^{ipy}|\Omega}=\\ \\
         &=\sum\limits_X\int d\Pi_Xe^{-iP_X(x-y)}\Braket{\Omega|\phi(x)|X}\Braket{X|\phi(y)|\Omega}=\\ \\
         &=\sum\limits_X\int d\Pi_Xe^{-iP_X(x-y)}\Braket{\Omega|\phi_0(x)|X}\Braket{X|\phi_0(y)|\Omega}=\\ \\
         &=\sum\limits_X\int d\Pi_Xe^{-iP_X(x-y)}\left|\Braket{\Omega|\phi(0)|X}\right|^2=\int\frac{d^4p}{(2\pi)^4}e^{-ip(x-y)}2\pi\Theta(p^0)\rho(p^2)
    \end{array}
    \end{equation}
    con
    \begin{equation}
        2\pi\Theta(p^0)\rho(p^2)=\sum_X\int d\Pi_X(2\pi)^4\delta^{(4)}(p-P_X)\left|\Braket{\Omega|\phi(0)|X}\right|^2
    \end{equation}
    donde $\rho$ es la \textbf{densidad espectral}.
\end{itemize}
Algunas propiedades de la densidad espectral son:
\begin{enumerate}
    \item $\rho(\mu^2)\geq0;\hspace{3mm}\forall\mu^2\geq0$
    \item $\rho(\mu^2)=0;\hspace{3mm}\forall\mu^2<0$
\end{enumerate}
Podemos reescribir la función de Green como,
\begin{equation}
    G_2(x,y)=\int_0^{\infty}d\mu^2\int\frac{d^4p}{(2\pi)^4}e^{-ip(x-y)}\Theta(p^0)\delta(p^2-m^2)\rho(\mu^2)=\int_0^{\infty}d\mu^2\rho(\mu^2)\int\frac{d^4p}{(2\pi)^4}e^{-ip(x-y)}\Theta(p^0)\delta(p^2-m^2)
\end{equation}
calculamos la integral de momentos,
\begin{equation}
        \int\frac{d^4p}{(2\pi)^4}e^{-ip(x-y)}\Theta(p^0)\delta(p^2-m^2)=\int\frac{d^3p}{(2\pi)^4}e^{-ip(x-y)}\int_0^{\infty}dp^0\delta(p^2-m^2)\Theta(p^0)
\end{equation}
Ahora calculamos la integral de $p^0$ usando que $p^2=p_{\mu}p^{\mu}=p_0^2-|\vec{p}|^2$, luego,
\begin{equation}
    \int_0^{\infty}dp^0\delta(p_0^2-(|\vec{p}|^2+m^2))\Theta(p^0)=\int_0^{\infty}dp^0\delta(p_0^2-\omega_p^2)\Theta(p^0)
\end{equation}
Usamos el cambio de variable $x=p_0^2-\omega_p^2$ con $dx=2p^0dp^0$, luego,
\begin{equation}
    \int_0^{\infty}dp^0\delta(p_0^2-\omega_p^2)\Theta(p^0)=\int_0^{\infty}\frac{dx}{2\sqrt{x+\omega_p^2}}\delta(x)=\frac{2\pi}{2\sqrt{\omega_p^2}}=\frac{2\pi}{2\omega_p}
\end{equation}
Luego,
\begin{equation}
    \int\frac{d^4p}{(2\pi)^4}e^{-ip(x-y)}\Theta(p^0)\delta(p^2-m^2)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_p}e^{-ip(x-y)}=\left.D(x-y)\right|_{m^2\to\mu^2}
\end{equation}
pues la integral que nos queda es la definición del propagador. Por tanto, para que el propagador no sea una constante de integración, hacemos $m^2\to\mu^2$, quedando la función de Green como,
\begin{equation}
    G_2(x,y)=\int_0^{\infty}d\mu^2\rho(\mu^2)\brackets{\left.D(x-y)\right|_{m^2\to\mu^2}}
\end{equation}
Este desarrollo lo hemos hecho para el caso $x^0>y^0$. En general tendremos,
\begin{equation}\small
    G_2(x,y)=\int_0^{\infty}d\mu^2\rho(\mu^2)\brackets{\Theta(x^0-y^0)\left.D(x-y)\right|_{m^2\to\mu^2}+\Theta(y^0-x^0)\left.D(y-x)\right|_{m^2\to\mu^2}}=\int_0^{\infty}d\mu^2\rho(\mu^2)\left.\Delta(x-y)\right|_{\mu^2}
\end{equation}
Luego, en el caso de interacciones, tendremos que la función de Green entre dos puntos será la integral del propagador de Feynman con distintas masas $\mu^2$, que dependerá de quién sea $\rho(\mu^2)$.\\ \\
De forma explícita tendremos,
\begin{equation}
    G_2(x,y)=\int_0^{\infty}d\mu^2\rho(\mu^2)\int\frac{d^4p}{(2\pi)^4}e^{-ip(x-y)}\frac{i}{p^2-m^2+i\epsilon}
\end{equation}
donde $\epsilon\to0^+$ al final del cálculo.\\ \\
Podemos escribir la función de Green en términos de la transformada de $(x-y)\to p$, tal que
\begin{equation}
    G_2(x,y)=\int\frac{d^4p}{(2\pi)^4}e^{-ip(x-y)}\hat{G}(p)
\end{equation}
donde hemos usado que es invariante bajo traslaciones.\\ \\
Comparando ambas expresiones, tenemos que
\begin{equation}
    \hat{G}(p)=\int_0^{\infty}d\mu^2\rho(\mu^2)\frac{i}{p^2-m^2+i\epsilon}
\end{equation}
en el espacio de momentos.\\ \\
Vemos que (obviando el $i\epsilon$), en $p^2=m^2$ tenemos un polo simple. Supondremos el caso de partículas de espín 0 y masa $m$. Esto está asociado a que la densidad espectral es de la forma,
\begin{equation}
    \rho(\mu^2)=Z\delta(\mu^2-m^2)+\dots
\end{equation}
con $Z>0$. El primer sumando corresponde con la teoría libre y el resto de sumandos corresponde con las correcciones de las teorías con interacciones.\\ \\
Esto podemos verlo tomando $X$ como un estado de esta partícula $\ket{\vec{p}}_m$, tal que $\ket{X}\equiv\ket{\vec{p}}_m$, por tanto
\begin{equation}
    \left|\Braket{\Omega|\phi(0)|X}\right|^2\to\left|\Braket{\Omega|\phi(0)|\vec{p}}_m\right|^2\to\Braket{\vec{p}|_m\phi(0)|\Omega}
\end{equation}
y supondremos que vale $Z^{1/2}$, por tanto 
\begin{equation}
    \left|\Braket{\Omega|\phi(0)|\vec{p}}_m\right|^2=Z
\end{equation}
Nos queda la integral de fases de una partícula multiplicada por la delta de Dirac, que al reescribirla con los momentos cuadráticos, la delta hace que $p^2=m^2$, obteniendo que $\rho(p^2)=Z\delta(p^2-m^2)$. En resumen, si $\rho(\mu^2)=Z\delta(\mu^2-m^2)$, entonces $\Braket{\vec{p}|_m\phi(0)|\Omega}=Z^{1/2}$, o bien, trasladando,
\begin{equation}
    \Braket{\vec{p}|_m\phi(x)|\Omega}=Z^{1/2}e^{ipx}
\end{equation}
donde $\vec{p}$ representa la partícula, $\phi(x)$ un campo y $Z^{1/2}e^{ipx}$ representa una conexión general entre campos y partículas. Así tenemos,
\begin{equation}
    \hat{G}(p)=\int_0^{\infty}d\mu^2\left(Z\delta(\mu^2-m^2)+\dots\right)\frac{i}{p^2-\mu^2+i\epsilon}
\end{equation}
Esta función de dos puntos, $\hat{G}(p)$, posee toda la información espectral de la teoría, conectando partículas masivas $(Z\neq0)$ con los campos. Nos dice el espectro de masas, por la $\rho(\mu^2)$, y la amplitud de $Z$. La forma típica de la función espectral es,
\begin{Figura}
    \centering
    \includegraphics[width=0.6\textwidth]{imagenes/fig5.1.png}
    \captionof{figure}{Forma de la densidad espectral.}
    \label{fig5.1}
\end{Figura}
que lo hemos pasado al espacio de momentos, por tanto, $\hat{G}(p)$ tiene un corte de ramas.
\begin{note}
    Todo este formalismo es general, pudiendo usar no solo campos, sino también que podemos usar $\phi^2$, $\partial\phi$, $\dots$ Solo hay que ver su $Z\neq0$.
\end{note}
Por otro lado, al ser $Z\neq0$, podemos renormalizar $\Braket{\vec{p}|\phi(x)|\Omega}$ para tener que $Z^{1/2}=1$ al otro lado de la igualdad, tal que
\begin{equation}
    \Braket{\vec{p}|\phi(x)|\Omega}=e^{ipx}
\end{equation}
\section{Teorema LSZ. Fórmula de reducción}
Esta fórmula conecta los elementos de matriz $S$ con las funciones de Green, por tanto, si conocemos las funciones de Green, podremos obtener de forma directa las amplitudes de colisión.
\subsection{Fórmula LSZ}
Esta fórmula se refiere a Lehmann, Symazik y Zimmermann.\\ \\
Vamos a normalizar los campos $\phi$, de forma que el residuo del polo simple $p^2=m^2$ sea 1, tal que $\Braket{\vec{p}|\phi(x)|\Omega}=e^{ipx}$. \\ \\
Tomando los elementos de matriz $S$, llegamos a la fórmula LSZ,
\begin{equation}
    \begin{array}{rl}
        \Braket{\vec{q}_1,\vec{q}_2,\dots,\vec{q}_n|S|\vec{p}_1,\vec{p}_2,\dots,\vec{p}_m} &=\brackets{i\int d^4x_1e^{-ip_1x_1}\left(\square_{x_1}+m^2\right)}\dots\brackets{i\int d^4x_me^{-ip_mx_m}\left(\square_{x_m}+m^2\right)}\times  \\
         & \times\brackets{i\int d^4y_1e^{-iq_1y_1}\left(\square_{y_1}+m^2\right)}\dots\brackets{i\int d^4y_ne^{-iq_ny_n}\left(\square_{y_n}+m^2\right)}\times\\
         &\times\Braket{\Omega|T\phi(x_1)\dots\phi(x_m)\phi(y_1)\dots\phi(y_n)|\Omega}
    \end{array}
\end{equation}
Esta fórmula nos relaciona los elementos de la matriz $S$ con las funciones de Green, ordenadas temporalmente, de los campos. Además, la fórmula LSZ se aplica a funciones de Green conectadas, ya que las desconectadas se cancelan o normalizan. Podemos reordenar la ecuación, pues las integrales en esencia son la misma integral y aplicamos el límite \textit{on-shell}, tal que
\begin{equation}
    \Braket{\vec{q}_1\dots\vec{q}_n|S|\vec{p}_1\dots\vec{p}_m}=(-i)^{n+m}\lim_{\begin{matrix}
        p_i^0\to \omega_{p_i}\\\\
        q_j^0\to\omega_{q_j}
    \end{matrix}}\prod\limits_{i=1}^m\left(p_i^2-m^2\right)\prod\limits_{j=1}^n\left(q_j^2-m^2\right)\tilde{G}(-p_1,\dots,-p_m,q_1,\dots,q_n)
\end{equation}
Vemos que si esta expresión es distinta de cero, la función de Green debe tener un polo simple cuando está \textit{on-shell}, por tanto, las funciones de Green tienen polos simples en $p^2=m^2$, como cabría esperar.\\ \\
Usando la definición,
\begin{equation}
    \tilde{G}(k_1,\dots,k_n)=(2\pi)^4\delta^{(4)}\left(\sum_i^nk_i\right)\hat{G}_n(k_1,\dots,k_n),
\end{equation}
podemos escribir las amplitudes de colisión como,
\begin{tcolorbox}[title=Amplitud de colisión en función de las funciones de Green, colback=gray!10, boxrule=0.5mm, width=1.2\textwidth]
Recordando que $S=1-i\mathscr{M}$,

    \begin{equation}
        i\mathscr{M}_{\vec{q}_1\dots\vec{q}_n,\vec{p}_1\dots\vec{p}_m}=\lim_{\begin{matrix}
            p_i^0\to\omega_{p_i}\\\\
            q_j^0\to\omega_{q_j}
        \end{matrix}}\prod\limits_{i=1}^m\left(p_i^2-m^2\right)\prod\limits_{j=1}^n\left(q_j^2-m^2\right)(-i)^{n+m}\hat{G}_{n+m}(-p_1,\dots,-p_m,q_1,\dots,q_n)
    \end{equation}
    
    obteniendo una conexión entre campos y partículas.
\end{tcolorbox}
el factor global \( (-i)^{n+m} \) proviene de la convención adoptada en la fórmula de reducción LSZ en el espacio de coordenadas, donde cada inserción de campo externo aporta dos factores: uno del operador \( (\Box + m^2) \), y otro de la transformada de Fourier \( \int d^4x\, e^{\pm ip\cdot x} \). Estos dos factores introducen fases \( \pm i \), que se combinan para dar \( (-1) \) por línea externa.\\ \\
Para un total de \( N = n + m \) partículas externas, el producto genera un factor \( (-1)^N \), que puede reexpresarse como \( (-i)^{n+m} \) dependiendo de la convención de fases empleada. Esta elección es matemáticamente consistente siempre que se mantenga coherencia interna. En la práctica, las amplitudes físicas observables dependen de \( |\mathscr{M}|^2 \), por lo que las fases globales no afectan los resultados experimentales. Sin embargo, es útil dejar clara esta convención para evitar ambigüedades en la reconstrucción de las reglas de Feynman a partir de la fórmula LSZ.
\begin{note}
    La función de Green $\hat{G}_{n+m}(-p_1,\dots,-p_m,q_1,\dots,q_n)$ lleva asociado un factor 
    $(2\pi)^4 \delta^{(4)}\left(\sum (-p_i) + \sum q_j\right)$ que exige que la suma de los momentos entrantes sea igual a la suma de los momentos salientes, llegando a la \textbf{conservación del momento}, pues al tener los signos cambiados, tenemos que
    \begin{equation}
        \sum_{i=1}^mp_i=\sum_{j=1}^nq_j
    \end{equation}
\end{note}
\section{Teoría de Perturbaciones}
\subsection{Imagen de Interacción}
Se basa en la descomposición del Hamiltoniano (generador de las traslaciones temporales) en $H=H_0+H'$, donde $H_0$ es el Hamiltoniano libre, que debe tener el mismo espectro de energías de $H$.\\ \\
Tomamos un tiempo de referencia $t_0$, definiendo los estados en la imagen de interacción como 
\begin{equation}
\ket{\Psi(t)}_I=e^{iH_0t}\ket{\Psi(t)}_S
\end{equation}
, donde $\ket{\Psi(t)}_S$ son los estados en la imagen de Schrödinger. Los operadores son de la forma,
\begin{equation}
    \mathscr{O}_I(t)=e^{iH_0t}\mathscr{O}_Se^{-iH_0t}
\end{equation}
Tenemos que la evolución temporal viene dada por un operador unitario, tal que
\begin{equation}
    \ket{\Psi(t)}_I=U(t,t_0)\ket{\Psi(t_0)}_I
\end{equation}
con $U(t,t_0)=e^{iH_0t}e^{-iH(t-t_0)}e^{-iH_0t_0}$ y $U(t_0,t_0)=\mathds{1}$. Esta definición es solución de la siguiente ecuación diferencial,
\begin{equation}
    i\partial_tU(t,t_0)=H_I(t)U(t,t_0)
\end{equation}
con $H_I(t)=e^{iH_0t}H'e^{-iH_0t}$. \\ \\
La idea fundamental se basa en ver que si $H_I(t)$ es pequeño, entonces podremos resolver el problema perturbativamente.\\ \\
Tenemos una solución exacta, que es la serie de Dyson,
\begin{equation}
    U(t,t_0)=T\exp\left(-i\int_{t_0}^tdt'H_I(t')\right)
\end{equation}
donde $\exp$ representa la serie de potencias de la exponencial y la $T$ actúa sobre cada término de la serie de la exponencial ordenándolos temporalmente.\\ \\
Veamos cómo el operador unitario $U(t,t_0)$ se relaciona con la matriz $S$. Tendremos dos casos:
\begin{itemize}
    \item \textbf{Para }$\mathbf{t\to-\infty:}$
    \begin{equation}
        e^{-itH}\ket{\alpha}_{in}=e^{-itH_0}\ket{\alpha}\Rightarrow\ket{\alpha}_{in}=\lim_{t\to-\infty}e^{itH}e^{-itH_0}\ket{\alpha}
    \end{equation}
    \item \textbf{Para }$\mathbf{t\to\infty:}$
    \begin{equation}
        e^{-itH}\ket{\alpha}_{out}=e^{-itH_0}\ket{\alpha}\Rightarrow\ket{\alpha}_{out}=\lim_{t\to\infty}e^{itH}e^{-itH_0}\ket{\alpha}
    \end{equation}
\end{itemize}
Luego, sabemos que $\Braket{\beta|S|\alpha}=S_{\beta\alpha}=\hspace{0mm}_{out}\Braket{\beta|\alpha}_{in}$, por tanto
\begin{equation}
\begin{array}{rl}
    S_{\beta\alpha}&=\Braket{\beta|\lim\limits_{t\to\infty}e^{iH_0t}e^{-itH}\lim\limits_{t_0\to-\infty}e^{it_0H}e^{-it_0H_0}|\alpha}=\Braket{\beta|\lim\limits_{\begin{matrix}
        t\to\infty\\
        t_0\to-\infty
    \end{matrix}}e^{iH_0t}e^{-i(t-t_0)H}e^{-it_0H_0}|\alpha}=\\ \\
    &=\Braket{\beta|\lim\limits_{\begin{matrix}
        t\to\infty\\
        t_0\to-\infty
    \end{matrix}}U(t,t_0)|\alpha}=\Braket{\beta|U(\infty,-\infty)|\alpha}
\end{array}
\end{equation}
Por tanto, comparando tenemos
\begin{equation}
    S=U(\infty,-\infty)
\end{equation}
\begin{remark}
    Si tenemos un campo $\phi_I(t,\vec{x})$ en la imagen de interacción, viene dado por $\phi_I(t,\vec{x})=\phi_0(x)$, es decir, es el campo libre, pues
    \begin{equation}
        \phi_I(t,\vec{x})=e^{iH_0t}\phi(0,\vec{x})e^{-iH_0t}=\phi_0(x)
    \end{equation}
    Además, podemos relacionarlo con el campo en la imagen de Heisenberg como,
    \begin{equation}
        \phi_H(t,\vec{x})=e^{iHt}\phi(0,\vec{x})e^{-iHt}=e^{-iHt}e^{-iH_0t}\phi_0(t,\vec{x})e^{iH_0t}e^{-iHt}=U(0,t)\phi_0(t,\vec{x})U(t,0)
    \end{equation}
\end{remark}
Veamos cómo usar la imagen de interacción para reescribir las funciones de Green (que están escritas en la imagen de Heisenberg) para ponerlas en función de campos libres. Para ello, usamos el valor esperado en el vacío de Fock, $\ket{0}$, tal que
\begin{equation}
    \Braket{0|T\phi_0(x_1)\phi_0(x_2)\dots\phi_0(x_n)S|0}=\Braket{0|T\phi_0(x_1)\phi_0(x_2)\dots\phi_0(x_n)U(\infty,-\infty)|0}
\end{equation}
Sabiendo que si $t=t_1+t_2$ podemos hacer que $U(t,-t)=U(t_1,-t_1)U(t_1,-t_2)U(t_2,-t_1)U(t_2,-t_2)$, como tenemos $U(\infty,-\infty)$, podemos factorizarlo tal que
\begin{equation}
    U(\infty,-\infty)=U(\infty,t_1)U(t_1,t_2)\dots U(t_n,-\infty)
\end{equation}
Además, podemos hacer que $U(t_1,t_2)=U(t_1,0)U(0,t_2)$. Luego, reordenando con el operador $T$ obtenemos,
\begin{equation}\small
    \Braket{0|T\phi_0(x_1)\dots\phi_0(x_n)S|0}=\Braket{0|U(\infty,0)U(0,t_1)\phi_0(x_1)U(t_1,0)\dots U(0,t_n)\phi_0(x_n)U(t_n,0)U(0,-\infty)|0}
\end{equation}
Sabiendo que $\phi(x)=U(0,t)\phi_0(x)U(t,0)$, tenemos que
\begin{equation}
    \Braket{0|T\phi_0(x_1)\dots\phi_0(x_n)S|0}=\Braket{0|U(\infty,0)\phi(x_1)\phi(x_2)\dots\phi(x_n)U(0,-\infty)|0}
\end{equation}
Ahora veamos cómo actúa $U(0,-\infty)$ sobre el vacío de Fock,
\begin{equation}
    \Braket{\Psi|U(0,-\infty)|0}=\lim_{t_0\to-\infty}\Braket{\Psi|e^{iHt_0}e^{-iH_0t_0}|0}
\end{equation}
Aplicando la serie de potencias de la exponencial, tenemos
\begin{equation}
    e^{-it_0H_0}\approx\mathds{1}-iH_0t_0+\mathcal{O}(H_0)
\end{equation}
donde $\mathcal{O}(H_0)$ representa que los órdenes superiores dependerán de $H_0$, pero sabemos que al tratar con el vacío de Fock, $H_0\ket{0}=0$, por tanto, tendremos que
\begin{equation}
    e^{-it_0H_0}\ket{0}=\mathds{1}\ket{0}-it_0\cancelto{0}{H_0\ket{0}}+\cancelto{0}{\mathcal{O}(H_0)\ket{0}}=\mathds{1}\ket{0}
\end{equation}
Por tanto,
\begin{equation}
    \Braket{\Psi|U(0,-\infty)|0}=\lim_{t_0\to-\infty}\Braket{\Psi|e^{iHt_0}\mathds{1}|0}
\end{equation}
Usamos una base de autovectores de $H$, donde todos los estados forman un continuo salvo el vacío físico, pues estará él solo y aislado de los demás estados (esto lo tratamos como Axioma de la teoría). Así, podemos introducir,
\begin{equation}
    \mathds{1}=\ket{\Omega}\bra{\Omega}+\mathop{\sum\!\!\!\!\!\!\!\!\int}_{n\neq\Omega}\ket{n}\bra{n}
\end{equation}
Luego, sustituyendo la identidad en la expresión anterior tenemos,
\begin{equation}
    \lim_{t_0\to-\infty}\Braket{\Psi|e^{iHt_0}\mathds{1}|0}=\lim_{t_0\to-\infty}\brackets{\Braket{\Psi|e^{iHt_0}|\Omega}\Braket{\Omega|0}+\mathop{\sum\!\!\!\!\!\!\!\!\int}_{n\neq\Omega}\Braket{\Psi|e^{iHt_0}|n}\Braket{n|0}}
\end{equation}
Repitiendo el razonamiento anterior, tenemos que
\begin{equation}
    e^{iHt_0}\approx\mathds{1}+iHt_0+\mathcal{O}(H)
\end{equation}
y al actuar sobre el vacío físico, tenemos $H\ket{\Omega}=0$, luego
\begin{equation}
    e^{iHt_0}\ket{\Omega}=\mathds{1}\ket{\Omega}+it_0\cancelto{0}{H\ket{\Omega}}+\cancelto{0}{\mathcal{O}(H)\ket{\Omega}}=\mathds{1}\ket{\Omega}
\end{equation}
Luego,
\begin{equation}
    \lim_{t_0\to-\infty}\Braket{\Psi|e^{iHt_0}\mathds{1}|0}=\Braket{\Psi|\Omega}\Braket{\Omega|0}+\lim_{t_0\to-\infty}\mathop{\sum\!\!\!\!\!\!\!\!\int}_{n\neq\Omega}\Braket{\Psi|e^{iE_nt_0}|n}\Braket{n|0}
\end{equation}
pues al tener estados continuos, el Hamiltoniano será la energía.
\begin{lemma}[Riemann-Lebesgue]
    \begin{equation}
        \lim_{\mu\to\infty}\int_{-\infty}^{\infty}dxf(x)e^{i\mu x}=0
    \end{equation}
\end{lemma}
Aplicando el Lema de Riemann-Lebesgue, vemos que
\begin{equation}
    \lim_{t_0\to-\infty}\mathop{\sum\!\!\!\!\!\!\!\!\int}_{n\neq\Omega}\Braket{\Psi|e^{iE_nt_0}|n}\Braket{n|0}=0
\end{equation}
Así tenemos,
\begin{equation}
    \Braket{\Psi|U(0,-\infty)|0}=\Braket{\Psi|\Omega}\Braket{\Omega|0}
\end{equation}
Usando que $U(x,y)=U(y,x)^{\dagger}$, tenemos que
\begin{equation}
    \Braket{0|U(\infty,0)|\Psi}=\Braket{0|\Omega}\Braket{\Omega|\Psi}
\end{equation}
Por tanto, tenemos
\begin{equation}
    \Braket{0|T\phi_0(x_1)\dots\phi_0(x_n)S|0}=\Braket{0|\Omega}\Braket{\Omega|T\phi(x_1)\dots\phi(x_n)|\Omega}\Braket{\Omega|0}
\end{equation}
donde $\Braket{\Omega|T\phi(x_1)\dots\phi(x_n)|\Omega}$ es una función de Green de $n-$puntos. Despejando la función de Green tenemos,
\begin{equation}
    \Braket{\Omega|T\phi(x_1)\dots\phi(x_n)|\Omega}=\frac{\Braket{0|T\phi_0(x_1)\dots\phi_0(x_n)U(\infty,-\infty)|0}}{\Braket{0|\Omega}\Braket{\Omega|0}}=\frac{\Braket{0|T\phi_0(x_1)\dots\phi_0(x_n)U(\infty,-\infty)|0}}{\Braket{0|U(\infty,-\infty)|0}}
\end{equation}
Para poder operar de forma más sencilla, aproximaremos los $U(\infty,-\infty)$ con la serie de Dyson.\\ \\
Recordamos que la serie de Dyson es
\[U(\infty,-\infty)=T\exp\left(-i\int_{-\infty}^{\infty}dtH_I(t)\right)\]
pero esta formulación no es covariante Lorentz, debido a la dependencia temporal en el Hamiltoniano. Para solucionarlo, hacemos
\begin{equation}
    H_I(t)=e^{iH_0t}H'(\phi(0,\vec{x}))e^{-iH_0t}=H'(\phi_0(t,\vec{x}))=-\int d^3x\mathscr{L}_{int}\left(\phi_0(t,\vec{x}),\vec{\nabla}\phi_0(t,\vec{x})\right)
\end{equation}
donde $\mathscr{L}_{int}=\mathscr{L}-\mathscr{L}_0$ y hemos supuesto que en la parte de interacción no hay derivadas temporales. Así tenemos,
\begin{equation}
    U(\infty,-\infty)=T\exp\left(i\int d^3x\mathscr{L}_{int}(\phi_0,\nabla\phi_0)\right)=T\exp\left(iS_{int}[\phi_0]\right)
\end{equation}
donde $S_{int}$ es la acción de la parte de interacción. Luego, la función de Green dependerá de la acción de interacción, tal que
\begin{equation}
    \Braket{\Omega|T\phi(x_1)\dots\phi(x_n)|\Omega}=\frac{\Braket{0|T\phi_0(x_1)\dots\phi_0(x_n)e^{iS_{int}[\phi_0]}|0}}{\Braket{0|e^{iS_{int}[\phi_0]}|0}}
    \label{eq5.61}
\end{equation}
Esta fórmula es solo cierta cuando no hay derivadas temporales en la parte de interacción y será la que usaremos desarrollando las exponenciales en serie de potencias. Ahora sí es covariante Lorentz.\\ \\
Ahora vamos a introducir el Teorema de Wick, que será muy útil para desarrollar los cálculos. Antes de ello, debemos introducir una definición, que es la \textbf{contracción de campos}.
\begin{definition}[Contracción de campos]
    La contracción de campos viene dada por,
    \begin{equation}
        \contraction{A}{\phi(x)}{B}{\phi(y)}A\phi(x)B\phi(y)C=ABC\Delta(x-y)
    \end{equation}
    es decir, cambiamos los campos por su propagador de Feynman.
\end{definition}
Ahora veamos el Teorema.
\begin{theorem}[Teorema de Wick]
    Vamos a empezar con un sistema sencillo y luego pasamos a lo general.\\ \\
    Consideramos dos campos escalares reales $T\phi_0(x)\phi_0(y)$. Descomponemos el campo como $\phi_0=\phi_0^++\phi_0^-$, tal que
    \begin{equation}
        \phi_0^+=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}a_{\vec{p}}e^{-ipx};\hspace{6mm}\phi_0^-=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}a_{\vec{p}}^{\dagger}e^{ipx}
    \end{equation}
    Tomando $x^0>y^0$ tenemos,
    \begin{equation}
        \begin{array}{rl}
            T\phi_0(x)\phi_0(y) &=\phi_0(x)\phi_0(y)=\left(\phi_0^+(x)+\phi_0^-(x)\right)\left(\phi_0^+(y)+\phi_0^-(y)\right)= \\ \\
             & =\phi_0^+(x)\phi_0^+(y)+\phi_0^+(x)\phi_0^-(y)+\phi_0^-(x)\phi_0^+(y)+\phi_0^-(x)\phi_0^-(y)=\\ \\
             &=\phi_0^+(x)\phi_0^+(y)+\phi_0^-(x)\phi_0^-(y)+\phi_0^-(x)\phi_0^+(y)+\phi_0^-(y)\phi_0^+(x)+\cancelto{D(x-y)}{\brackets{\phi_0^+(x),\phi_0^-(y)}}=\\ \\
             &=:\phi_0(x)\phi_0(y):+D(x-y)
        \end{array}
    \end{equation}
    Tomando $x^0<y^0$, análogamente tenemos,
    \begin{equation}
        T\phi_0(x)\phi_0(y)=\phi_0(y)\phi_0(x)=:\phi_0(y)\phi_0(x):+D(y-x)=:\phi_0(x)\phi_0(y):+D(y-x)
    \end{equation}
    Por tanto, uniendo ambos casos tenemos,
    \begin{equation}
        T\phi_0(x)\phi_0(y)=:\phi_0(x)\phi_0(y):+\left(D(x-y)+D(y-x)\right)=:\phi_0(x)\phi_0(y):+\Delta(x-y)
    \end{equation}
    Usando la definición de la contracción de campos, podemos escribir,
    \begin{equation}
        T\phi_0(x)\phi_0(y)=:\phi_0(x)\phi_0(y):+\contraction{}{\phi_0(x)}{}{\phi_0(y)}\phi_0(x)\phi_0(y)
    \end{equation}
    Este sería el Teorema de Wick para dos campos.\\ \\
    Para el Teorema general, vamos a simplificar la notación, usaremos $\phi\equiv\phi_0$ y $\phi(x_i)\equiv\phi_i$.\\ \\
    El Teorema de Wick general será:
    \begin{equation}
        T\phi_1\phi_2\dots\phi_n=:\phi_1\phi_2\dots\phi_n+\text{ todas las contracciones}:
    \end{equation}
\end{theorem}
\begin{corollary}
    En el ordenamiento hecho a través del Teorema de Wick, tendremos términos puramente contraídos. La cantidad del número de términos puramente contraídos viene dada por,
    \begin{equation}
        \left\lbrace\begin{array}{lr}
            0, & \text{si }n\text{ es impar} \\
            (2k-1)!!, &\text{si }n=2k\text{ es par} 
        \end{array}\right.
    \end{equation}
    donde $!!$ representa el doble factorial, $(2k-1)!!=(2k-1)\cdot(2k-3)\dots3\cdot1$
\end{corollary}
Veamos un ejemplo de cómo quedaría el Teorema de Wick para cuatro campos,
\begin{equation}
    \begin{array}{rl}
    T\phi_1\phi_2\phi_3\phi_4&=:\phi_1\phi_2\phi_3\phi_4+\contraction{}{\phi_1}{}{\phi_2}\phi_1\phi_2\phi_3\phi_4+\contraction{}{\phi_1}{}{\phi_3}\phi_1\phi_3\phi_2\phi_4+\contraction{}{\phi_1}{}{\phi_4}\phi_1\phi_4\phi_2\phi_3+\contraction{}{\phi_2}{}{\phi_3}\phi_2\phi_3\phi_1\phi_4+\\ \\
    &+\contraction{}{\phi_2}{}{\phi_4}\phi_2\phi_4\phi_1\phi_3+\contraction{}{\phi_3}{}{\phi_4}\phi_3\phi_4\phi_1\phi_2+\contraction{}{\phi_1}{}{\phi_2}\phi_1\phi_2\contraction{}{\phi_3}{}{\phi_4}\phi_3\phi_4+\contraction{}{\phi_1}{}{\phi_3}\phi_1\phi_3\contraction{}{\phi_2}{}{\phi_4}\phi_2\phi_4+\contraction{}{\phi_1}{}{\phi_4}\phi_1\phi_4\contraction{}{\phi_2}{}{\phi_3}\phi_2\phi_3:=\\ \\
    &=:\phi_1\phi_2\phi_3\phi_4:+\contraction{}{\phi_1}{}{\phi_2}\phi_1\phi_2:\phi_3\phi_4:+\contraction{}{\phi_1}{}{\phi_3}\phi_1\phi_3:\phi_2\phi_4:+\contraction{}{\phi_1}{}{\phi_4}\phi_1\phi_4:\phi_2\phi_3:+\contraction{}{\phi_2}{}{\phi_3}\phi_2\phi_3:\phi_1\phi_4:+\\ \\
    &+\contraction{}{\phi_2}{}{\phi_4}\phi_2\phi_4:\phi_1\phi_3:+\contraction{}{\phi_3}{}{\phi_4}\phi_3\phi_4:\phi_1\phi_2:+\contraction{}{\phi_1}{}{\phi_2}\phi_1\phi_2\contraction{}{\phi_3}{}{\phi_4}\phi_3\phi_4+\contraction{}{\phi_1}{}{\phi_3}\phi_1\phi_3\contraction{}{\phi_2}{}{\phi_4}\phi_2\phi_4+\contraction{}{\phi_1}{}{\phi_4}\phi_1\phi_4\contraction{}{\phi_2}{}{\phi_3}\phi_2\phi_3
    \end{array}
\end{equation}
De forma que, 
\begin{equation}
\begin{array}{rl}
    \Braket{0|T\phi_1\phi_2\phi_3\phi_4|0}&=\contraction{}{\phi_1}{}{\phi_2}\phi_1\phi_2\contraction{}{\phi_3}{}{\phi_4}\phi_3\phi_4+\contraction{}{\phi_1}{}{\phi_3}\phi_1\phi_3\contraction{}{\phi_2}{}{\phi_4}\phi_2\phi_4+\contraction{}{\phi_1}{}{\phi_4}\phi_1\phi_4\contraction{}{\phi_2}{}{\phi_3}\phi_2\phi_3=\\ \\
    &=\Delta(x_1-x_2)\Delta(x_3-x_4)+\Delta(x_1-x_3)\Delta(x_2-x_4)+\Delta(x_1-x_4)\Delta(x_2-x_3)
    \end{array}
\end{equation}
o simplificando la notación con $\Delta_{ij}\equiv\Delta(x_i-x_j)$ tenemos
\begin{equation}
    \Braket{0|T\phi_1\phi_2\phi_3\phi_4|0}=\Delta_{12}\Delta_{34}+\Delta_{13}\Delta_{24}+\Delta_{14}\Delta_{23}
\end{equation}

\section{Diagramas de Feynman}
En la práctica, los cálculos de las funciones de Green o de las amplitudes de colisión pueden llegar a ser extremadamente complicados debido al gran número de términos que aparecen al aplicar la expansión de Dyson o el teorema de Wick.\\ \\
Para simplificar y visualizar mejor los procesos, se introducen los diagramas de Feynman, que proporcionan una representación gráfica de las interacciones y permiten organizar y calcular de manera sistemática las distintas contribuciones a la amplitud.
\\ \\
Veamos un ejemplo donde los cálculos se complican e introduciremos los diagramas de Feynman. Luego explicaremos los convenios y el proceso para representar los diagramas.\\ \\
Consideramos el Lagrangiano,
\begin{equation}
    \mathscr{L}=\underbrace{\frac{1}{2}\partial_{\mu}\phi\partial^{\mu}\phi-\frac{m^2}{2}\phi^2}_{\mathscr{L}\text{ libre de }\phi-}+\underbrace{\partial_{\mu}\psi^{\dagger}\partial^{\mu}\psi-M^2\psi^{\dagger}\psi}_{\mathscr{L}\text{ libre de }\psi}-\underbrace{g\psi^{\dagger}\psi\phi}_{\mathscr{L}\text{ de interacción}}
\end{equation}
donde $\phi$ es un campo escalar real y $\psi$ es un campo escalar complejo. Supondremos que $m>2M$, de forma que se pueda dar la desintegración,
\begin{equation}
    \phi\longrightarrow\psi+\bar{\psi}
\end{equation}
Queremos calcular la anchura de la desintegración. Para ello, comenzamos calculando $\mathcal{M}_{\beta\alpha}$ usando que $\ket{\alpha}=\ket{\vec{p},\phi}$ y $\ket{\beta}=\ket{\vec{q}_1,\vec{q}_2,\psi\bar{\psi}}$. Además, usaremos la siguiente función de Green,
\begin{equation}
    \Braket{\Omega|T\phi(x)\psi(y_1)\psi^{\dagger}(y_2)|\Omega}
\end{equation}
Recordando la ecuación (\ref{eq5.61}), debemos calcular el numerador y el denominador. Veamos el numerador, donde 
\begin{equation}
    S_{int}=\int d^4z\mathscr{L}_{int}=-g\int d^4z\psi^{\dagger}(z)\psi(z)\phi(z)
\end{equation}
Luego,
\begin{equation}
    N\equiv\Braket{0|T\phi_0(x)\psi_0(y_1)\psi_0^{\dagger}(y_2)e^{-ig\int d^4z\psi^{\dagger}_0(z)\psi_0(z)\phi_0(z)}|0}
\end{equation}
Desarrollamos la exponencial en serie de potencias suponiendo que $g$ es pequeño, tal que
\begin{equation}
    \begin{array}{rl}
       N & \approx\Braket{0|T\phi_0(x)\psi_0(y_1)\psi_0^{\dagger}(y_2)|0}+ \\ \\
         & + (-g)i\int d^4z\Braket{0|T\phi_0(x)\psi_0(y_1)\psi_0^{\dagger}(y_2)\psi^{\dagger}_0(z)\psi_0(z)\phi_0(z)|0}+\\ \\
         &+(-g)^2i^2\int d^4z_1d^4z_2\Braket{0|T\phi_0(x)\psi_0(y_1)\psi_0^{\dagger}(y_2)\psi^{\dagger}_0(z_1)\psi_0(z_1)\phi_0(z_1)\psi^{\dagger}_0(z_2)\psi_0(z_2)\phi_0(z_2)|0}+\dots
    \end{array}
\end{equation}
Vemos que cada orden añade más integrales, por lo que cortaremos a orden cuadrático. Ahora aplicamos el Teorema de Wick para hacer la ordenación temporal de los campos. Lo haremos orden a orden,
\begin{itemize}
    \item \textbf{Orden 0:} Como vimos antes, para cuatro campos tendremos términos totalmente contraídos, que serán los términos que sobreviven, pues los términos ordenados normalmente se anulan. Para el caso de tres campos no hay términos puramente contraídos, por lo que al tener todos los términos un campo con orden normal, el término de orden cero se anula, tal que
    \begin{equation}
        \Braket{0|T\phi_0(x)\psi_0(y_1)\psi_0^{\dagger}(y_2)|0}=0
    \end{equation}
    \item \textbf{Orden }$\mathbf{g}:$ Primero de nada debemos aplicar el Teorema de Wick, pues tenemos seis campos, que usando el Corolario 5.3.3 sabemos que tendremos como máximo un término de los $\phi_0$ y tres términos de los $\psi_0$ puramente contraídos, siendo los términos que no se anulan. Veámoslo,
    \begin{equation}
    \begin{array}{l}
        
        T\phi_0(x)\psi_0(y_1)\psi_0^{\dagger}(y_2)\psi^{\dagger}_0(z)\psi_0(z)\phi_0(z) =\text{ términos de orden normal }+ \\  \\
          +\contraction{}{\phi_0(x)}{}{\phi_0(z)}\phi_0(x)\phi_0(z)\left(\contraction{}{\psi_0(y_1)}{}{\psi_0^{\dagger}(y_2)}\psi_0(y_1)\psi_0^{\dagger}(y_2)\contraction{}{\psi_0^{\dagger}(z)}{}{\psi_0(z)}\psi_0^{\dagger}(z)\psi_0(z)++\contraction{}{\psi_0(y_1)}{}{\psi_0^{\dagger}(z)}\psi_0(y_1)\psi_0^{\dagger}(z)\contraction{}{\psi_0^{\dagger}(y_2)}{}{\psi_0(z)}\psi_0^{\dagger}(y_2)\psi_0(z)+\contraction{}{\psi_0(y_1)}{}{\psi_0(z)}\psi_0(y_1)\psi_0(z)\contraction{}{\psi_0^{\dagger}(y_2)}{}{\psi_0^{\dagger}(z)}\psi_0^{\dagger}(y_2)\psi_0^{\dagger}(z)\right)
    \end{array}
    \end{equation}
En el último sumando estamos contrayendo $\psi_0$ con $\psi_0$ y $\psi_0^{\dagger}$ con $\psi_0^{\dagger}$, que al tratarse de campos escalares complejos, estas contracciones se anulan, pues para campos escalares complejos, $\psi\in\mathbb{C}$, se cumple que, $\Braket{0|T\psi\psi|0}=\Braket{0|T\psi^{\dagger}\psi^{\dagger}|0}=0$. Por tanto, aplicando ahora el módulo de los espacios de Fock, anulando los términos de ordenamiento normal, queda
\begin{equation}\small
    \Braket{0|T\phi_0(x)\psi_0(y_1)\psi_0^{\dagger}(y_2)\psi^{\dagger}_0(z)\psi_0(z)\phi_0(z)|0}=\Delta_m(x-z)\left[\Delta_M(y_1-y_2)\Delta_M(z-z)+\Delta_M(y_1-z)\Delta_M(y_2-z)\right]
\end{equation}
donde los $\Delta$ son los propagadores de Feynman, que distinguimos en función de los campos que representen.
Luego, tenemos la integral
\begin{equation}
    (-g)i\int d^4z\Delta_m(x-z)\left[\Delta_M(y_1-y_2)\Delta_M(z-z)+\Delta_M(y_1-z)\Delta_M(y_2-z)\right]
\end{equation}
\item \textbf{Orden }$\mathbf{g^2:}$ Como tenemos 9 campos, al tener un número impar, no tendremos términos puramente contraídos, por lo que también se anulará,
    \begin{equation}
        \Braket{0|T\phi_0(x)\psi_0(y_1)\psi_0^{\dagger}(y_2)\psi^{\dagger}_0(z_1)\psi_0(z_1)\phi_0(z_1)\psi^{\dagger}_0(z_2)\psi_0(z_2)\phi_0(z_2)|0}=0
    \end{equation}
\end{itemize}
Como de forma general tendremos expresiones muy complejas para tratar con los cálculos, usaremos los diagramas de Feynman para simplificar los cálculos, y luego aplicaremos el Teorema LSZ para obtener las fórmulas de los diagramas de Feynman simplificadas.\\ \\
El número de ramas, entrantes y salientes, del diagrama de Feynman que queramos representar dependerá del número de partículas iniciales y finales que tengamos en la interacción. Estas ramas deberán unirse mediante vértices internos, que dependerán del orden de $g$ en el que estemos, de forma que si estamos en el orden $g^m$, tendremos $m-$vértices internos y por convenio deberemos añadir un factor $(-ig)$ por cada vértice interno, así, si estamos a orden $g^m$, tendremos el factor $(-ig)^m$.\\ \\
Así, para nuestro sistema $\phi(x)\to \psi(y_1)+\bar{\psi}(y_2)$, como solo el orden $g$ tiene términos no nulos, tendremos un vértice interno $(z)$, teniendo así los diagramas de Feynman siguientes,
\begin{Figura}
    \centering
    \includegraphics[width=0.8\textwidth]{imagenes/diagrama5.4.1.png}
    \label{diag5.4.1}
\end{Figura}
Debemos tener en cuenta, que cada línea de los diagramas de Feynman son distintas, siempre que tengamos masas distintas. La flecha indica el adjunto al otro, es decir, como tenemos $\psi(y_1)$ y $\bar{\psi}(y_2)$, como $\psi(y_1)$ apunta en un sentido, su adjunto, $\bar{\psi}(y_2)$ apuntará en el otro sentido.\\ \\
El diagrama completo será todas las posibilidades de las distintas formas de unir los puntos, tal que
\begin{center}
\begin{fmffile}{diagrama541}
  \begin{fmfgraph*}(100,60)
    \fmfright{i1,i2}       % Entradas visuales (ahora serán salidas físicas)
    \fmfleft{o1}           % Salida visual (origen del vértice)

    % Flechas SALIENDO del vértice hacia la derecha
    \fmf{fermion}{v4,v2}
    \fmf{phantom}{v5,v4}
    \fmf{fermion}{i1,v5}
    \fmf{fermion}{v2,v6}
    \fmf{phantom}{v6,v7}
    \fmf{fermion}{v7,i2}

    % El fotón también sale hacia la izquierda (sin reverse)
    \fmf{dashes}{o1,v3}
    \fmf{phantom}{v3,v1}
    \fmf{dashes}{v1,v2}
    \fmf{phantom}{v3,o1}


  \end{fmfgraph*}
\end{fmffile}
\end{center}
\[\hspace{1mm}\]
Para el cálculo, usamos LSZ y la transformada de Fourier de las funciones de Green, escribiendo los propagadores de Feynman de forma explícita, centrándonos en el término de la delta, tal que
\begin{equation}
    \begin{array}{l}
         \tilde{G}_3(q_0,q_1,q_2)=-ig\int d^4z\int d^4x\int d^4y_1\int d^4y_2 e^{ixq_0+iy_1q_1+iy_2q_2}\times \\ \\
         \times\int \frac{d^4k_1}{(2\pi)^4}\int\frac{d^4k_2}{(2\pi)^4}\int\frac{d^4k_3}{(2\pi)^4}e^{-ik_1(x-z)}e^{-ik_2(y_1-z)}e^{-ik_3(y_2-z)}\frac{i}{k_1^2-m^2+i\epsilon}\frac{i}{k_2^2-M^2+i\epsilon}\frac{i}{k_3^3-M^2+i\epsilon}+\dots
    \end{array}
\end{equation}
Como para $z,x,y_1,y_2$ tenemos exponenciales, hacemos las integrales de las exponenciales que nos dan deltas de Dirac, y con las deltas integramos los momentos, obteniendo,
\begin{equation}
    \tilde{G}_3(q_0,q_1,q_2)=-ig(2\pi)^4\delta^{(4)}(q_0+q_1+q_2)\frac{i^3}{\left(q_0^2-m^2+i\epsilon\right)\left(q_1^2-M^2+i\epsilon\right)\left(q_2^2-M^2+i\epsilon\right)}+\dots
\end{equation}
Debemos notar que, por la delta, los momentos que entran en $z$ deben ser igual a los momentos que salen, pues la invariancia de las traslaciones en $\Braket{0|T\phi_0(x)\psi_0(y_1)\psi^{\dagger}_0(y_2)|0}$ se traduce en una conservación del momento. Tomando $q_0\equiv-p$, tenemos
\begin{equation}
    \tilde{G}_3(-p,q_1,q_2)=-g\frac{1}{\left(p^2-m^2+i\epsilon\right)\left(q_1^2-M^2+i\epsilon\right)\left(q_2^2-M^2+i\epsilon\right)}+\dots
\end{equation}
donde los factores multiplicativos de $\frac{1}{p^2-m^2}$ son los propagadores de ramas.\\ \\
Para calcular la amplitud de colisión, $\mathscr{M}$, deberemos multiplicar por el inverso de los propagadores de ramas, cargándose estos mismos, obteniendo que
\begin{equation}
    \mathscr{M}(\phi\to\psi\bar{\psi})=\mathscr{M}_{\psi q_1\bar{\psi}q_2,\phi p}=-g+\dots+\mathscr{O}(g^3)
\end{equation}
Observando los diagramas anteriores, vemos que el diagrama de la izquierda es disconexo, por lo que los momentos se conservan por separado, esto implica que el momento en $x$ sea $0$, pues no puede conservarse con nada. Entonces, el único caso de $p=0$ es el vacío y como hemos empezado con una partícula, este proceso va a cero, por lo que este diagrama no lo contemplamos.\\ \\
Ahora vamos a ver el denominador, tenemos
\begin{equation}
    \Braket{0|e^{iS_{int}}|0}
\end{equation}
que equivale al diagrama,
\begin{Figura}
    \centering
    \includegraphics[width=0.15\textwidth]{imagenes/diag5.4.2.png}
    \label{diag5.4.2}
\end{Figura}
Este tipo de diagramas se conocen como \textbf{diagramas de vacío}, donde no tenemos puntos externos, solo integrados. Por tanto, tenemos
\begin{equation}
    \frac{\Braket{0|T\phi_0\psi_0\psi_0^{\dagger}e^{iS_{int}}|0}}{\Braket{0|e^{iS_{int}}|0}}=\frac{\text{diag derecha}+\text{diag izquierda}+\dots}{1+\text{diag vacío}+\dots}=\text{diag derecha}+\dots
\end{equation}
donde usamos que
\begin{equation}
    \frac{1}{1+\text{diag vacío}}=1-\text{diag vacío}+\dots
\end{equation}
y hemos cortado a orden $g$, que es orden que estamos estudiando. Por tanto, a nuestro orden, la amplitud de colisión es,
\begin{equation}
    \mathscr{M}(\phi\to\bar{\psi}\psi)=-g
\end{equation}
Veamos otro ejemplo. Si tenemos una interacción del tipo $-g\psi^{\dagger}\psi\phi$ y queremos calcular la amplitud de colisión $\mathscr{M}(\bar{\psi}\psi\to\bar{\psi}\psi)$. Tendremos una función de Green de cuatro puntos, $\hat{G}_4(p_1,p_2,p_3,p_4)$ que será la que nos interese para obtener la amplitud de colisión y vamos a resolverla directamente con los diagramas. Tenemos el diagrama,
\begin{center}
    \begin{fmffile}{blobdiagram}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1,l2}
  \fmfright{r1,r2}
  \fmf{fermion}{v,l1}
  \fmf{fermion}{l2,v}
  \fmf{fermion}{r1,v}
  \fmf{fermion}{v,r2}

  % Dibuja un "blob" en el vértice central
  \fmfblob{.16w}{v}
\end{fmfgraph*}
\end{fmffile}
\end{center}
que dependiendo del orden que tengamos, tendremos más o menos vértices internos.
\begin{note}
    Si tenemos varias partículas que forman un diagramas desconectado, podremos descomponerlo en diagramas conectados más simples.
\end{note}
\begin{itemize}
    \item \textbf{Orden 0:} A orden cero no tenemos vértices internos, luego, tendremos los diagramas siguientes,\[\hspace{1mm}\]
    \begin{multicols}{2}
        \begin{center}
    \begin{fmffile}{blobdiagram1}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1,l2}
  \fmfright{r1,r2}
  \fmf{fermion}{l2,l1}
  \fmf{fermion}{l2,l1}
  \fmf{fermion}{r1,r2}
  \fmf{fermion}{r1,r2}

  % Dibuja un "blob" en el vértice central
  %\fmfblob{.16w}{v}
\end{fmfgraph*}
\end{fmffile}
\end{center}
\begin{center}
    \begin{fmffile}{blobdiagram2}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1,l2}
  \fmfright{r1,r2}
  \fmf{fermion}{r1,l1}
  \fmf{fermion}{l2,r2}
  \fmf{fermion}{r1,l1}
  \fmf{fermion}{l2,r2}

  % Dibuja un "blob" en el vértice central
  %\fmfblob{.16w}{v}
\end{fmfgraph*}
\end{fmffile}
\end{center}
    \end{multicols}
    \[\hspace{1mm}\]
    Son diagramas desconectados y nos dicen que no pasa nada, pues tenemos una partícula y una antipartícula, cuyos momentos son iguales, teniendo la identidad en la matriz $S$. Por lo que no incluimos estos diagramas, ya que no contribuyen.
    \item \textbf{Orden }$\mathbf{g:}$ A este orden solo tenemos un único vértice interno, pero a la hora de representar el diagrama es imposible conectar los puntos, por lo que este orden es cero.
    \item \textbf{Orden }$\mathbf{g^2:}$ A este orden tenemos dos vértices internos, para ver todas las posibilidades de unir los vértices deberemos usar combinatoria, de forma que tenemos 3 diagramas, tal que
    \begin{multicols}{3}
    \begin{center}
\begin{fmffile}{diagra1}
\begin{fmfgraph*}(100,60)
  \fmfleft{i1,i2}
  \fmfright{o1,o2}
  \fmf{fermion}{i1,v1}
  \fmf{fermion}{i2,v1}
  \fmf{dashes}{v1,v2}
  \fmf{fermion}{v2,o1}
  \fmf{fermion}{v2,o2}
    \fmflabel{$p_2$}{i1}
    \fmflabel{$p_1$}{i2}
    \fmflabel{$p_4$}{o1}
    \fmflabel{$p_3$}{o2}
\end{fmfgraph*}
\end{fmffile}
\end{center}
\begin{center}
\begin{fmffile}{diagra2}
\begin{fmfgraph*}(100,60)
  \fmfleft{i1,i2}
  \fmfright{o1,o2}
  \fmf{fermion}{i1,v1}
  \fmf{fermion}{i2,v2}
  \fmf{dashes}{v1,v2}
  \fmf{fermion}{v1,o1}
  \fmf{fermion}{v2,o2}
    \fmflabel{$p_2$}{i1}
    \fmflabel{$p_1$}{i2}
    \fmflabel{$p_4$}{o1}
    \fmflabel{$p_3$}{o2}
\end{fmfgraph*}
\end{fmffile}
\end{center}
\begin{center}
\begin{fmffile}{diagra3}
\begin{fmfgraph*}(100,60)
  \fmfleft{i1,i2}
  \fmfright{o1,o2}
  \fmf{fermion}{v1,i1}
  \fmf{fermion}{i2,v1}
  \fmf{dashes}{v1,v2}
  \fmf{fermion}{v2,o1}
  \fmf{fermion}{o2,v2}
    \fmflabel{$p_4$}{i1}
    \fmflabel{$p_1$}{i2}
    \fmflabel{$p_3$}{o1}
    \fmflabel{$p_2$}{o2}
\end{fmfgraph*}
\end{fmffile}
\end{center}
    \end{multicols}
    Veamos las expresiones de estos diagramas:
    \begin{itemize}
        \item \textbf{Diagrama 1:} Para el primer diagrama suponemos todos los momentos entrantes, pero como tenemos flechas salientes, los momentos de $p_3$ y $p_4$ tendrán el signo negativo. Como la invariancia bajo traslaciones se traduce como la conservación del momento, el momento total del propagador interno será $\xrightarrow{p_1+p_2}$ ó $\xleftarrow{p_3+p_4}\equiv\xrightarrow{-p_3-p_4}$, por tanto, tendremos que $p_3+p_4=-(p_1+p_2)$, obteniendo la delta de conservación del momento,
        \begin{equation}
            \sum_ip_i=0
        \end{equation}
        Por tanto, la función de Green de este diagrama será,
        \begin{equation}
            \tilde{G}_4(p_1,p_2,-p_3,-p_4)=(-ig)^2\frac{i}{p_1^2-M^2}\frac{i}{p_2^2-M^2}\frac{i}{p_3^3-M^2}\frac{i}{p_4^4-M^2}\frac{i}{(p_1+p_2)^2-m^2}
        \end{equation}
        donde el último término se refiere al propagador interno, cuya masa no es la misma que los campos $\psi$, sino que el propagador deberá tener una masa $m\neq M$, que se corresponderá con el campo de interacción, en nuestro caso será $\phi$.\\ \\
        Tendremos una integral por cada momento que no esté fijado (no por cada vértice), pero en este caso tenemos todos los momentos fijados.
        \item \textbf{Diagrama 2:} Repitiendo el procedimiento anterior, vemos que para el segundo diagrama la función de Green es,
        \begin{equation}
            \tilde{G}_4=(-ig)^2\frac{i}{p_1^2-M^2}\frac{i}{p_2^2-M^2}\frac{i}{p_3^3-M^2}\frac{i}{p_4^4-M^2}\frac{i}{(p_1-p_3)^2-m^2}
        \end{equation}
        donde el momento total del propagador interno será $p_1-p_3$.
        \item \textbf{Diagrama 3:} Con este diagrama debemos tener cuidado, pues vemos que $p_1$ se une con $p_4$ y $p_2$ se une con $p_3$, pero como los campos correspondientes a cada uno de los momentos son el mismo, es decir, $\psi(p_1)\to\psi(p_4)$ y $\bar{\psi}(p_2)\to\bar{\psi}(p_3)$. Hemos visto que para campos complejos, si tenemos $\Braket{0|T\psi\psi|0}$ ó $\Braket{0|T\bar{\psi}\bar{\psi}|0}$, ambos se anulan. Por tanto, el tercer diagrama será cero.
    \end{itemize}
\end{itemize}
\begin{note}
    Los diagramas se nombrarán según el momento del propagador interno, usando las variables de Mandelstam, tal que
    \[\begin{array}{rcl}
        (p_1+p_2)^2=s & \Rightarrow & \text{Diagrama tipo }S \\
        (p_1-p_3)^2=t & \Rightarrow & \text{Diagrama tipo }T \\
        (p_1-p_4)^2=u & \Rightarrow & \text{Diagrama tipo }U 
    \end{array}\]
\end{note}
Luego, la función de Green total será,
\begin{equation}
    \tilde{G}_4=(-ig)^2\frac{i}{p_1^2-M^2}\frac{i}{p_2^2-M^2}\frac{i}{p_3^3-M^2}\frac{i}{p_4^4-M^2}\brackets{\frac{i}{(p_1+p_2)^2-m^2}+\frac{i}{(p_1-p_3)^2-m^2}}
\end{equation}
Luego, para obtener la amplitud de colisión multiplicamos por el inverso de los propagadores de ramas, obteniendo la función de Green amputada del sistema,
\begin{equation}
    \tilde{G}_4^{amp}=(-ig)^2\brackets{\frac{i}{(p_1+p_2)^2-m^2}+\frac{i}{(p_1-p_3)^2-m^2}}
\end{equation}
que se relaciona con la amplitud de colisión, tal que
\begin{equation}
    i\mathscr{M}(q_1,\dots,q_n;p_1,\dots,p_m)=\left.\hat{G}_4^{amp}\left(-p_1,\dots,-p_m;q_1,\dots,q_n\right)\right|^{\sum\limits_{i=1}^mp_1=\sum\limits_{j=1}^nq_j}_{\begin{array}{l}
        p_i^2=m_i^2\\
        q_j^2=m_j^{'2}
    \end{array}}
\end{equation}
donde 
\begin{equation}
    \tilde{G}(p_1,\dots,p_n)=\int d^4x_1\dots d^4x_n e^{ix_np_n}G_n(x_1,\dots,x_n)
\end{equation}
Por tanto, la amplitud de colisión queda,
\begin{equation}
    \mathscr{M}=-ig^2\brackets{\frac{i}{(p_1+p_2)^2-m^2}+\frac{i}{(p_1-p_3)^2-m^2}}\equiv-ig^2\brackets{\frac{i}{s-m^2}+\frac{i}{t-m^2}}
\end{equation}
Vemos que el primer diagrama es un diagrama tipo $S$ y el segundo diagrama es un diagrama tipo $T$.
\begin{note}
    Si no tenemos todos los momentos fijados, es decir, si tenemos un diagrama del tipo,
    \begin{center}
        \begin{fmffile}{feyn-square}
\begin{fmfgraph*}(100,100)
  \fmfleft{p1,p2}
  \fmfright{q1,q2}

  \fmf{scalar, label=$p_2$}{p1,v1}
  \fmf{scalar, label=$p_1$}{p2,v2}
  \fmf{scalar, label=$p_3$}{v3,q2}
  \fmf{scalar, label=$p_4$}{v4,q1}

  % cuadrado interno
  \fmf{fermion,label=$k$}{v1,v2}
  \fmf{fermion,label=$q$}{v2,v3}
  \fmf{fermion,label=$s$}{v3,v4}
  \fmf{fermion,label=$p$}{v4,v1}
\end{fmfgraph*}
\end{fmffile}
    \end{center}
    Para el propagador de $q$, tendremos que el momento total es $q=p_1+k$; para el propagador de $s$, tendremos que el momento total es $s=q+p-3=p_1+p_3+k$; para el propagador de $p$, tendremos que el momento total es $p=s+p_4=p_1+p_2+p_3+k$ y para el propagador de $k$, tendremos que el momento total es $k=p+p_2$, luego, sustituyendo esto en $s$ tenemos, $k-p_2=p_1+p_2+p_3+k$, luego, anulando las $k$, obtenemos la conservación del momento, $p_1+p_2+p_3+p_4=0$. Aún así, vemos que el momento $k$ no está fijado, pues todos los momentos internos dependen de $k$, por tanto, para obtener el propagador interno de $k$ para la función de Green deberemos integrar sobre $k$.\\ \\
    Tenemos una diferencia topológica entre este diagrama y el anterior, pues en este diagrama tenemos un bucle.\\ \\
    \textbf{Cada bucle añade una integral al cálculo.} Por tanto, cuántos más bucles, tendremos más complejidad.
\end{note}
\subsection{Convenios}
Si tenemos el estado,
\begin{center}
    \begin{fmffile}{blobdiagram4}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1,l2}
  \fmfright{r1,r2}
  \fmf{fermion, label=$p_2$}{v,l1}
  \fmf{fermion, label=$p_1$}{v,l2}
  \fmf{fermion, label=$q_2$}{v,r1}
  \fmf{fermion, label=$q_1$}{v,r2}

  % Dibuja un "blob" en el vértice central
  \fmfblob{.16w}{v}
\end{fmfgraph*}
\end{fmffile}
\end{center}
Por convenio, los momentos $p_i$ iniciales van hacia dentro y en la función de Green le cambiamos el signo.\\ \\
Por convenio, sabemos que las flechas de los campos tienen sentido contrario a las flechas de sus conjugados, tal que
\begin{center}
    \begin{fmffile}{blobdiagram7}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1,l2}
  \fmfright{r1,r2}
  \fmf{fermion, label=$\psi$}{r1,l1}
  \fmf{fermion}{l2,r2}
  \fmf{fermion}{r1,l1}
  \fmf{fermion, label=$\psi^{\dagger}$}{l2,r2}
\end{fmfgraph*}
\end{fmffile}
\end{center}
es decir, deben seguir el sentido de las flechas, ya que dos flechas que apuntan en sentidos opuestos no se pueden juntar, teniendo un estado no disponible.\\ \\
Para las partículas de los estados \textit{in} tenemos,
\begin{center}
    \begin{fmffile}{blobdiagra}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1,l2}
  \fmfright{r1,r2}
  \fmf{fermion, label=$\bar{b}$}{r1,l1}
  \fmf{fermion}{l2,r2}
  \fmf{fermion}{r1,l1}
  \fmf{fermion, label=$b$}{l2,r2}
\end{fmfgraph*}
\end{fmffile}
\end{center}
Para las partículas de los estados \textit{out} tenemos,
\begin{center}
    \begin{fmffile}{blobdiagra}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1,l2}
  \fmfright{r1,r2}
  \fmf{fermion, label=$b$}{r1,l1}
  \fmf{fermion}{l2,r2}
  \fmf{fermion}{r1,l1}
  \fmf{fermion, label=$\bar{b}$}{l2,r2}
\end{fmfgraph*}
\end{fmffile}
\end{center}
donde $b$ es la partícula y $\bar{b}$ es la antipartícula. Así, tenemos,
\[\hspace{1mm}\]
\begin{center}
    \begin{fmffile}{blobdiag}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1,l2}
  \fmfright{r1,r2}

  % Línea real con label para momentum
  \fmf{fermion, label=$p_2\nearrow$}{v,l1}
  \fmf{vanilla, label=$p_1$}{l2,v}
  \fmf{vanilla, label=$q_2$}{v,r1}
  \fmf{fermion, label=$q_1\nearrow$}{v,r2}

  % Conexión fantasma para habilitar etiquetas de vértices
  \fmf{phantom}{l1,v1}
  \fmf{phantom}{l2,v2}
  \fmf{phantom}{v3,r1}
  \fmf{phantom}{v4,r2}

  % Blob en el centro
  \fmfblob{.16w}{v}

  % Etiquetas de vértices (números)
  \fmflabel{$\bar{b}$}{l1}
  %\fmflabel{2}{l2}
  %\fmflabel{3}{r1}
  \fmflabel{$b
  $}{r2}
\end{fmfgraph*}
\end{fmffile}
\end{center}
\[\hspace{1mm}\]
donde vemos que la antipartícula $\bar{b}$ tendrá sentido opuesto al momento $p_2$, mientras que la partícula $b$ tiene el mismo sentido que el momento $q_1$, esto se traduce en un cambio de signo en $p_1$ a la hora de poner los propagadores en la función de Green.\\ \\
Por otro lado, si el campo es real no pondremos flechas a las partículas, solo tendremos las flechas de los momentos, teniendo que la partícula es su propia antipartícula.
\begin{example}
    Tomamos una teoría cuya interacción es,
    \begin{equation}
        \mathscr{L}_{int}=\frac{\lambda}{4!}\phi^4=\tilde{\lambda}\phi^4
    \end{equation}
    siendo $\phi$ un campo escalar real. Queremos calcular un proceso del tipo,
    \begin{equation}
        \phi+\phi\to\phi+\phi
    \end{equation}
    Para ello, tendremos diagramas del tipo,
    \[\hspace{1mm}\]
  \begin{center}
\begin{fmffile}{loopx}
\begin{fmfgraph*}(120,80)
  \fmfleft{i1,i2}
  \fmfright{o1,o2}

  % Conexiones externas
  \fmf{vanilla}{i1,z}
  \fmf{vanilla}{i2,z}
  \fmf{vanilla}{w,o1}
  \fmf{vanilla}{w,o2}

  % Bucle tipo X
  \fmf{plain,right,tension=0.4}{z,w}
  \fmf{plain,left,tension=0.4}{z,w}

  % Etiquetas externas (1-4)
  \fmflabel{2}{i1}
  \fmflabel{1}{i2}
  \fmflabel{4}{o1}
  \fmflabel{3}{o2}

  % Etiquetas internas (z, w)
  \fmfv{label=$z$,label.angle=180,label.dist=3}{z}
  \fmfv{label=$w$,label.angle=0,label.dist=3}{w}
\end{fmfgraph*}
\end{fmffile}
\end{center}
Ahora debemos aplicar combinatoria para ver las formas distintas de unir los puntos del diagrama anterior. Vemos que la primera rama puede unirse a ambos vértices internos, luego tendrá un factor $2$, y también vemos que a estos vértices pueden conectarse los cuatro vértices restantes, luego para la primera rama tendremos $2\cdot4$. Para la segunda rama, solo podrá unirse a un vértice, pues el otro estará ocupado por la rama $1$, luego tendrá un factor $1$, además, a este vértice solo podrán unirse $3$ vértices más, por lo que la rama $2$ tendrá $1\cdot3$. Para la rama $3$ también tendremos un único vértice interno disponible, pero a este vértice se le podrán unir los cuatro vértices restantes, luego tendrá un factor $1\cdot 4$. Vemos que la rama $4$ solo puede unirse a un vértice y a éste solo pueden unirse los tres restantes, teniendo un factor $1\cdot3$. Por último, debemos ver la rama del propagador $z-w$, que solo puede unirse a dos ramas externas y entre ellos, luego tendrá un factor $2\cdot1$. Así, la combinatoria nos da,
\[(2\cdot4)\cdot(1\cdot3)\cdot(1\cdot4)\cdot(1\cdot3)\cdot(2\cdot1)=4!\cdot4!\]

que será el número máximo de combinaciones posibles. Sabemos que cada vértice interno tendrá un factor $i\tilde{\lambda}$ multiplicando, por tanto, al tener dos vértices internos, tendremos $(i\tilde{\lambda})^2=\left(\frac{i\lambda}{4!}\right)^2$. Además deberemos multiplicar por un factor $1/s$, donde $s$ es el peso del diagrama y en nuestro caso es $s=2$, luego, cancelando los $4!^2$, tendremos un factor $\frac{1}{2}(i\lambda)^2$. Además, el $1/2$ representa una simetría tipo $\mathbb{Z}_2$, es decir, se queda invariante al girar sobre el eje de simetría, por lo que quitamos la mitad de los posibles diagramas, pues son el mismo.
\end{example}
\begin{remark}
    Los \textbf{diagramas tipo árbol} son aquellos que, dado un cierto número de partículas, serán los que menos vértices conectados tengan, sin bucles. Matemáticamente, son aquellos diagramas que, si cortamos una rama, hacemos que sean desconexos. Los \textbf{diagramas loops} (bucles) serán de orden superior, teniendo más bucles cuánto mayor sea el orden.\\ \\
    En los diagramas loops, tendremos integrales divergentes, que se asocian con distancias tan cortas que nos permiten cancelar estos infinitos, obteniendo una teoría finita y bien definida; esto se denomina \textbf{renormalización}.\\ \\
    En diagramas tipo árbol de tipo $S$, podremos ajustar los momentos $p_1$ y $p_2$ para que $s=m^2$, teniendo una divergencia. Para solucionarlo, introducimos diagramas con loops internos, incluyendo en la amplitud de colisión términos del tipo,
    \begin{equation}
       \mathscr{M}\sim \frac{i}{s-m^2+i\epsilon+\sum(s)}\overset{s\approx m^2}{=}\frac{i}{s-m^2+im\Gamma}
    \end{equation}
    obteniendo un \textbf{propagador corregido}, donde $\Gamma$ es la anchura. 
\end{remark}
\section{Acoplamiento derivativo}
En teoría cuántica de campos, el término \textit{acoplamiento derivativo} se refiere a interacciones cuya estructura involucra derivadas de los campos. Formalmente, un término de la densidad lagrangiana de interacción exhibe acoplamiento derivativo si contiene derivadas actuando sobre uno o más campos, en lugar de depender directamente de los campos sin derivar. Es decir, en lugar de un producto directo de campos (por ejemplo, un término de interacción usual $\lambda\,\phi_1 \phi_2 \phi_3$), aparece una combinación donde al menos un campo está diferenciado. Un ejemplo genérico sería un término del tipo $\mathcal{L}_{\text{int}} \supset g\,(\partial_\mu \phi)\,\chi^\mu$, donde $g$ es una constante de acoplamiento y $\chi^\mu$ representa otro campo (por ejemplo, una corriente vectorial a la que $\phi$ se acopla). Tales términos son invariantes relativistas (las derivadas $\partial_\mu$ se transforman como vectores bajo transformaciones de Lorentz) y, como se discute a continuación, suelen surgir debido a requisitos de simetría en el modelo físico.\\ \\
El acoplamiento derivativo juega un papel crucial en muchos modelos, especialmente aquellos con simetrías continuas rotas espontáneamente. Un caso fundamental es el de las simetrías globales espontáneamente rotas: el correspondiente bosón de Nambu–Goldstone (un campo escalar o pseudoescalar) posee una simetría de fase o \textit{traslación} que lo hace inobservable si es homogéneo (es decir, la densidad lagrangiana es invariante bajo la transformación $\phi(x) \to \phi(x) + \text{constante}$). Como consecuencia, todas las interacciones de un Goldstone puro deben involucrar al menos una derivada del campo; en otras palabras, el bosón de Goldstone no puede aparecer linealmente (sin derivar) en la lagrangiana a bajo orden. Esto implica que a bajas energías o momento nulo el efecto de tales interacciones se suprime fuertemente: por ejemplo, la amplitud de emisión o dispersión de un bosón de Goldstone con momento muy pequeño tiende a cero (la conocida \textit{condición de Adler} en la física de los piones). Así, los acoplamientos derivativos garantizan que estas interacciones sean \textit{suaves} (\textit{soft}) en el régimen de baja energía, intensificándose solo cuando el intercambio de momento aumenta, en concordancia con la protección impuesta por la simetría subyacente.\\ \\
La forma típica de un acoplamiento derivativo es la de un campo escalar acoplado a una corriente conservada. Por ejemplo, si $\phi(x)$ es el bosón de Goldstone asociado a una simetría global $U(1)$, su interacción efectiva de menor dimensión puede escribirse como:
\begin{equation}
\mathscr{L}_{\text{int}} \;=\; \frac{1}{F}\,\partial_\mu \phi(x)\;J^\mu(x)\,,
\end{equation}
donde $J^\mu(x)$ es la corriente de Noether conservada ($\partial_\mu J^\mu=0$) de la simetría en cuestión, y $F$ es una constante con dimensiones de energía (relacionada con la escala de ruptura de la simetría, a veces denominada \textit{constante de decaimiento} del bosón). Este término de interacción acopla derivativamente las variaciones del campo $\phi$ (a través de $\partial_\mu \phi$) a la corriente de carga asociada, y es consistente con el hecho de que para un campo $\phi$ con simetría de desplazamiento global, un campo $\phi$ uniforme no puede producir efectos físicos (solo los gradientes del campo generan interacción).\\ \\
Un caso emblemático es el del \textit{axión} de Peccei–Quinn, un campo pseudoescalar que, al ser un pseudo-Nambu–Goldstone de una simetría global, solo posee interacciones derivativas con los campos del Modelo Estándar. En particular, el acoplamiento axión–fermión puede expresarse mediante:
\begin{equation}
\mathscr{L}_{a\text{-ferm}} \;=\; \frac{\partial_\mu a(x)}{f_a}\,\bar{\psi}(x)\,\gamma^\mu \gamma^5\,\psi(x)\,,
\end{equation}
que involucra explícitamente la derivada del campo de axión $a(x)$ acoplada a la corriente axial $J_5^\mu(x) = \bar{\psi}(x)\gamma^\mu \gamma^5 \psi(x)$ de un fermión $\psi$ (aquí $f_a$ es la constante de acoplamiento, correspondiente a la escala de Peccei–Quinn). Si dicha corriente axial fuera estrictamente conservada ($\partial_\mu J_5^\mu = 0$, lo cual ocurriría en el límite $m_\psi \to 0$ y ausencia de anomalías quirales), entonces este término derivativo equivaldría a una derivada total que no contribuye a las ecuaciones de movimiento (reflejando que un auténtico Goldstone puro no genera interacción a nivel macroscópico). Sin embargo, en la realidad $J_5^\mu$ no es perfectamente conservada (se viola por las masas de los fermiones y por la anomalía quiral de Adler–Bell–Jackiw), de modo que el acoplamiento derivativo del axión sí produce efectos físicos importantes. En efecto, a través de la anomalía, el término $\frac{1}{f_a}\,\partial_\mu a\,J_5^\mu$ se traduce en acoplamientos efectivos de $a$ con campos de gauge, como $a\,G_{\mu\nu}\tilde{G}^{\mu\nu}$ (interacción del axión con el sector de gluones, responsable de dotarle de una pequeña masa) y $a\,F_{\mu\nu}\tilde{F}^{\mu\nu}$ (acoplamiento del axión a dos fotones, relevante para su posible detección experimental).\\ \\
En resumen, el acoplamiento derivativo es una característica esencial de los campos tipo Goldstone (como el axión), garantizando la consistencia con las simetrías y dictando la forma ``suave'' de sus interacciones a bajas energías, a la vez que permite interacciones observables cuando dichas simetrías se rompen ligeramente (por ejemplo, por efectos de anomalía o términos de masa).
\includepdf[pages=-]{Entregable4_QFT.pdf}
\chapter{Fermiones. Campos espinoriales}
\section{Introducción}
En la formulación relativista de la teoría cuántica de campos, una cuestión fundamental es cómo representar partículas de espín diferente de cero, en particular fermiones de espín $\frac{1}{2}$. Mientras que los campos escalares $\phi(x)$ proporcionan una descripción adecuada para partículas bosónicas de espín cero, no son suficientes para describir fermiones, cuya estadística y transformaciones relativistas imponen requisitos adicionales.\\ \\

La motivación principal para introducir campos espinoriales proviene de la clasificación de las representaciones unitarias irreducibles del grupo de Poincaré. Dicho grupo, que codifica las simetrías fundamentales del espacio-tiempo de Minkowski, admite representaciones caracterizadas por la masa $m$ y el espín $s$ de la partícula. Para espín distinto de cero, las funciones de onda deben transformarse no como escalares, sino de acuerdo con representaciones no triviales del grupo de Lorentz.\\ \\

En particular, las partículas de espín $\frac{1}{2}$ corresponden a la representación $(\tfrac{1}{2}, 0) \oplus (0, \tfrac{1}{2})$ del grupo de Lorentz, lo cual requiere el uso de campos con múltiples componentes que se transforman de manera específica bajo transformaciones de Lorentz. Estos objetos se denominan \emph{espinores de Dirac}, y se agrupan en un campo cuántico $\psi(x)$ de cuatro componentes, cuyo comportamiento transforma correctamente bajo simetrías relativistas.\\ \\

Además del aspecto de simetría, las partículas de espín semi-entero obedecen la \textit{estadística de Fermi-Dirac}, lo que impone que los operadores asociados a su creación y aniquilación deben satisfacer \emph{relaciones de anticonmutación}, en contraste con los campos bosónicos que conmutan. Esta exigencia garantiza la validez del principio de exclusión de Pauli y la correcta estructura de los niveles de energía.\\ \\

Por tanto, el uso de campos espinoriales no es simplemente una elección estética o técnica, sino una necesidad impuesta por la consistencia de la teoría con los principios de simetría, causalidad y estadística cuántica. La formulación de Weinberg enfatiza este punto, mostrando que los campos de Dirac surgen naturalmente al exigir que los estados de una partícula de espín $\frac{1}{2}$ transformen de forma covariante bajo el grupo de Poincaré y que su evolución sea compatible con la unitariedad y el espectro de energía positivo.
\section{Fermiones sin masa}
Vamos a considerar partículas sin masa de espín $+1/2$, con la posibilidad de que existan también partículas de espín $-1/2$. Así, considerando partículas de espín $1/2$, tendrán las helicidades posibles $h=\pm1/2$. Tomaremos los operadores de creación y destrucción, $a_s^{\dagger}$ y $a_s$, con $s=\pm$. Esta clase de partículas no pueden describirse por medio de campos escalares (espín $0$), sino que debemos utilizar los \textbf{espinores} $(\chi_{\alpha})$. Recordemos que los espinores \textit{left-handed} transforman como,
\begin{equation}
    \chi_{\alpha}\to N_{\alpha}^{\beta}\chi_{\beta}
\end{equation}
La forma explícita de un campo libre espinorial es la siguiente,
\begin{equation}
    \chi_{\alpha}=\int\frac{d^3p}{(2pi)^3}\frac{1}{\sqrt{2\omega_p}}\sum_{s=\pm}\brackets{u_{\alpha}(s,p)a_s(p)e^{-ipx}+v_{\alpha}(s,p)a_s^{\dagger}e^{+ipx}}
\end{equation}
donde usamos que $p^0=\omega_p=|\vec{p}|$ porque estamos con $m=0$ y $s$ es una etiqueta que recorre los dos posibles valores de helicidad. Es un campo libre de Weyl $LH$, donde omitimos el subíndice $\hspace{0mm}_0$.\\ \\
Vamos a buscar cómo tienen que ser $u_{\alpha}(s,p)$ y $v_{\alpha}(s,p)$ para que $\chi_{\alpha}$ transforme de forma covariante (como un espinor) y poder escribir acciones escalares.\\ \\
Primero vemos cómo transforman $a_s$ y $a_s^{\dagger}$, cuya transformación Lorentz deberá estar determinada por la transformación de un estado de una partícula con helicidad $s$,
\begin{equation}
    \begin{array}{cl}
        U(N)\ket{p}_s & =D^{(s/2)}(W(M,p))\ket{\Lambda p}_s \\
        || & \\
        \sqrt{2\omega_p}U(N)a^{\dagger}_s(p)U(N)^{-1}&=D^{(s/2)}(W(N,p))a_s^{\dagger}(\Lambda p)\ket{0}\sqrt{2\omega_{\Lambda p}}
    \end{array}
\end{equation}
Luego,
\begin{equation}
    U(N)a_s^{\dagger}(p)U(N)^{-1}=\sqrt{\frac{\omega_{\Lambda p}}{\omega_p}}D^{(s/2)}(W(N,p))a_s^{\dagger}(\Lambda p)
\end{equation}
donde $N\in SO(1,3)$, $U(N)$ es una representación unitaria del grupo de Poincaré y $D^{(s/2)}(W(N,p))$ es una matriz de representación del \textit{little group} $SO(3)$. El operador $a_s(p)$ transforma igual pero usando la matriz conjugada de $D$, tal que
\begin{equation}
    U(N)a_s(p)U(N)^{-1}=\sqrt{\frac{\omega_{\Lambda p}}{\omega_p}}D^{(s/2)\dagger}(W(N,p))a_s^{\dagger}(\Lambda p)
\end{equation}
Por tanto, el campo espinorial $\chi_{\alpha}$ transforma como,
\begin{equation}
\begin{array}{rl}
    U(N)\chi_{\alpha}U(N)^{-1}&=\int\frac{d^3p}{(2\pi)^3}\frac{\sqrt{\omega_{\Lambda p}}}{\sqrt{\omega_p^2}}\sum\limits_{s=\pm}\left[e^{-ipx}u_{\alpha}(s,p)D^{(s/2)}(W(N,p))^{\dagger}a_s(\Lambda p)\right.+\\ \\
    &\left.+e^{ipx}v_{\alpha}(s,p)D^{(s/2)}(W(N,p))a_s^{\dagger}(\Lambda p)\right]\\ \\
    &=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{\omega_p}}\sum\limits_{s=\pm}\left[e^{-ip(\Lambda x)}u_{\alpha}(s,\Lambda^{-1}p)D^{(s/2)}(W(N,\Lambda^{-1}p))^{\dagger}a_s(p)\right.+\\ \\
   & \left.+e^{+ip(\Lambda x)}v_{\alpha}(s,\Lambda^{-1}p)D^{(s/2)}(W(N,\Lambda^{-1}p))a_s^{\dagger}(p)\right]
    \end{array}
\end{equation}
y queremos que $\chi_{\alpha}$ transforme como,
\begin{equation}
    U(N)\chi_{\alpha}(x)U(N)^{-1}=N_{\alpha}^{-1\beta}\chi_{\beta}(\Lambda x)
\end{equation}
Para que esto se cumpla, necesitamos que
\begin{equation}
    \begin{array}{c}
         D^{(s/2)}(W(n,p))^{\dagger}u_{\alpha}(s,p)=N_{\alpha}^{-1\beta}u_{\beta}(s,\Lambda p)  \\ \\
         D^{(s/2)}(W,(N,p))v_{\alpha}(s,p)=N_{\alpha}^{-1\beta}v_{\beta}(s,\Lambda p)
    \end{array}
\end{equation}
Vamos a resolver la ecuación para $u_{\alpha}(s,p)$. Para simplificar la ecuación, tomamos
\[\left.\begin{array}{r}
     p=k=(E,0,0,E)  \\
     N=L(k\to q)
\end{array}\right\rbrace\Rightarrow W(N,k)=L^{-1}(k\to\Lambda k)NL(k\to k)=L(\Lambda k)^{-1}L(\Lambda k)\mathds{1}=\mathds{1}\]
donde $L^{-1}(k\to\Lambda k)$ es el inverso de $N$, con $q\equiv\Lambda p$ y $L(k\to k)\equiv\mathds{1}$. 
Así, tenemos 
\begin{equation}
    D^{(s/2)}(W(N,p))^{\dagger}=D^{(s/2)}(\mathds{1})^{\dagger}=\mathds{1}
\end{equation}
Por tanto,
\begin{equation}
     D^{(s/2)}(W(N,p))^{\dagger}u_{\alpha}(s,p)=\mathds{1}u_{\alpha}(s,p)=L(k\to q)_{\alpha}^{-1\beta}u_{\beta}(s,q)
\end{equation}
Luego, despejando tenemos
\begin{equation}
    u_{\alpha}(s,q)=L(k\to q)_{\alpha}^{\beta}u_{\beta}(s,k)
\end{equation}
en este caso, $N\in$\textit{little group}, por lo que $N$ no cambia el momento $p$, teniendo que $W(N)=N\equiv W$ y tomamos de nuevo $k$, tal que
\begin{equation}
    \begin{array}{l}
         D^{(s/2)}(W)^{\dagger}u_{\alpha}(s,k)=W_{\alpha}^{-1\beta}u_{\beta}(s,k)\Rightarrow \\  \\
         \Rightarrow D^{(s/2)}(W^{-1})^{\dagger}u_{\alpha}(s,k)=D^{(s/2)}(W)u_{\alpha}(s,k)=W_{\alpha}^{\beta}u_{\beta}(s,k)
    \end{array}
\end{equation}
teniendo el siguiente problema de autovalores,
\begin{equation}
    D^{(s/2)}(W)u_{\alpha}(s,k)=W_{\alpha}^{\beta}u_{\beta}(s,k)
\end{equation}
Luego, tomando $k=(E,0,0,E)$ y haciendo una transformación infinitesimal del tipo $e^{i\frac{s}{2}\varphi}$, podemos redefinir $D$ tal que,
\begin{equation}
    J_3u(s,k)=\frac{\sigma_3}{2}u(s,k)=\frac{s}{2}u(s,k)
\end{equation}
como $s=\pm$, tendremos que
\begin{equation}
    u(+,k)\propto\begin{pmatrix}
        1\\
        0
    \end{pmatrix};\hspace{6mm}u(-,k)\propto\begin{pmatrix}
        0\\
        1
    \end{pmatrix}
\end{equation}
donde hemos tomado como elemento del \textit{little group} una rotación del eje $Z$, $J_3$. También tendremos otras transformaciones que dejen invariante el \textit{little group}, que corresponden a las otras componentes del vector de Pauli-Lebanski para la representación $LH$, tal que
\begin{equation}
    W_1:=-\frac{1}{2}\begin{pmatrix}
        0 & 0\\
        1 & 0
    \end{pmatrix};\hspace{6mm}W_2:=iW_1
\end{equation}
que aniquilan los vectores, es decir, 
\begin{equation}
    W_1u(s,k)=0\Rightarrow W_2u(s,k)=0
\end{equation}
pues para partículas sin masa, el grupo euclídeo no es compacto, por lo que tendremos representaciones de dimensión finita (que serán de dimensión 1) o representaciones de dimensión infinita (que no consideraremos), por tanto, las representaciones de dimensión 1 se caracterizan por la helicidad, luego, las traslaciones deben dejar la helicidad invariante, y entonces, se deberán aniquilar los vectores.\\ \\
Vemos que,
\begin{equation}
    u(-,k)=\begin{pmatrix}
        0 & 0\\
        1 & 0
    \end{pmatrix}\begin{pmatrix}
        0\\
        1
    \end{pmatrix}\neq0;\hspace{6mm}u(+,k)=\begin{pmatrix}
        0 & 0\\
        1 & 0
    \end{pmatrix}\begin{pmatrix}
        0\\
        0
    \end{pmatrix}=0
\end{equation}
por lo que no podremos tener helicidad $+1/2$, luego, al tener solo helicidad $-1/2$, llegamos a la conclusión de
\begin{equation}
    u(-,k)=\sqrt{2\omega_k}\begin{pmatrix}
        0\\
        1
    \end{pmatrix};\hspace{6mm}u(+,k)=0
\end{equation}
donde hemos normalizado el $u(-,k)$. Repitiendo el mismo proceso para $v_{\alpha}(s,p)$, llegamos a que,
\begin{equation}
    v(-,k)=0;\hspace{6mm}v(+,k)=\sqrt{2\omega_k}\begin{pmatrix}
        0\\
        1
    \end{pmatrix}
\end{equation}
donde
\begin{equation}
    v_{\alpha}(s,q)=L(q)_{\alpha}^{\beta}v_{\beta}(s,k);\hspace{6mm}J_3v(s,k)=-\frac{s}{2}v(s,k)
\end{equation}
Notar que,
\begin{equation}
    v_{\alpha}(s,p)=u_{\alpha}(-s,p)
\end{equation}
Por tanto, usando la desaparición de $u(+)$ y $v(-)$, para el caso sin masa encontramos que el campo $\chi_{\alpha}$ será,
\begin{equation}
    \Psi_{\alpha}(x)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\brackets{e^{-ixp}u_{\alpha}(-,p)a_-(p)+e^{ixp}v_{\alpha}(+,p)b_+^{\dagger}(p)}
\end{equation}
Luego, vemos que se crea una partícula de helicidad $+1/2$ y destruimos una partícula de helicidad $-1/2$. Si queremos lo contrario, es decir, si queremos crear una partícula de helicidad $-1/2$ y destruir una partícula de helicidad $+1/2$, deberemos tomar el adjunto del campo, $\chi_{\dot{\alpha}}^{\dagger}$, tal que
\begin{equation}
    \Psi_{\dot{\alpha}}^{\dagger}=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\brackets{e^{-ixp}\bar{v}_{\dot{\alpha}}(+,p)b_+(p)+e^{ixp}\bar{u}_{\dot{\alpha}}(-,p)a_-^{\dagger}(p)}
\end{equation}
donde $\bar{u}\equiv u^*$ y $\bar{v}\equiv v^*$.\\ \\
Así el campo $\chi_{\alpha}$ es un \textbf{campo de Weyl} en $LH$, asociado a una partícula de helicidad $+1/2$ y $\chi_{\dot{\alpha}}^{\dagger}$ es el \textbf{conjugado del campo de Weyl} en $RH$, asociado a una partícula de helicidad $-1/2$.\\ \\
Si tomamos los operadores $a_-=b_-$ y $a_+=b_+$, obtenemos un \textbf{campo de Majorana}, que viene dado por,
\begin{equation}
    \chi_{\alpha}=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\brackets{e^{-ixp}u_{\alpha}(-,p)a_-(p)+e^{ixp}v_{\alpha}(+,p)a_+^{\dagger}(p)}
\end{equation}
Tomando la representación espinorial del cuadrimomento,
\begin{equation}
    P_{\alpha\dot{\alpha}}=P_{\mu}\sigma_{\alpha\dot{\alpha}}^{\mu}
\end{equation}
podemos ver cómo actúa sobre $u^{\dot{\alpha}}(p)$, tal que
\begin{equation}\small
    P_{\alpha\dot{\alpha}}u^{\dot{\alpha}}(p)=P_{\alpha\dot{\alpha}}\left(L^{-1\dagger}(k\to p)\right)_{\dot{\beta}}^{\dot{\alpha}}\bar{u}^{\dot{\beta}}(k)=\underbrace{L^{-1}(p\to k)_{\alpha}^{\beta}L(p\to k)_{\beta}^{\gamma}}_{\mathds{1}}P_{\gamma\dot{\gamma}}L^{\dagger}(p\to k)_{\dot{\beta}}^{\dot{\gamma}}\bar{u}^{\dot{\beta}}(k)=L(k\to p)_{\alpha}^{\beta}K_{\beta\dot{\beta}}\bar{u}^{\dot{\beta}}(k)
\end{equation}
Ahora, tomando $k=(E,0,0,E)$, tenemos que 
\begin{equation}
    \hat{k}=K_{\beta\dot{\beta}}=2E\begin{pmatrix}
        0 & 0\\
        1 & 0
    \end{pmatrix}
\end{equation}
y por otro lado,
\begin{equation}
    \bar{u}^{\dot{\beta}}(k)=\mathscr{E}^{\dot{\beta}\dot{\alpha}}u^*_{\dot{\alpha}}(k)\sim\begin{pmatrix}
        1\\
        0
    \end{pmatrix}
\end{equation}
Por tanto, como $\begin{pmatrix}
    0 & 0\\
    1 & 0
\end{pmatrix}\begin{pmatrix}
    1\\
    0
\end{pmatrix}=\begin{pmatrix}
    0\\
    0
\end{pmatrix}$, tenemos que $K_{\beta\dot{\beta}}\bar{u}^{\dot{\beta}}(k)=0$, luego $P_{\alpha\dot{\alpha}}\bar{u}^{\dot{\alpha}}(p)=0$. Así, repitiendo el cálculo para todos los casos, tenemos las propiedades siguientes,
\begin{equation*}
    \begin{array}{rlrl}
        (i) & P_{\alpha\dot{\alpha}}\bar{u}^{\dot{\alpha}}(p)=0 & (iii) & P^{\dot{\alpha}\alpha}v_{\alpha}(p)=0 \\ \\
        (ii) & P^{\dot{\alpha}\alpha}u_{\alpha}(p)=0 & (iv) & P_{\alpha\dot{\alpha}}\bar{v}^{\dot{\alpha}}(p)=0
    \end{array}
\end{equation*}
con $P^{\dot{\alpha}\alpha}=P_{\mu}(\bar{\sigma}^{\mu})^{\dot{\alpha}\alpha}$ y $P_{\alpha\dot{\alpha}}=P_{\mu}\sigma_{\alpha\dot{\alpha}}^{\mu}$.\\ \\
Estas propiedades las podemos usar para calcular las derivadas de los campos, pues $P^{\mu}\sim\partial_{\mu}$, obteniendo así la \textbf{ecuación de Weyl},
\begin{equation}
    i\left(\bar{\sigma}^{\mu}\right)^{\dot{\alpha}\alpha}\partial_{\mu}\chi_{\alpha}(x)=0
\end{equation}
Esta ecuación es el caso particular más sencillo de la ecuación de Dirac. El principio físico básico de esta ecuación es la invariancia Lorentz.\\ \\
Podemos encontrar un Lagrangiano tal que, sus ecuaciones del movimiento, nos den esta ecuación. Este Lagrangiano será,
\begin{equation}
    \mathscr{L}=\chi_{\dot{\alpha}}^{\dagger}i\left(\bar{\sigma}^{\mu}\right)^{\dot{\alpha}\alpha}\partial_{\mu}\chi_{\alpha}=\chi_{\dot{\alpha}}^{\dagger}i\partial^{\dot{\alpha}\alpha}\chi_{\alpha}=\chi^{\dagger}i\bar{\sigma}^{\mu}\partial_{\mu}\chi
\end{equation}
Para simplificar la notación escribiremos el Lagrangiano como,
\begin{equation}
    \mathscr{L}=\Psi^{\dagger}i\bar{\sigma}^{\mu}\partial_{\mu}\Psi
\end{equation}
con $Pu=Pv=0$. Ahora, para ir al momento $p$ que queremos, $L(k\to p)$, realizamos una rotación en la dirección de $p$, $\hat{k}\to\hat{p}$, después del boost a lo largo de $\hat{z}$, que convierte la energía $E$ en $|\vec{p}|$.\\ \\
Tenemos entonces que,
\begin{equation}
    \begin{array}{cc}
        u(-,p)=\sqrt{2\omega_p}\chi_-(p); & \bar{u}(-,p)=\sqrt{2\omega_p}\chi_+(p) \\  \\
        v(+,p)=\sqrt{2\omega_p}\chi_-(p); & \bar{v}(+,p)=\sqrt{2\omega_p}\chi_+(p)
    \end{array}
\end{equation}
donde $u$ y $v$ tienen subíndices sin punto, $\bar{u}$ y $\bar{v}$ tienen superíndices con punto, y
\begin{equation}
    \vec{\sigma}\cdot\hat{p}\chi_s(p)=s\chi_s(p),\hspace{4mm}s=\pm1
\end{equation}
Es decir, $u$, $v$, $\bar{u}$ y $\bar{v}$ son autoestados de helicidad. Usando esto, podemos volver a comprobar las ecuaciones de Weyl para $u$, $v$, $\bar{u}$ y $\bar{v}$, tal que
\begin{equation}
P\bar{u}=\sqrt{2\omega_p}P\chi_+ \sqrt{2\omega_p}\left(\omega_p\mathds{1}-\vec{\sigma}\cdot\vec{p}\right)\chi_+=\sqrt{2\omega_p}\left(\omega_p\mathds{1}-|\vec{p}|\mathds{1}\right)\chi_+=0
\end{equation}
en resumen,
\begin{equation}
    \begin{array}{ccc}
        u_{\alpha}(-,p)\bar{u}_{\dot{\alpha}}(-,p)=P_{\alpha\dot{\alpha}}; & u_{\alpha}(+,p)=0; & \sum\limits_su_{\alpha}(s,p)\bar{u}_{\dot{\alpha}}(s,p)=P_{\alpha\dot{\alpha}} \\ \\
        v_{\alpha}(+,p)\bar{v}_{\dot{\alpha}}(+,p)=P_{\alpha\dot{\alpha}}; & v_{\alpha}(-,p)=0; & \sum\limits_sv_{\alpha}(s,p)\bar{v}_{\dot{\alpha}}(s,p)=P_{\alpha\dot{\alpha}}
    \end{array}
\end{equation}
Ahora vamos a comprobar si los campos conmutan a distancias grandes de tipo espacio, pues nos interesará saberlo para estudiar causalidad. Recordamos que
\[\left.\begin{array}{rl}
    \text{\textbf{Bosones:}} & \brackets{a_s(\vec{p}),a_{s'}^{\dagger}(\vec{p})}=(2\pi)^3\delta^{(3)}(\vec{p}-\vec{q})\delta_{ss'}\equiv \brackets{a_s(\vec{p}),a_{s'}^{\dagger}(\vec{p})}_- \\ \\
    \text{\textbf{Fermiones:}} & \curlybraces{a_s(\vec{p}),a_{s'}^{\dagger}(\vec{p})}=(2\pi)^3\delta^{(3)}(\vec{p}-\vec{q})\delta_{ss'}\equiv \brackets{a_s(\vec{p}),a_{s'}^{\dagger}(\vec{p})}_+
\end{array}\right\rbrace\Rightarrow \brackets{a_s(\vec{p}),a_{s'}^{\dagger}(\vec{p})}_{\mp}\]
Luego, podemos calcular los (anti)conmutadores de los campos, tal que
\begin{equation}
    \begin{array}{cc}
        \brackets{\chi_{\alpha}(x),\chi_{\beta}(y)}_{\mp}=\brackets{\chi_{\dot{\alpha}}^{\dagger}(x),\chi_{\dot{\beta}}^{\dagger}(y)}_{\mp}=0 & \brackets{\chi_{\alpha}(x),\chi_{\dot{\beta}}^{\dagger}(y)}_{\mp}\neq0
    \end{array}
\end{equation}
Usando distancias tipo espacio, $(x-y)^2<0$, el último (anti)conmutador sí se anula, tal que
\begin{equation}
\begin{array}{rl}
    \brackets{\chi_{\alpha}(x),\chi_{\dot{\beta}}^{\dagger}(y)}_{\mp}&=\int\frac{d^3p}{(2\pi)^3}\frac{d^3q}{(2\pi)^3}\frac{1}{\sqrt{4\omega_p\omega_q}}\left(e^{-ixp+iyq}u_{\alpha}(-,p)\bar{u}_{\dot{\alpha}}(+,q)\brackets{a_-(p),a_-^{\dagger}(q)}_{\mp}+\right.\\ \\
    &\left.+e^{ixp-iyq}v_{\alpha}(+,p)\bar{v}_{\dot{\alpha}}(-,q)\brackets{a_+^{\dagger}(p),a_+(p)}_{\mp}\right)=\\ \\
    &=\int\frac{d^3p}{`(2\pi)^3}\frac{1}{2\omega_p}\brackets{e^{-i(x-y)p}u_{\alpha}(-,p)\bar{u}_{\dot{\alpha}}(-,p)\mp e^{i(x-y)p}v_{\alpha}(+,p)\bar{v}_{\dot{\alpha}}(+,p)}=\\ \\
&=\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_p}P_{\alpha\dot{\alpha}}\left(e^{-i(x-y)p}\mp e^{i(x-y)p}\right)=i\partial_{\alpha\dot{\alpha}}D(x-y)\mp i\partial_{\alpha\dot{\alpha}}D(y-x)=0
    \end{array}
\end{equation}
Luego, a distancias tipo espacio los campos espinoriales anticonmutan. De hecho, esto ocurre porque al tener distancias tipo espacio, $(x-y)^2<0$, demostramos que $D(x-y)=D(y-x)$, es decir, es par; por lo que su derivada será impar, es decir, $\partial_{\alpha\dot{\alpha}}D(x-y)=-\partial_{\alpha\dot{\alpha}}D(y-x)$. Esta propiedad garantiza que el anticommutador $\{\chi_\alpha(x), \chi^\dagger_{\dot{\alpha}}(y)\}$ se anule para $(x - y)^2 < 0$, preservando la causalidad. Esta estructura requiere que los operadores $\chi_\alpha$ satisfagan relaciones de anticommutación, lo que implica que describen \textbf{partículas fermiónicas}. Por tanto, la combinación de causalidad, energía positiva y simetría de Lorentz obliga a que los campos espinoriales describan fermiones.\\ \\
Luego, como ya sabemos que estamos tratando con fermiones, usaremos el anticonmutador,
\begin{equation}
    \begin{array}{rl}
        \curlybraces{\chi_{\alpha}(x),\chi_{\dot{\alpha}}(x)} &=i\partial_{\alpha\dot{\alpha}}D(x-y)+i\partial_{\alpha\dot{\alpha}}D(y-x)= \\  \\
         & =\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_p}P_{\alpha\dot{\alpha}}\left(e^{-i(x-y)p}+e^{i(x-y)p}\right)
    \end{array}
\end{equation}
Si ahora miramos el anticonmutador para $t=0$,
\begin{equation}
\begin{array}{rl}
    \curlybraces{\chi_{\alpha}(0,\vec{x}),\chi_{\dot{\alpha}}^{\dagger}(0,\vec{y})}&=\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_p}\sigma_{\alpha\dot{\alpha}}^{\mu}P_{\mu}\left(e^{i(\vec{x}-\vec{y})\cdot\vec{p}}+e^{-i(\vec{x}-\vec{y})\cdot\vec{p}}\right)=\\ \\
    &=\int\frac{d^3\vec{p}}{(2\pi)^3}\sigma^0_{\dot{\alpha}\alpha}P_02e^{i(\vec{x}-\vec{y})\cdot\vec{p}}=\delta_{\alpha\dot{\alpha}}\int\frac{d^3p}{(2\pi)^3}e^{i(\vec{x}-\vec{y})\cdot\vec{p}}=\\ \\
    &=\sigma^0_{\dot{\alpha}\alpha}\delta^{(3)}(\vec{x}-\vec{y})
\end{array}
\end{equation}
En efecto, a partir del Lagrangiano anterior, vemos que $i\chi_{\dot{\alpha}}^{\dagger}$ es el momento conjugado de $\chi_{\alpha}$. Actuando con la transformada de Legendre sobre el Lagrangiano, encontramos el Hamiltoniano. Después de hacer el ordenamiento normal (con $:aa^{\dagger}:=-a^{\dagger}a$) tenemos,
\begin{equation}
    H_0=\int\frac{d^3p}{(2\pi)^3}\omega_p\brackets{a_+^{\dagger}(p)a_+(p)+a_-^{\dagger}(p)a_-(p)}
\end{equation}
\section{Propagador de Feynman}
Primero deberemos usar $LSZ$, para lo que necesitaremos
\begin{equation}
    \begin{array}{rl}
        \hspace{0mm}_s\Braket{\vec{p}|\chi_{\alpha}(x)|0} &=\Braket{0|\sqrt{2\omega_p}a_s(p)\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}e^{ixq}v_{\alpha}(+,q)a_+^{\dagger}(q)|0}=  \\ \\
         & =e^{ixp}v_{\alpha}(+,p)\delta_{s+}
    \end{array}
\end{equation}
Repitiendo el proceso tenemos,
\begin{equation}
    \begin{array}{rlrl}
        (i) & \hspace{0mm}_s\Braket{\vec{p}|\chi_{\alpha}(x)|0}=e^{ixp}v_{\alpha}(+,p)\delta_{s+} & (iii) &  \Braket{0|\chi_{\alpha}(x)|\vec{p}}_s=e^{-ixp}u_{\alpha}(-,p)\delta_{s-}\\ \\
        (ii) & \hspace{0mm}_s\Braket{\vec{p}|\chi^{\dagger}_{\dot{\alpha}}(x)|0}=e^{ixp}\bar{u}_{\dot{\alpha}}(-,p)\delta_{s-} & (iv) & \Braket{0|\chi_{\dot{\alpha}}^{\dagger}(x)|\vec{p}}_s=e^{-ixp}\bar{v}_{\dot{\alpha}}(+,p)\delta_{s+}
    \end{array}
\end{equation}
Para demostrar $LSZ$ añadimos el conjugado de los espinores en las expresiones (i) y (ii) para los estados $in$ y $out$. Entonces, asociamos $\bar{v}_{\dot{\alpha}}(+,p)$ y $u_{\alpha}(-,p)$ a las ramas de las partículas iniciales y asociamos $v_{\alpha}(+,p)$ y $\bar{u}_{\dot{\alpha}}(-,p)$ a las ramas de las partículas finales.\\ \\
El campo de Majorana $\chi$ no puede describir partículas cargadas. En este caso, como $\Psi^{\dagger}$ y $\Psi$ son diferentes, no necesitaremos más grados de libertad para describir partículas sin masa y helicidad $\pm1/2$ con carga. Es suficiente con usar los campos de Weyl, que recordamos
\begin{equation}
    \Psi_{\alpha}(x)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\brackets{e^{-ixp}u_{\alpha}(-,p)a_-(p)+e^{ixp}v_{\alpha}(+,p)b_+^{\dagger}}
\end{equation}
Luego,
\begin{equation}
    \Psi_{\dot{\alpha}}^{\dagger}=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\brackets{e^{-ixp}\bar{v}_{\dot{\alpha}}(+,p)b_+(p)+e^{ixp}\bar{u}_{\dot{\alpha}}(-,p)a_-^{\dagger}(p)}
\end{equation}
Por lo que, $a_-^{\dagger}$ crea una partícula con helicidad $-1/2$ y carga $Q$, $b_+^{\dagger}$ crea su antipartícula, con helicidad $+1/2$ y carga $-Q$. En el caso sin masa, cada partícula solo podrá tener una helicidad (y su antipartícula solo tendrá la helicidad opuesta).\\ \\
Excepto para la carga, no existe una distinción real entre el campo de Weyl y el de Majorana para el caso sin masa. Simplemente, en el caso de Majorana decimos que la partícula con helicidad $+1/2$ y la otra con helicidad opuesta son la misma partícula en dos estados diferentes de helicidad. Pero en ambos casos, tenemos dos grados de libertad y todas las ecuaciones que hemos escrito son igualmente válidas, solo identificando las partículas con helicidad $+1/2$ (partículas $RH$) como antipartículas en el caso de Weyl. Un ejemplo de un fermión de Weyl es el neutrino en el Modelo Estándar, que tiene carga electrodébil. El neutrino siempre es $LH$ y el antineutrino siempre $RH$.\\ \\
Por tanto, para usar $LSZ$ con fermiones, debemos identificar,
\begin{equation*}
    \begin{array}{rlrl}
        \text{Partícula entrante }(LH): & u_{\alpha}(-,p); & \text{Partícula saliente }(RH): & \bar{u}_{\dot{\alpha}}(-,p)\\ \\
        \text{Antipartícula entrante }(RH): & \bar{v}_{\dot{\alpha}}(+,p); & \text{Antipartícula saliente }(LH): & v_{\alpha}(+,p)
    \end{array}
\end{equation*}
Para la teoría de perturbaciones necesitamos el propagador de Feynman, que vendrá dado por
\begin{equation}
    \begin{array}{rl}
        S_{\alpha\dot{\alpha}}(x-y) &=\Braket{0|T\Psi_{\alpha}(x)\Psi_{\dot{\alpha}}^{\dagger}(y)|0}= \\  \\
         & =\Theta(x^0-y^0)\Braket{0|\Psi_{\alpha}(x)\Psi_{\dot{\alpha}}^{\dagger}(y)|0}-\Theta(y^0-x^0)\Braket{0|\Psi_{\dot{\alpha}}^{\dagger}(y)\Psi_{\alpha}(x)|0}= \\ \\
         &=i\partial_{\alpha\dot{\alpha}}\Delta(x-y)=\curlybraces{\begin{matrix}
             \text{Pasamos a la }\\
             \text{representación}\\
             \text{de momentos}
         \end{matrix}}=\int\frac{d^4p}{(2\pi)^4}e^{-ip(x-y)}\frac{iP_{\alpha\dot{\alpha}}}{p^2+i\epsilon}
    \end{array}
\end{equation}
donde no hay un $-m^2$ porque estamos en el caso sin masa.\\ \\
Usando el Teorema de Wick, podemos ver que
\begin{equation}
    \contraction{}{\Psi_{\alpha}(x)}{}{\Psi_{\dot{\alpha}}^{\dagger}(y)}\Psi_{\alpha}(x)\Psi_{\dot{\alpha}}^{\dagger}(y)=T\Psi_{\alpha}(x)\Psi_{\dot{\alpha}}^{\dagger}(y)-:\Psi_{\alpha}(x)\Psi_{\dot{\alpha}}(y):=S_{\alpha\dot{\alpha}}(x-y)
\end{equation}
donde $S$ es la función de Green de la ecuación de Weyl, tal que
\begin{equation}
    \begin{array}{rl}
        i\partial^{\dot{\alpha}\alpha}S_{\alpha\dot{\beta}}(x) &=-\partial^{\dot{\alpha}\alpha}\partial_{\alpha\dot{\beta}}\Delta(x)=-(\bar{\sigma}^{\mu})^{\dot{\alpha}\alpha}\sigma^{\nu}_{\alpha\dot{\beta}}\partial_{\mu}\partial_{\nu}\Delta(x)=\\  \\
         & =-\frac{1}{2}\left(\bar{\sigma}^{\mu}\sigma^{\nu}+\bar{\sigma}^{\nu}\sigma^{\mu}\right)_{\dot{\alpha}\dot{\beta}}\partial_{\mu}\partial_{\nu}\Delta(x)=\mathscr{E}_{\dot{\alpha}\dot{\beta}}\square\Delta(x)=i\mathscr{E}_{\dot{\alpha}\dot{\beta}}\delta^{(4)}(x)
    \end{array}
\end{equation}
Los diagramas de Feynman y las reglas de Feynman se usan como antes. Consideramos el Lagrangiano siguiente,
    \begin{equation}
        \mathscr{L}=\Psi^{\dagger}i\bar{\sigma}^{\mu}\partial_{\mu}\Psi+\frac{1}{2}\partial_{\mu}\phi\partial^{\mu}\phi-\frac{\lambda}{2}\left(\Psi\Psi+\Psi^{\dagger}\Psi^{\dagger}\right)\phi
    \end{equation}
    donde los campos de Weyl $\Psi$ no pueden estar cargados, porque el último término no conserva carga. Como tenemos todos los índices contraídos, el Lagrangiano es un invariante de Lorentz. Para el campo $\phi$ tendremos un propagador bosónico, $\tilde{\Delta}(p)$, mientras que para el campo $\chi$ tendremos un propagador fermiónico, $\tilde{S}_{\alpha\dot{\beta}}(p)$, tal que
    \begin{multicols}{2}
    \begin{center}
        \begin{fmffile}{diag61}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1}
  \fmfright{r1}
  \fmf{dashes, label=$\xrightarrow{p}$}{r1,l1}
  \fmf{phantom}{v,l1}
  \fmflabel{$\tilde{\Delta}(p)\longrightarrow$}{v}
\end{fmfgraph*}
\end{fmffile}
\end{center}
    \begin{center}
        \begin{fmffile}{diag62}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1}
  \fmfright{r1}
  \fmf{fermion, label=$\xrightarrow{p}$}{r1,l1}
  \fmf{phantom}{v,l1}
  \fmflabel{$\dot{\beta}$}{l1}
  \fmflabel{$\alpha$}{r1}
  \fmflabel{$\tilde{S}_{\alpha\dot{\beta}}(p)\longrightarrow\hspace{4mm}$}{v}
\end{fmfgraph*}
\end{fmffile}
\end{center}
\end{multicols}
donde vemos que las flechas fermiónicas apuntan desde los índices sin punto hacia los índices con punto, es decir, del $LH$ al $RH$. \\ \\
Luego, tendremos dos diagramas de orden $\lambda$. tal que
\begin{multicols}{2}
   \begin{center}
        \begin{fmffile}{diag63}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1}
  \fmfright{r1,r2}
  \fmf{dashes}{l1,v1}
  \fmf{phantom}{v,l1}
  \fmf{fermion}{r1,v1}
  \fmf{fermion}{r2,v1}
  \fmflabel{$\beta$}{r1}
  \fmflabel{$\alpha$}{r2}
  \fmflabel{$-i\lambda\delta_{\beta}^{\alpha}\longrightarrow$}{v}
\end{fmfgraph*}
\end{fmffile}
\end{center} 
\begin{center}
        \begin{fmffile}{diag64}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1}
  \fmfright{r1,r2}
  \fmf{dashes}{l1,v1}
  \fmf{phantom}{v,l1}
  \fmf{fermion}{v1,r1}
  \fmf{fermion}{v1,r2}
  \fmflabel{$\dot{\beta}$}{r1}
  \fmflabel{$\dot{\alpha}$}{r2}
  \fmflabel{$-i\lambda\delta_{\dot{\beta}}^{\dot{\alpha}}\longrightarrow$}{v}
\end{fmfgraph*}
\end{fmffile}
\end{center} 
\end{multicols}
Vemos que cada campo fermiónico tendrá dimensión de $3/2$.\\ \\
Ahora veamos los diagramas a orden $\lambda^2$, que serán de la forma,
\[\hspace{1mm}\]
\[
    \begin{fmffile}{blobdiag65}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1,l2}
  \fmfright{r1,r2}

  % Línea real con label para momentum
  \fmf{fermion, label=2}{v,l1}
  \fmf{fermion, label=1}{l2,v}
  \fmf{fermion, label=4}{r1,v}
  \fmf{fermion, label=3}{v,r2}

  % Conexión fantasma para habilitar etiquetas de vértices
  \fmf{phantom}{l1,v1}
  \fmf{phantom}{l2,v2}
  \fmf{phantom}{v3,r1}
  \fmf{phantom}{v4,r2}

  % Blob en el centro
  \fmfblob{.16w}{v}

  % Etiquetas de vértices (números)
  \fmflabel{$\begin{matrix}
      \bar{v}_+(p_2)\\
      h=+
  \end{matrix}$}{l1}
  \fmflabel{$\begin{matrix}
      h=-\\
      u_-(p_1)
  \end{matrix}$}{l2}
  \fmflabel{$\begin{matrix}
      v_+(p_4)\\
      h=+
  \end{matrix}$}{r1}
  \fmflabel{$\begin{matrix}
      h=-\\
      \bar{u}_-(p_3)
  \end{matrix}$}{r2}
\end{fmfgraph*}
\end{fmffile}
\]
\[\hspace{1mm}\]
Como tenemos los espinores $u$ y $v$, estos deberán aparecer. Denominamos partícula a $h=-$ y antipartícula a $h=+$. Como los fermiones anticonmutan, al hacer el intercambio de dos partículas idénticas, deberemos poner un signo $(-)$ relativo al intercambio. Esto afecta también a los diagramas, tal que
\[\begin{fmffile}{blobdiag66}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1,l2}
  \fmfright{r1,r2}

  % Línea real con label para momentum
  \fmf{fermion, label=2}{l1,v1}
  \fmf{fermion, label=1}{l2,v2}
  \fmf{fermion, label=4}{v1,r1}
  \fmf{fermion, label=3}{v2,r2}
  \fmf{photon}{v1,v2}
  \fmflabel{$\begin{matrix}
      \uparrow\\
      (+)
  \end{matrix}$}{v1}
\end{fmfgraph*}
\end{fmffile}\hspace{20mm}\begin{fmffile}{blobdiag67}
\begin{fmfgraph*}(100,60)
  \fmfleft{l1,l2}
  \fmfright{r1,r2}

  % Línea real con label para momentum
  \fmf{fermion, label=2}{l1,v1}
  \fmf{fermion, label=1}{l2,v2}
  \fmf{fermion, label=3}{v1,r1}
  \fmf{fermion, label=4}{v2,r2}
  \fmf{photon}{v1,v2}
  \fmflabel{$\begin{matrix}
      \uparrow\\
      (-)
  \end{matrix}$}{v1}
\end{fmfgraph*}
\end{fmffile}\]
Además, si tenemos bucles, debemos añadir un signo $(-)$ adicional por cada bucle.\\ \\
Si consideramos el último término del Lagrangiano como,
\begin{equation}
    \frac{m}{2}\left(\Psi_{\alpha}\Psi^{\alpha}+\Psi_{\dot{\alpha}}\Psi^{\dot{\alpha}}\right)
\end{equation}
siendo el \textbf{término de masa de Majorana}, correspondiente a los \textbf{fermiones de Majorana}. Vemos que si estos campos tuvieran carga, este término no respetaría la conservación de la carga. Sin embargo, si tenemos dos campos fermiónicos con carga opuesta, $\Psi_{\alpha}$, $\xi_{\alpha}$, podemos escribir un término masivo de carga neutra, $\Psi_{\alpha}\xi^{\alpha}$. En el caso de Majorana neutral podremos escribir términos masivos sin necesidad de duplicar el número de campos. Veremos que esto coincide con el número de grados de libertad de las partículas creadas por estos campos.
\begin{remark}
    Si queremos fermiones masivos con carga, necesitaremos dos campos espinoriales distintos; a este conjunto de dos campos espinoriales se le denomina \textbf{fermiones de Dirac}.
\end{remark}
\section{Fermiones masivos}
\subsection{Fermiones de Majorana}
Este tipo de fermiones serán aquellos, cuyos campos espinoriales tienen los mismos operadores de creación y destrucción, tal que, considerando un campo espinorial $LH$, tenemos
\begin{equation}
    \chi_{\alpha}(x)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\sum_{s=\pm}\brackets{u_{\alpha}(s,p)a_s(p)e^{-ipx}+v_{\alpha}(s,p)a_s^{\dagger}e^{ipx}}
\end{equation}
denominado \textbf{campo de Majorana}. Este campo lo usamos para describir una partícula de masa $m$ y espín $1/2$. Al tener masa y espín, el \textit{little group} es $SU(2)$, que es el grupo de rotaciones de dimensión $2$ que representa las dos polarizaciones posibles del espín, $m_s=\pm1/2$.\\ \\
Empleamos el mismo razonamiento que hicimos para el caso sin masa, pero ahora $u_{\alpha}$ y $v_{\alpha}$ transformarán de forma diferente. Tenemos que
\begin{equation}
    \begin{array}{c}
         D^{(1/2)}\left(W(N,p)\right)^{\dagger}_{s\bar{s}}u_{\alpha}(\bar{s},p)=N_{\alpha}^{-1\beta}u_{\beta}(s,\Lambda p)\\ \\
         D^{(1/2)}\left(W(N,p)\right)_{s\bar{s}}v_{\alpha}(\bar{s},p)=N_{\alpha}^{-1\beta}v_{\beta}(s,\Lambda p)
    \end{array}
\end{equation}
Veamos primero la transformación de $u_{\alpha}(s,q)$ considerando $k=(m,0,0,0)$,
\begin{equation}
    u_{\alpha}(s,q)=K(k\to q)_{\alpha}^{\beta}u_{\beta}(s,k)
\end{equation}
tomamos un $N=W\in$\textit{little group} y sustituimos,
\begin{equation}
    D^{(1/2)}(W)^{\dagger}_{s\bar{s}}u_{\alpha}(\bar{s},k)=W_{\alpha}^{\beta}u_{\beta}(s,k)
\end{equation}
donde $W$ es la matriz de rotación en la representación $\left(\frac{1}{2}\right)$, luego, pensamos en rotaciones infinitesimales, cerca de la identidad, es decir, trabajamos con el álgebra. Veamos esta ecuación escrita con rotaciones infinitesimales,
\begin{equation}
    \vec{\sigma}_{s\bar{s}}u_{\alpha}(\bar{s},k)=\vec{\sigma}_{\alpha}^{\beta}u_{\beta}(s,k)
\end{equation}
donde $\vec{\sigma}$ son las matrices de Pauli, que coinciden con los genreadores del álgebra de $J=1/2$.\\ \\
Análogamente, obtenemos
\begin{equation}
    -\vec{\sigma}_{s\bar{s}}v_{\alpha}(\bar{s},k)=\vec{\sigma}_{\alpha}^{\beta}v_{\beta}(s,k)
\end{equation}
Comparando ambas ecuaciones, vemos que
\begin{equation}
    \left.\begin{array}{r}
         u_{\alpha}(s,k)=c\delta_{s\alpha} \\ \\
         v_{\alpha}(s,k)=d\mathscr{E}_{s\alpha}
    \end{array}\right\rbrace
\end{equation}
Tomaremos una dirección $\hat{r}$ arbitraria en el espacio. Definimos un vector $\hat{r}\chi_s$, tal que
\begin{equation}
    \frac{\vec{\sigma}\cdot\hat{r}}{2}\chi_s=\frac{s}{2}\chi_s
\end{equation}
Una forma de escoger $\hat{r}$ es en la dirección donde el trimomento $\vec{p}$ no se anule, es decir, $\hat{r}=\vec{p}/|\vec{p}|$. Por tanto,
\begin{equation}
    \begin{array}{cc}
        u_{\alpha}(s,k)=\sqrt{m}(\chi_s)_{\alpha} & v_{\alpha}(s,k)=s\sqrt{m}(\chi_{-s})_{\alpha} \\ \\
        \bar{u}_{\dot{\alpha}}(s,k)=\sqrt{m}\left(\chi_s^{\dagger}\right)_{\dot{\alpha}} & \bar{v}_{\dot{\alpha}}(s,k)=s\sqrt{m}\left(\chi_{-s}^{\dagger}\right)_{\dot{\alpha}}
    \end{array}
\end{equation}
Tomando $L(k\to p)$ como un boost puro desde el sistema en reposo hasta $\vec{p}$, con $\omega_{ij}=0$, $\xi^i=\theta^{i0}=-\theta^{0i}$, usando que $p^0=\omega_p=\sqrt{\vec{p}^2+m^2}$ tenemos
\begin{equation}
    \begin{array}{cc}
         &L(k\to p)=e^{-\frac{i}{2}\omega_{\mu\nu}J^{\mu\nu}}=e^{-\frac{1}{2}\vec{\xi}\cdot\vec{\sigma}}=\sqrt{\frac{p\sigma}{m}}  \\
         &[L(k\to p)^{-1}]^{\dagger}=e^{\frac{1}{2}\vec{\xi}\cdot\vec{\sigma}}=\sqrt{\frac{p\bar{\sigma}}{m}} 
    \end{array}
\end{equation}
donde
\begin{equation}
    \sqrt{p \sigma}=e^{-\frac{1}{2}\vec{\xi}\cdot\vec{\sigma}}\approx\frac{(\omega_p+m)\mathds{1}+\vec{\sigma}\cdot\vec{p}}{\sqrt{2(\omega_p+m)}}
\end{equation}
donde hemos desarrollado en serie la exponencial y $\vec{\xi}$ es un boost de Lorentz. Además, tiene las propiedades,
\begin{equation}
    \sqrt{p\sigma}\sqrt{p\sigma}=p_{\mu}\sigma^{\mu}\bar{\sigma}^0;\hspace{6mm}\sqrt{p\bar{\sigma}}\sqrt{p\bar{\sigma}}=p_{\mu}\bar{\sigma}^{\mu}\sigma^0
\end{equation}
Usando este boost y sabiendo que $u_{\alpha}(s,p)=L(k\to p)_{\alpha}^{\beta}u_{\beta}(s,k)$ y $v_{\alpha}(s,p)=L(k\to p)_{\alpha}^{\beta}v_{\beta}(s,k)$. Tenemos por tanto,
\begin{equation}
    \begin{array}{cc}
        u_{\alpha}(s,p)=\left(\sqrt{p \sigma}\chi_s\right)_{\alpha} & v_{\alpha}(s,p)=s\left(\sqrt{p \sigma}\chi_{-s}\right)_{\alpha}  \\ \\
        \bar{u}_{\dot{\alpha}}(s,p)=\left(\chi_{s}^{\dagger}\sqrt{p \sigma}\right)_{\dot{\alpha}} & \bar{v}_{\dot{\alpha}}(s,p)=s\left(\chi_{-s}^{\dagger}\sqrt{p \sigma}\right)_{\dot{\alpha}}\\ \\
        u^{\alpha}(s,p)=-s(\chi_{-s}^{\dagger}\sqrt{p\bar{\sigma}})^{\alpha}; & v^{\alpha}(s,p)=(\chi_s^{\dagger}\sqrt{p\bar{\sigma}})^{\alpha}\\ \\
        \bar{u}^{\dot{\alpha}}(s,p)=-s(\sqrt{p\bar{\sigma}}\chi_{-s})^{\dot{\alpha}}; & \bar{v}^{\dot{\alpha}}(s,p)=(\sqrt{p\bar{\sigma}}\chi_s)^{\dot{\alpha}}
    \end{array}
\end{equation}
Notar que,
\begin{equation}
    v(s,p)=su(-s,p)
\end{equation}
Por tanto, para el caso masivo, tenemos las siguientes relaciones de $u$ y $v$ con el momento espinorial $P$:
\begin{equation*}
    \begin{array}{rlrl}
        (i) & P^{\dot{\alpha}\alpha}u_{\alpha}(s,p)=m\bar{v}^{\dot{\alpha}}(s,p) & (ii) & P^{\dot{\alpha}\alpha}v_{\alpha}(s,p)=-m\bar{u}^{\dot{\alpha}}(s,p) \\ \\
        (iii) & P_{\alpha\dot{\alpha}}\bar{u}^{\dot{\alpha}}(s,p)=-mv_{\alpha}(s,p) & (iv) & P_{\alpha\dot{\alpha}}\bar{v}^{\dot{\alpha}}(s,p)=mu_{\alpha}(s,p) \\ \\
        (v) & u^{\alpha}(s,p)P_{\alpha\dot{\alpha}}=-m\bar{v}_{\dot{\alpha}}(s,p) & (vi) & v^{\alpha}(s,p)P_{\alpha\dot{\alpha}}=m\bar{u}_{\dot{\alpha}}(s,p)\\ \\
        (vii) & \bar{u}_{\dot{\alpha}}(s,p)P^{\dot{\alpha}\alpha}=mv^{\alpha}(s,p) & (viii) & \bar{v}^{\dot{\alpha}}(s,p)P^{\dot{\alpha}\alpha}=-mu^{\alpha}(s,p)
    \end{array}
\end{equation*}
donde vimos que todas estas relaciones son nulas para el caso sin masa.\\ \\
Por tanto, agrupando las relaciones, las podemos unificar, tal que
\begin{equation*}
    \begin{array}{rlrl}
        (i) & \sum\limits_{s=\pm}u_{\alpha}(s,p)\bar{u}_{\dot{\alpha}}(s,p)=P_{\alpha\dot{\alpha}} & (ii) & \sum\limits_{s=\pm}u_{\alpha}(s,p)v^{\beta}(s,p)=m\delta_{\alpha}^{\beta} \\ \\
        (iii) & \sum\limits_{s=\pm}\bar{v}^{\dot{\alpha}}(s,p)v^{\alpha}(s,p)=P^{\dot{\alpha}\alpha} & (iv) & \sum\limits_{s=\pm}\bar{v}^{\dot{\alpha}}(s,p)\bar{u}_{\dot{\beta}}(s,p)=m\delta_{\dot{\beta}}^{\dot{\alpha}}\\ \\
        (v) & \sum\limits_{s=\pm}\bar{u}^{\dot{\alpha}}(s,p)u^{\alpha}(s,p)=P^{\dot{\alpha}\alpha}; & (vi) & \sum\limits_{s=\pm}v_{\alpha}(s,p)u^{\beta}(s,p)=-m\delta_{\alpha}^{\beta} \\ \\
        (vii) & \sum\limits_{s=\pm}v_{\alpha}(s,p)\bar{v}_{\dot{\alpha}}(s,p)=P_{\alpha\dot{\alpha}} & (viii) & \sum\limits_{s=\pm}\bar{u}^{\dot{\alpha}}(s,p)\bar{v}_{\dot{\beta}}(s,p)=-m\delta_{\dot{\beta}}^{\dot{\alpha}}
    \end{array}
\end{equation*}
Usando estas relaciones podemos calcular la derivada del campo de Majorana obteniendo la ecuación,
\begin{equation}
    i\partial^{\dot{\alpha}\alpha}\chi_{\alpha}=m\chi^{\dagger\dot{\alpha}}
\end{equation}
siendo un caso particular de la ecuación de Dirac.\\ \\
Esta ecuación se puede derivar del siguiente Lagrangiano,
\begin{equation}
    \mathscr{L}=\chi^{\dagger}i\partial\chi-\frac{1}{2}m\left(\chi\chi+\chi^{\dagger}\chi^{\dagger}\right)
\end{equation}
siendo un Lagrangiano hermítico, donde el producto de los campos no se anula al tener anticonmutadores, y los campos no podrán tener carga porque no la conserva.\\ \\
Para añadir la carga necesitamos dos campos distintos, imponiendo que uno tendrá la carga opuesta del otro campo.
\subsection{Campo de Dirac}
El campo de Dirac nos servirá para explicar las partículas masivas, de espín $+1/2$ y con carga.\\ \\
El campo de Dirac es una combinación de dos campos de Majorana, $\xi_1$ y $\xi_2$, de igual masa, $m_1=m_2\equiv m$, pero con operadores de creación y destrucción distintos, tal que
\begin{equation*}
    \xi_1\leadsto a_1,a_1^{\dagger}\hspace{8mm}\xi_2\leadsto a_2,a_2^{\dagger}
\end{equation*}
Consideraremos que la carga no actúa multiplicativamente, sino que provoca una rotación en $SU(2)$; pero esto no es la forma usual de hacerlo. La forma usual es tomar otra base, haciendo una rotación, donde el término de masa del Lagrangiano no es diagonal y la carga sí actúa multiplicativamente en esta base, pues en esta base, $\chi$ y $\eta$ tienen cargas opuestas.\\ \\
Tomamos
\begin{equation}
    \chi=\frac{1}{\sqrt{2}}\left(\xi_1+i\xi_2\right);\hspace{8mm}\eta=\frac{1}{\sqrt{2}}\left(\xi_1-i\xi_2\right)
\end{equation}
denominados \textbf{campos de Weyl masivos}. Su forma explícita es,
\begin{equation}
    \chi_{\alpha}=\sum_{s=\pm}\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\brackets{e^{-ipx}u_{\alpha}(s,p)b_s(p)+e^{ipx}v_{\alpha}(s,p)c_s^{\dagger}(p)}
\end{equation}
siendo un campo $LH$, y
\begin{equation}
    \eta_{\alpha}=\sum_{s=\pm}\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\brackets{e^{-ipx}u_{\alpha}(s,p)c_s(p)+e^{ipx}v_{\alpha}(s,p)b_s^{\dagger}(p)}
\end{equation}
siendo un campo $RH$ y donde
\begin{equation}
    b=\frac{1}{\sqrt{2}}\left(a_+ia_2\right);\hspace{8mm}c=\frac{1}{\sqrt{2}}\left(a_1-ia_2\right)
\end{equation}
estos operadores crean partículas y antipartículas de igual masa y carga opuesta con ambas polarizaciones.\\ \\
Para estos campos $u_{\alpha}$ y $v_{\alpha}$ son los mismos que calculamos antes debido a la invariancia de Lorentz. $\chi$ y $\chi^{\dagger}$ por sí solos pueden crear los cuatro grados de libertad, pero como el conjugado de $\chi$, $\bar{\chi}$, está en la representación $RH$ y el conjugado de $\eta$, $\bar{\eta}$, está en la representación $LH$, una forma adecuada de agrupar los grados de libertad para construir Lagrangianos invariantes será tomar ambos campos.\\ \\
Normalmente, el \textbf{campo de Dirac} es el par $\left(\chi_{\alpha},\eta_{\alpha}\right)$, siendo simplemente una rotación de $\left(\xi_1,\xi_2\right)$. Los operadores $b^{\dagger}$ y $c^{\dagger}$ crean partículas y antipartículas con ambas polarizaciones. Estas tienen la misma masa y carga opuesta.
\\ \\
Vemos que la derivada de estos campos es,
\begin{equation}
    i\partial^{\dot{\alpha}\alpha}\chi_{\alpha}=m\eta^{\dagger\dot{\alpha}};\hspace{8mm}i\partial^{\dot{\alpha}\alpha}\eta_{\alpha}=m\chi^{\dagger\dot{\alpha}}
\end{equation}
Estas dos ecuaciones equivalen a la \textbf{ecuación de Dirac}. Tenemos dos ecuaciones acopladas de primer orden, que podemos desacoplar usando la base $\left(\xi_1,\xi_2\right)$, pero para el caso de interacciones nos quedaremos con las ecuaciones acopladas. Estas ecuaciones pueden derivarse del siguiente Lagrangiano,
\begin{equation}
    \mathscr{L}=i\chi^{\dagger}\partial\chi+i\eta^{\dagger}\partial\eta-m\left(\chi\eta+\chi^{\dagger}\eta^{\dagger}\right)
\end{equation}
denominado \textbf{Lagrangiano libre de Dirac}. Vemos que una simetría del Lagrangiano es $U(1)$, usando las rotaciones $\chi\to e^{i\theta}\chi$ y $\eta\to e^{-i\theta}\eta$, cuya carga conservada asociada es la carga de las partículas. Si cambiamos a la base de $\xi_1$ y $\xi_2$ la simetría será de la forma de $SO(2)$.\\ \\
Vamos a calcular los anticonmutadores,
\begin{equation}
    \begin{array}{rl}
       \curlybraces{\chi_{\alpha}(x),\chi_{\dot{\alpha}}^{\dagger}(x)}  & =\int\frac{d^3p}{(2\pi)^3}\frac{1}{2\omega_p}\brackets{e^{-i(x-y)p}\sum\limits_{s=\pm}u_{\alpha}(s,p)\bar{u}_{\dot{\alpha}}(s,p)+e^{i(x-y)p}\sum\limits_{s=\pm}v_{\alpha}(s,p)\bar{v}_{\dot{\alpha}}(s,p)}= \\ \\
         & =i\partial_{\alpha\dot{\alpha}}D(x-y)+i\partial_{\alpha\dot{\alpha}}D(y-x)
    \end{array}
\end{equation}
Repitiendo el cálculo obtenemos los anticonmutadores,
\begin{equation}
    \curlybraces{\eta_{\alpha}(x),\eta_{\dot{\alpha}}^{\dagger}(y)}=i\partial_{\alpha\dot{\alpha}}D(x-y)+i\partial_{\alpha\dot{\alpha}}D(y-x)
\end{equation}
\begin{equation}
\begin{array}{rl}
     
    \curlybraces{\chi_{\alpha}(x),\eta_{\beta}(x)}&=\int\frac{d^3p}{(2\pi)^2}\frac{1}{2\omega_p}\brackets{e^{-i(x-y)p}\sum\limits_{s=\pm}u_{\alpha}(s,p)v_{\beta}(s,p)+e^{i(x-y)p}\sum\limits_{s=\pm}v_{\alpha}(s,p)u_{\beta}(s,p)}= \\  \\
     & =\int\frac{d^3p}{(2\pi)^3}\frac{m}{2\omega_p}\brackets{e^{-i(x-y)p}-e^{i(x-y)p}}=m\left(D(x-y)-D(y-x)\right)
\end{array}
\end{equation}
Vemos que la causalidad se preserva y las relaciones canónicas dan,
\begin{equation}
    \curlybraces{\chi_{\alpha}(o,\vec{x}),\chi_{\dot{\alpha}}^{\dagger}(0,\vec{y})}=\curlybraces{\eta_{\alpha}(0,\vec{x}),\eta_{\dot{\alpha}}^{\dagger}(0,\vec{y})}=\sigma_{\alpha\dot{\alpha}}^0\delta^{(2)}(\vec{x}-\vec{y})
\end{equation}
Los propagadores de Feynman son,
\begin{equation*}
    \begin{array}{c}
         \Braket{0|T\chi_{\alpha}(x)\chi_{\dot{\alpha}}^{\dagger}(y)|0}=i\partial_{\alpha\dot{\alpha}}\Delta(x-y) \\ \\
          \Braket{0|T\eta_{\alpha}(x)\eta_{\dot{\alpha}}^{\dagger}(y)|0}=i\partial_{\alpha\dot{\alpha}}\Delta(x-y)\\ \\
          \Braket{0|T\chi_{\alpha}(x)\eta^{\beta}(y)|0}=m\delta_{\alpha}^{\beta}\Delta(x-y)\\ \\
          \Braket{0|T\chi^{\dagger\dot{\alpha}}(x)\eta_{\dot{\beta}}^{\dagger}(y)|0}=m\delta_{\dot{\beta}}^{\dot{\alpha}}\Delta(x-y)
    \end{array}
\end{equation*}
Luego, las reglas de Feynman serán,
\begin{itemize}
    \item \textbf{Propagador de un fermión}:
    \[\begin{fmffile}{cabcajk}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l}
            \fmfright{r}
            \fmf{fermion,label=$\xrightarrow{p}$}{l,r}
            \fmflabel{$\dot{\beta}$}{l}
            \fmflabel{$\dot{\alpha}\hspace{5mm}\to\frac{iP_{\alpha\dot{\alpha}}}{p^2-m^2+i\epsilon}$}{r}
        \end{fmfgraph*}
    \end{fmffile}\]
    \item \textbf{Colisión frontal de dos fermiones}:
    \[\begin{fmffile}{3781}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l}
            \fmfright{r}
            \fmf{fermion}{l,v}
            \fmf{fermion}{r,v}
            \fmflabel{$\dot{\beta}$}{l}
            \fmflabel{$\dot{\alpha}\hspace{5mm}\to\frac{im}{p^2-m^2+i\epsilon}\delta_{\dot{\beta}}^{\dot{\alpha}}$}{r}
        \end{fmfgraph*}
    \end{fmffile}\]
    \item \textbf{Repulsión de dos fermiones}:
    \[\begin{fmffile}{canfgghc333a}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l}
            \fmfright{r}
            \fmf{fermion}{v,l}
            \fmf{fermion}{v,r}
            \fmflabel{$\beta$}{l}
            \fmflabel{$\alpha\hspace{5mm}\to\frac{im}{p^2-m^2+i\epsilon}\delta_{\alpha}^{\beta}$}{r}
        \end{fmfgraph*}
    \end{fmffile}\]
    \item \textbf{Para estados externos}:
    \[\hspace{1mm}\]
    \[\begin{fmffile}{adjdo}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l2,l1}
            \fmfright{r2,r1}
            \fmf{fermion,label=$u$}{l1,v}
            \fmf{fermion,label=$\bar{v}$}{v,l2}
            \fmfblob{.16w}{v}
            \fmf{fermion,label=$\bar{u}$}{v,r1}
            \fmf{fermion,label=$v$}{r2,v}
        \end{fmfgraph*}
    \end{fmffile}\]
    Aquí las flechas no son flujos de cargas, sino que son flujos de espinores. Los índices sin punto van hacia los vértices, mientras que los índices con punto, salen de los vértices.
    \item \textbf{Interacción de Yukawa}: Esta interacción viene dada por el Lagrangiano,
    \begin{equation}
        \mathscr{L}_{int}=-\lambda\phi(\eta\chi+\chi^{\dagger}\eta^{\dagger})
    \end{equation}
    obteniendo,
    \[\begin{fmffile}{addsha}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l}
            \fmfright{r2,r1}
            \fmf{scalar}{l,v}
            \fmf{fermion}{v,r1}
            \fmf{fermion}{r2,v}
            \fmflabel{$\alpha$}{r1}
            \fmflabel{$\hspace{12mm}\to -i\lambda\delta_{\alpha}^{\beta}$}{v}
            \fmflabel{$\beta$}{r2}
        \end{fmfgraph*}
    \end{fmffile}\]
    \[\hspace{1mm}\]
    \[\begin{fmffile}{adddadasha}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l}
            \fmfright{r2,r1}
            \fmf{scalar}{v,l}
            \fmf{fermion}{r1,v}
            \fmf{fermion}{v,r2}
            \fmflabel{$\dot{\alpha}$}{r1}
            \fmflabel{$\hspace{12mm}\to -i\lambda\delta_{\dot{\alpha}}^{\dot{\beta}}$}{v}
            \fmflabel{$\dot{\beta}$}{r2}
        \end{fmfgraph*}
    \end{fmffile}\]
\end{itemize}
\section{Formalismo de Dirac}
Los campos de Weyl $\chi_{\alpha}$, que transforma en la representación $\left(\frac{1}{2},0\right)$, y $\eta^{\dagger\dot{\alpha}}$, que transforma en la representación $\left(0,\frac{1}{2}\right)$, son espinores de dos dimensiones, es decir, son \textbf{biespinores}. Dirac implementó el cuadriespinor siguiente,
\begin{equation}
    \Psi(x)=\begin{pmatrix}
        \chi_{\alpha}(x)\\
        \eta^{\dagger\dot{\alpha}}(x)
    \end{pmatrix}
\end{equation}
que transforma en la representación reducible $\left(\frac{1}{2},0\right)\oplus\left(0,\frac{1}{2}\right)$. Definimos las \textbf{matrices de Dirac} en la representación de Weyl, tal que
\begin{equation}
    \gamma^{\mu}:=\begin{pmatrix}
        0 & \sigma_{\alpha\dot{\beta}}^{\mu}\\
        \bar{\sigma}^{\mu\dot{\alpha}\beta} & 0
    \end{pmatrix}
\end{equation}
en la representación de Dirac $\gamma^0$ es diagonal. Vemos que 
\begin{equation}
    \curlybraces{\gamma^{\mu},\gamma^{\nu}}=2\eta^{\mu\nu}\mathds{1}_{4};\hspace{6mm}\mathds{1}_4=\begin{pmatrix}
        \delta_{\alpha}^{\beta} & 0\\
        0 & \delta_{\dot{\beta}}^{\dot{\alpha}}
    \end{pmatrix}
\end{equation}
siendo las matrices que forman el \textbf{álgebra de Dirac}, que es un caso particular del álgebra de Clifford.\\ \\
Estas matrices nos permiten escribir los generadores del grupo de Lorentz, $\Sigma^{\mu\nu}$, (equivalente a los $J^{\mu\nu}$ de los capítulos anteriores) en esta representación, tal que
\begin{equation}
    \frac{1}{2}\Sigma^{\mu\nu}:=\frac{i}{4}\brackets{\gamma^{\mu},\gamma^{\nu}}=\begin{pmatrix}
        (\sigma^{\mu\nu})_{\alpha}^{\beta} & 0 \\
        0 & (\bar{\sigma}^{\mu\nu})_{\dot{\beta}}^{\dot{\alpha}}
    \end{pmatrix}
\end{equation}
Podemos hacer transformaciones finitas del grupo exponenciando estos generadores, tal que
\begin{equation}
    M=\begin{pmatrix}
        N & 0\\
        0 & (N^{-1})^{\dagger}
    \end{pmatrix}=e^{-\frac{i}{4}\omega_{\mu\nu}\Sigma^{\mu\nu}}
\end{equation}
donde los $\omega_{\mu\nu}$ serán parámetros antisimétricos que nos indicarán si tratamos con rotaciones o con boosts.\\ \\
Como nos interesará trabajar con proyectores de $\Psi(x)$ que nos lleven a $\chi_{\alpha}(x)$ ó a $\eta_{\alpha}(x)$, introducimos la matriz siguiente, que será útil para separar las dos representaciones irreducibles,
\begin{equation}
    \gamma_5=i\gamma^0\gamma^1\gamma^2\gamma^3=\begin{pmatrix}
        -\delta_{\alpha}^{\beta} & 0\\
        0 & \delta_{\dot{\beta}}^{\dot{\alpha}}
    \end{pmatrix}
\end{equation}
y cumple que $\gamma_5^2=\mathds{1}$ y cuya propiedad más importante es
\begin{equation}
    \curlybraces{\gamma_5,\gamma^{\mu}}=0
\end{equation}
Definimos los cuadriespinores quirales $LH$ y $RH$ como:\\ \\
-Denominamos el campo $left$, $\Psi_L$, al proyector \textit{left},
\begin{equation}
    \Psi_L:=\frac{1}{2}(\mathds{1}-\gamma_5)\Psi=\begin{pmatrix}
        \chi_{\alpha}\\
        0
    \end{pmatrix}
\end{equation}
-Denominamos al campo $right$, $\Psi_R$, al proyector \textit{right},
\begin{equation}
    \Psi_R:=\frac{1}{2}(\mathds{1}+\gamma_5)\Psi=\begin{pmatrix}
        0\\
        \eta^{\dagger\dot{\alpha}}
    \end{pmatrix}
\end{equation}
Estos proyectores son ortogonales entre sí, siendo autovectores de $\gamma_5$ con autovalor $\pm1$, tal que
\begin{equation}
    \gamma_5\Psi_L=-\Psi_L;\hspace{6mm}\gamma_5\Psi_R=+\Psi_R
\end{equation}
Ahora vamos a construir los invariantes, para ello, usamos la matriz siguiente,
\begin{equation}
    A=\begin{pmatrix}
        0 & \delta_{\dot{\beta}}^{\dot{\alpha}}\\
        \delta_{\alpha}^{\beta} & 0
    \end{pmatrix}
\end{equation}
cuyas propiedades son,
\begin{equation*}
    \begin{matrix}
        (i) & A\gamma_{\mu}A^{-1}=\gamma_{\mu}^{\dagger} & (ii) & A^{\dagger}=A
    \end{matrix}
\end{equation*}
Debemos notar que $\Psi^{\dagger}\Psi$ no es invariante. Por lo que para construir invariantes debemos definir el \textbf{Conjugado de Dirac}, $\bar{\Psi}:=\Psi^{\dagger}A=\begin{pmatrix}
    \eta^{\alpha},& \chi_{\dot{\alpha}}^{\dagger}
\end{pmatrix}$.\\ \\
Vemos que $\bar{\Psi}\Psi$ es un escalar, pues tenemos todos los índices contraídos, obteniendo un invariante.\footnote{Como una matriz, $A=\gamma^0$ y, de hecho, se suele escribir $\bar{\Psi}=\Psi^{\dagger}\gamma^0$. Pero, esto no es correcto del todo, pues $\gamma^0=\begin{pmatrix}
    0 & \sigma_{\alpha\dot{\alpha}}^0\\
    \sigma_{\dot{\alpha}\alpha}^{\mu} & 0
\end{pmatrix}$, entonces las propiedades de transformación no son las requeridas. $J$ usará $A$.}
Ahora, vamos a introducir los índices de Dirac, que nombramos con letras latinas y van del 1 al 4, es decir, $a,b,c,\dots\in\curlybraces{1,2,3,4}$. Estos índices se colocan en los cuadriespinores, $\Psi_a$, tal que
\begin{equation*}
    \begin{matrix}
        \Psi_1=\chi_1; & \Psi_2=\chi_2 & \Psi_3=\eta^{\dagger\dot{1}}; & \Psi_4=\eta^{\dagger\dot{2}}
    \end{matrix}
\end{equation*}
mientras que para el conjugado de Dirac usamos superíndices, $\bar{\Psi}^a$, tenemos
\begin{equation*}
    \begin{matrix}
        \bar{\Psi}^1=\eta^{1}; & \bar{\Psi}^2=\eta^2; & \bar{\Psi}^3=\chi_{\dot{1}}^{\dagger}; & \bar{\Psi}^4=\chi_{\dot{2}}^{\dagger}
    \end{matrix}
\end{equation*}
Luego, las transformaciones del grupo de Lorentz en la representación de Dirac son matrices $4\times4$, donde podemos usar los índices de Dirac, tal que
\begin{equation*}
    \begin{matrix}
        \Psi_a\to M_a^b\Psi_b\\
        \bar{\Psi}^a\to\bar{\Psi}^b(M^{-1})_b^a
    \end{matrix}
\end{equation*}
Usando estas transformaciones, tenemos otra forma de ver que $\bar{\Psi}\Psi=\bar{\Psi}^a\Psi_a$ es invariante, pues los índices de Dirac también se contraen.\\ \\
Para subir y bajar índices de Dirac usamos la matriz $C$,
\begin{equation}
    C=\begin{pmatrix}
        \mathscr{E}_{\alpha\beta} & 0\\
        0 & \mathscr{E}^{\dot{\alpha}\dot{\beta}}
    \end{pmatrix}
\end{equation}
denominada \textbf{matriz de conjugación de carga}, tal que
\begin{equation*}
    \begin{matrix}
        \Psi_a=C_{ab}\Psi^b; & \bar{\Psi}^a=(C^{-1})^{ab}\bar{\Psi}_b;\\
        \Psi^a=(C^{-1})^{ab}\Psi_b; & \bar{\Psi}_a=C_{ab}\bar{\Psi}^b
    \end{matrix}
\end{equation*}
Las propiedades de la matriz de conjugación de carga son,
\begin{equation*}
    \begin{matrix}
        (i) & C^t=-C & (ii) & C^{-1}\gamma_{\mu}C=-\gamma_{\mu}^t
    \end{matrix}
\end{equation*}
donde la $t$ representa la matriz traspuesta.\\ \\
La matriz $C$ se denomina conjugación de carga, pues la conjugación de carga nos cambia las partículas por las antipartículas, y esto para los campos se traduce en hacer el cambio $\chi\leftrightarrow\eta$, que equivale a la transformación
\begin{equation}
    \Psi\to\Psi^C\equiv C\bar{\Psi}^t=CA^t\Psi^*\equiv \Psi_a^C=C_{ab}\bar{\Psi}^b
\end{equation}
donde $\Psi^C$ se denomina \textbf{campo conjugado de carga}.\\ \\
Este formalismo se puede aplicar a los campos de Majorana, obteniendo que $\Psi=\Psi^C$. En general, $\Psi$ y $\Psi^C$ serán distintos.\\ \\
Por otro lado, podremos construir tensores Lorentz, como
\begin{equation*}
    \begin{matrix}
    \bar{\Psi}\Psi=\bar{\Psi}^a\Psi_a=\eta\chi+\chi^{\dagger}\eta^{\dagger} & \to & \text{escalar Lorentz (pseudoescalar)}\\ \\
    \bar{\Psi}\gamma^{\mu}\Psi=\chi^{\dagger}\bar{\sigma}^{\mu}\chi+\eta\sigma^{\mu}\eta^{\dagger} & \to & \text{vector (pseudovector bilineal covariante)} \\ \\

    \bar{\Psi}\Sigma^{\mu\nu}\Psi=2\left(\eta\sigma^{\mu\nu}\chi+\chi^{\dagger}\bar{\sigma}^{\mu\nu}\eta^{\dagger}\right) & \to & \text{tensor antisimétrico}\\ \\

    \bar{\Psi}\gamma_5\Psi=-\eta\chi+\chi^{\dagger}\eta^{\dagger} & \to & \text{escalar Lorentz}\\ \\

    \bar{\Psi}\gamma^{\mu}\gamma_5\Psi=-\chi^{\dagger}\bar{\sigma}^{\mu}\chi+\eta\sigma^{\mu}\eta^{\dagger} & \to & \text{vector}\\ \\

    \bar{\Psi}\Sigma^{\mu\nu}\gamma_5\Psi=2\left(-\eta\sigma^{\mu\nu}\chi+\chi^{\dagger}\bar{\sigma}^{\mu\nu}\eta\right) & \to & \text{tensor antisimétrico}
    \end{matrix}
\end{equation*}
Podemos formar la siguiente base compleja de matrices $4\times4$ complejas,
\begin{equation}
    B_{esp}=\curlybraces{\mathds{1},\gamma_5,\gamma^{\mu},\gamma^{\mu}\gamma_5,\Sigma^{\mu\nu}}
\end{equation}
que nos permite escribir cualquier representación del grupo de Lorentz (escalares, vectores, tensores, ...) como combinación lineal de los elementos de esta base. Esta base es ortogonal siempre que tomemos un producto escalar de la forma,
\begin{equation}
    g(A,B)=\frac{1}{4}tr(AB)
\end{equation}
Tenemos las siguientes propiedades,
\begin{equation}
    \begin{array}{rl}
        (i) & tr(\mathds{1})=4 \\
        (ii) & tr(\gamma^{\mu}\gamma^{\nu})=4\eta^{\mu\nu}\\
        (iii) & tr(\gamma^{\mu}\gamma^{\nu}\gamma^{\rho}\gamma^{\sigma})=4\left(\eta^{\mu\nu}\eta^{\rho\sigma}-\eta^{\mu\rho}\eta^{\nu\sigma}+\eta^{\mu\sigma}\eta^{\nu\rho}\right)\\
        (iv) & tr(\gamma^{\mu}\gamma^{\nu}\gamma^{\rho}\gamma^{\sigma}\gamma_5)=-4i\epsilon^{\mu\nu\rho\sigma}\\
        (v) & tr(\gamma^{\mu})=tr(\gamma^{\mu}\gamma^{\nu}\gamma^{\rho})=tr(\gamma \text{-impar})=0\\
        (vi) & tr(\gamma_5)=tr(\underbrace{\gamma^{\mu}\dots\gamma^{\nu}}_{\text{num impar}}\gamma_5)=0\\
        (vii) & \gamma_{\mu}\gamma^{\mu}=4\\
        (viii) & \gamma^{\mu}\gamma^{\nu}\gamma_{\mu}=-2\gamma^{\nu}\\
        (ix) & \gamma^{\mu}\gamma^{\nu}\gamma^{\rho}\gamma_{\mu}=4\eta^{\nu\rho}
    \end{array}
\end{equation}
Volviendo al campo espinorial de Dirac, $\Psi=\begin{pmatrix}
    \chi\\
    \eta^{\dagger}
\end{pmatrix}$, tenemos que el Lagrangiano de Dirac lo podemos reescribir en forma de 4 componentes,
\begin{equation}
    \mathscr{L}=i\bar{\Psi}\slashed{\partial}\Psi-m\bar{\Psi}\Psi
\end{equation}
donde $\slashed{A}=A_{\mu}\gamma^{\mu}$, es decir, tenemos una contracción lorentziana con $\gamma^{\mu}$, luego $\slashed{\partial}=\partial_{\mu}\gamma^{\mu}$, obteniendo una forma más compacta de escribir el Lagrangiano de Dirac.\\ \\
La ecuación del movimiento para un fermión con masa usando este Lagrangiano es,
\begin{equation}
    (i\slashed{\partial}-m)\Psi=0
\end{equation}
obteniendo la forma compacta de la \textbf{ecuación de Dirac}, que la hemos derivado de la covariancia Lorentz de los campos y partículas de espín $1/2$.\\ \\
En lugar de nuestras matrices de Dirac explícitas, usaremos el conjunto cumpliendo que, $\curlybraces{\gamma^{\mu},\gamma^{\nu}}=2g^{\mu\nu}\mathds{1}_4$.\\ \\
Diferentes $\gamma^{\mu}$ se relacionan con relaciones similares y corresponden a diferentes bases del álgebra de Dirac. Por ejemplo, la representación,
\[\gamma^0=\begin{pmatrix}
    1 & 0\\
    0 & -1
\end{pmatrix}\hspace{7mm}\gamma^i=\begin{pmatrix}
    0 & \sigma^i\\
    -\sigma^i & 0
\end{pmatrix}\longrightarrow\gamma^5=\begin{pmatrix}
    0 & 1\\
    1 & 0
\end{pmatrix}\]
es útil en aproximaciones no relativistas. Nuestra elección, llamada representación de Weyl, es mejor, porque la estructura $\left(\frac{1}{2},0\right)\oplus\left(0,\frac{1}{2}\right)$ es aparente.\\ \\
Los campos de Majorana se recuperan identificando $b=c$ (los operadores de creación y destrucción son los mismos), esto es, la restricción $\chi=\eta$, o equivalentemente, $\Psi=\Psi^C$.\\ \\
Los propagadores de Feynman pueden combinarse en un único objeto,
\begin{equation}
    S_a^b(x-y)=\Braket{0|T\Psi_a(x)\bar{\Psi}^b(y)|0}
\end{equation}
tenemos,
\begin{equation}
    \begin{array}{cccc}
       S_{\alpha\dot{\beta}}(x-y)=\Braket{0|T\chi_{\alpha}(x)\chi_{\dot{\beta}}^{\dagger}(y)|0};  & S_{\dot{\alpha}\beta}(x-y)=\Braket{0|T\eta_{\dot{\alpha}}^{\dagger}(x)\eta_{\beta}(y)|0}\\ \\
        S_{\alpha}^{\beta}(x-y)=\Braket{0|T\chi_{\alpha}(x)\eta^{\beta}(y)|0}; & S_{\dot{\beta}}^{\dot{\alpha}}(x-y)=\Braket{0|T\eta^{\dagger\dot{\alpha}}(x)\chi^{\dagger}_{\dot{\beta}}(y)|0}
    \end{array}
\end{equation}
Usando las expresiones anteriores llegamos a,
\begin{equation}
    S(x-y)=(i\slashed{\partial}+m)\Delta(x-y)=\int\frac{d^4p}{(2\pi)^4}e^{-ip(x-y)}\frac{i(\slashed{p}+m)}{p^2-m^2+i\epsilon}
\end{equation}
Podemos escribir los campos de Dirac en términos de los operadores de creación y destrucción,
\begin{equation}
    \Psi_a(x)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\sum_{s=\pm}\brackets{e^{-ipx}\begin{pmatrix}
        u_{\alpha}(s,p)\\
        \bar{v}^{\dot{\alpha}}(s,p)
    \end{pmatrix}b_s(p)+e^{ipx}\begin{pmatrix}
        v_{\alpha}(s,p)\\
        \bar{u}^{\dot{\alpha}}(s,p)
    \end{pmatrix}c_s^{\dagger}(p)}
\end{equation}
Pero emplearemos el campo $\bar{\Psi}^a$, que es más covariante, y viene dado por
\begin{equation}
    \bar{\Psi}^a(x)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\sum_{s=\pm}\brackets{e^{-ipx}\begin{pmatrix}
        u^{\alpha}(s,p) & \bar{v}_{\dot{\alpha}}(s,p)
    \end{pmatrix}c_s(p)+e^{ipx}\begin{pmatrix}
        v^{\alpha}(s,p) & \bar{u}_{\dot{\alpha}}(s,p)
    \end{pmatrix}b_s^{\dagger}(p)}
\end{equation}
donde ambas expresiones usan $b^{(\dagger)}$ y $c^{(\dagger)}$ como operadores de creación y destrucción, porque los campos $\chi$ y $\eta$ tienen estos mismos operadores de creación y destrucción. Podemos compactar la notación usando los cuadriespinores siguientes,\footnote{En los libros, estos cuadriespinores se representan con las letras $u$ y $v$, pero como ya las hemos usado en el texto, empleamos $x$ e $y$.}
\begin{equation}
\begin{matrix}
    x_a(s,p)=\begin{pmatrix}
        u_{\alpha}(s,p)\\
        \bar{v}^{\dot{\alpha}}(s,p)
    \end{pmatrix}; & y_a(s,p)=\begin{pmatrix}
        v_{\alpha}(s,p)\\
        \bar{u}^{\dot{\alpha}}(s,p)
    \end{pmatrix}\\ \\
    \bar{y}^a(s,p)=\begin{pmatrix}
        u^{\alpha}(s,p) & \bar{v}_{\dot{\alpha}}(s,p)\end{pmatrix}; & \bar{x}^a(s,p)=\begin{pmatrix}
            v^{\alpha}(s,p) & \bar{u}_{\dot{\alpha}}(s,p)
    \end{pmatrix}
\end{matrix}
\end{equation}
donde hemos tomado de forma adecuada los biespinores $u$ y $v$ para que las soluciones de la ecuación de Dirac sea covariante Lorentz.\\ \\
Así tenemos,
\begin{equation}
    \Psi_a(x)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\sum_{s=\pm}\brackets{e^{-ipx}x_a(s,p)b_s(p)+e^{ipx}y_a(s,p)c_s^{\dagger}(p)}
\end{equation}
\begin{equation}
    \bar{\Psi}^a(x)=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\sum_{s=\pm}\brackets{e^{-ipx}\bar{y}^a(s,p)c_s(p)+e^{ipx}\bar{x}^a(s,p)b_s^{\dagger}(p)}
\end{equation}
Estos cuadriespinores cumplirán las siguientes ecuaciones,
\begin{equation*}
    \begin{matrix}
        (i) & (\slashed{p}-m\mathds{1}_4)x(s,p)=0; & (ii) & (\slashed{p}+m\mathds{1}_4)y(s,p)=0\\
        (iii) & \bar{x}(s,p)(\slashed{p}-m\mathds{1}_4)=0; & (iv) & \bar{y}(s,p)(\slashed{p}+m\mathds{1}_4)=0
    \end{matrix}
\end{equation*}
donde $\mathds{1}_4$ es la identidad cuadridimensional y podemos omitirla, pues se sobreentiende que la masa no puede actuar como un escalar en las expresiones. Además, para los cálculos necesitaremos las ecuaciones de proyección de espín, que vienen dadas por,
\begin{equation}
    \sum_sx(s,p)\bar{x}(s,p)=\slashed{p}+m;\hspace{8mm}\sum_sy(s,p)\bar{y}(s,p)=\slashed{p}-m
\end{equation}
\section{Reglas de Feynman}
Sabemos que los campos espinoriales de Dirac son campos complejos, luego
\begin{equation}
    \Braket{0|T\Psi\Psi|0}=\Braket{0|T\bar{\Psi}\bar{\Psi}|0}=0
\end{equation}
Por tanto, el propagador de Feynman solo lo podremos formar con combinaciones de $\Psi$ y $\bar{\Psi}$, tal que
\begin{equation}
    S_a^b(x-y)=\Braket{0|T\Psi_a(x)\bar{\Psi}^b(x)|0}
\end{equation}
siendo una matrix $4\times4$. Desarrollando los cálculos llegamos a,
\begin{equation}
    S_a^b(x-y)=(i\slashed{\partial}+m)\Delta_m(x-y)
\end{equation}
La expresión explícita es,
\begin{equation}
    S_a^b(x-y)=\int\frac{d^4p}{(2\pi)^4}e^{-ip(x-y)}\frac{i(\slashed{p}+m)}{p^2-m^2+i\epsilon}
\end{equation}
donde $\frac{i(\slashed{p}+m)}{p^2-m^3+i\epsilon}$ es el propagador de Feynman en el espacio de momentos, tal que
\[\begin{fmffile}{diag679}
    \begin{fmfgraph*}(100,60)
        \fmfleft{a}
        \fmfright{b}
        \fmf{fermion,label=$\xrightarrow{p}$}{a,b}
        \fmflabel{$a$}{a}
        \fmflabel{$b\hspace{3mm}\Rightarrow\tilde{S}_a^b=\frac{\brackets{i(\slashed{p}+m)}_a^b}{p^2-m^2+i\epsilon}$}{b}
    \end{fmfgraph*}
\end{fmffile}\]
Las reglas de Feynman para los diagramas de campos espinoriales para fermiones son las siguientes,
\begin{itemize}
    \item Solo colocamos flechas a las ramas de partículas/antipartículas o de campos complejos.
    \item Las partículas \textit{in} apuntan hacia dentro y las partículas \textit{out} apuntan hacia fuera.
    \item Las antipartículas \textit{in} apuntan hacia fuera y las antipartículas \textit{out} apuntan hacia dentro.
    \item Las partículas \textit{in} van con $x(s,p)$ y las partículas \textit{out} van con $\bar{x}(s,p)$.
    \item Las antipartículas \textit{in} van con $\bar{y}(s,p)$ y las antipartículas \textit{out} van con $y(s,p)$.
\end{itemize}
Si llamamos $e$ a la partícula y $\bar{e}$ a la antipartícula, tenemos el diagrama de Feynman siguiente,
\[\hspace{1mm}\]
\[\begin{fmffile}{diag487320}
    \begin{fmfgraph*}(100,60)
        \fmfleft{l1,l2}
  \fmfright{r1,r2}

  % Línea real con label para momentum
  \fmf{fermion, label=$\overset{p}{\nearrow}$}{v,l1}
  \fmf{fermion, label=$\overset{p}{\searrow}$}{l2,v}
  \fmf{fermion, label=$\overset{p}{\searrow}$}{r1,v}
  \fmf{fermion, label=$\overset{p}{\nearrow}$}{v,r2}

  % Conexión fantasma para habilitar etiquetas de vértices
  \fmf{phantom}{l1,v1}
  \fmf{phantom}{l2,v2}
  \fmf{phantom}{v3,r1}
  \fmf{phantom}{v4,r2}

  % Blob en el centro
  \fmfblob{.16w}{v}

  % Etiquetas de vértices (números)
  \fmflabel{$\begin{matrix}
      \bar{y}(s,p)\\
      \bar{e}_s
  \end{matrix}$}{l1}
  \fmflabel{$\begin{matrix}
      e_s\\
      x(s,p)
  \end{matrix}$}{l2}
  \fmflabel{$\begin{matrix}
      y(s,p)\\
      \bar{e}_s
  \end{matrix}$}{r1}
  \fmflabel{$\begin{matrix}
      e_s\\
      \bar{x}(s,p)
  \end{matrix}$}{r2}
        
    \end{fmfgraph*}
\end{fmffile}\]
\[\hspace{1mm}\]
\begin{example}
    Si tenemos la interacción de Yukawa, $\mathscr{L}_{int}=-\lambda\phi\bar{\Psi}\Psi$, su diagrama de Feynman a orden $\lambda$ es el siguiente,
    \[\begin{fmffile}{daigajkf}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l1}
            \fmfright{r1,r2}
            \fmf{dashes}{l1,v}
            \fmf{fermion}{r1,v}
            \fmf{fermion}{v,r2}
            \fmflabel{$\hspace{10mm}-i\lambda$}{v}
        \end{fmfgraph*}
    \end{fmffile}\]
\end{example}
\begin{example}
    Consideramos el proceso $e\psi\to e\psi$. El orden más bajo aquí es $\lambda^2$ y tenemos dos diagramas de Feynman. Vamos a trabajar con el siguiente,
    \[\hspace{1mm}\]
    \[\begin{fmffile}{daiaf}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l1,l2}
            \fmfright{r1,r2}
            \fmf{fermion,label=$\overset{p_1}{\searrow}$,label.side=left}{l2,v1}
            \fmf{dashes,label=$\overset{p_2}{\nearrow}$}{l1,v1}
            \fmf{fermion,label=$\overset{p_1+p_2}{\longrightarrow}$}{v1,v2}
            \fmf{fermion,label=$\overset{p_3}{\nearrow}$}{v2,r2}
            \fmf{dashes,label=$\overset{p_4}{\searrow}$}{v2,r1}
            \fmflabel{$e$}{l2}
            \fmflabel{$e$}{r2}
            \fmflabel{$x(s,p_1)$}{v1}
            \fmflabel{$\bar{x}(s',p_3)$}{v2}
        \end{fmfgraph*}
    \end{fmffile}\]
\end{example}
Luego, tenemos
\begin{equation}
    i\mathscr{M}_{ss'}=(-i\lambda)^2\bar{x}(s',p_3)\tilde{S}(p_1+p_2)x(s,p_1)+\dots
\end{equation}
donde añadimos el $(-i\lambda)^2$ porque estamos a segundo orden, también añadimos los cuadriespinores $x$ y $\bar{x}$ porque acompañan a la partícula $e$ y añadimos también el propagador interno $\tilde{S}$, el orden es el que tenemos porque escribimos los términos comenzando en el sentido contrario a las flechas y ponemos puntos suspensivos porque tenemos que sumar también la contribución del otro diagrama.\\ \\
De forma explícita tenemos,
\begin{equation}
    i\mathscr{M}_{ss'}=\lambda^2\bar{x}(s',p_3)\frac{i(\slashed{p_1}-\slashed{p_2})+m}{(p_1+p_2)^2-m^2}x(s,p)+\dots
\end{equation}
Luego,
\begin{equation}
    |\mathscr{M}_{ss'}|^2=\lambda^4\brackets{\bar{x}^a(s',p_3)\tilde{S}_a^b(p_1+p_2)x_b(s,p_1)}\brackets{\bar{x}^c(s,p_1)\tilde{S}_c^{d}x_d(s',p_3)}
\end{equation}
donde hemos usado que $\left(\bar{\Psi}_1\gamma^{\mu}\Psi_2\right)^{\dagger}=\bar{\Psi}_2\gamma_{\mu}\Psi_1$. Además, por tener partículas iniciales y finales no polarizadas tenemos que,
\begin{equation}
    \frac{1}{2}\sum_s\sum_{s'}|\mathscr{M}_{ss'}|^2=\frac{1}{2}\lambda^4(\slashed{p}_1+m)_b^c\tilde{S}_c^d(\slashed{p}_3+m)_d^a\tilde{S}_a^b=\frac{\lambda^4}{2}tr\left((\slashed{p}_1+m)\tilde{S}(\slashed{p}_3+m)\tilde{S}\right)
\end{equation}
donde $\tilde{S}=\tilde{S}(p_1+p_2)$
\begin{note}
    Si tenemos diagramas fermiónicos con loops, solo tendremos propagadores internos y añadiremos un signo $(-)$ por cada loop.
\end{note}
\chapter{Bosones. Campos Vectoriales}
\section{Introducción}

En los capítulos anteriores hemos estudiado la formulación cuántica de campos escalares y espinoriales, correspondientes a partículas de espín 0 y $1/2$, respectivamente. Ambos casos ilustran cómo las representaciones del grupo de Lorentz determinan la estructura de los campos cuánticos que describen partículas elementales.\\ \\
En este capítulo abordaremos el caso de los \textbf{campos vectoriales}, que permiten describir partículas con \textbf{espín 1}, tanto masivas como sin masa. El ejemplo paradigmático de un campo vectorial sin masa es el \textit{campo electromagnético}, cuya cuantización conduce a la teoría cuántica del fotón. Por otro lado, los \textit{bosones masivos} como los del modelo electrodébil (bosones $W^\pm$ y $Z$) también requieren campos vectoriales, pero con una formulación ligeramente distinta para garantizar la correcta propagación de los grados de libertad físicos.\\ \\
A nivel clásico, un campo vectorial se representa por una función $A^\mu(x)$ que transforma como un \textit{cuatrivector} bajo transformaciones de Lorentz. Sin embargo, al cuantizar este campo surgen \textbf{complicaciones adicionales} respecto a los casos anteriores:
\begin{itemize}
    \item En el caso sin masa, no todos los componentes de $A^\mu$ corresponden a grados de libertad físicos (por ejemplo, el fotón tiene solo dos polarizaciones).
    \item En el caso masivo, aunque $A^\mu$ parece tener cuatro componentes, solo tres corresponden a los \textit{grados de libertad físicos} de una partícula con espín 1.
\end{itemize}

Para resolver estas dificultades, será necesario:
\begin{itemize}
    \item Imponer condiciones de \textit{gauge} (en el caso sin masa), como la \textit{condición de Lorenz}.
    \item Introducir técnicas como el uso del \textit{tensor de campo} $F_{\mu\nu}$, que encapsula las propiedades físicas de $A^\mu$ de manera invariante.
\end{itemize}

En este capítulo desarrollaremos la teoría de campos vectoriales desde su descripción lagrangiana hasta su cuantización canónica. Estudiaremos las propiedades de transformación, las soluciones a la ecuación de movimiento (ecuación de Proca o de Maxwell), los problemas asociados a la covarianza y la eliminación de grados de libertad no físicos, y finalmente su incorporación a la formulación de reglas de Feynman.\\ \\
La comprensión de los campos vectoriales constituye un paso esencial para introducir las \textbf{interacciones gauge}, que son la base de las teorías de Yang-Mills y del Modelo Estándar de las interacciones fundamentales.
\section{Bosones masivos}
Consideramos ahora partículas masivas con espín $1$ y masa $m$. Para estas partículas, el grupo de simetría que deja invariante el momento en el sistema de reposo (el \textit{little group}) es $SO(3)$, y su representación de espín $1$ contiene tres estados físicos (tres grados de libertad), caracterizados por la proyección del espín sobre un eje de cuantización: helicidad $-1, 0, +1$.\\ \\
Sin embargo, para construir una teoría de campos relativista, es necesario que los campos definidos en todo el espacio-tiempo transformen bajo una representación del grupo de Lorentz \( SO(1,3) \), y no solo bajo su subgrupo \( SO(3) \). Por tanto, buscamos representaciones del grupo de Lorentz que, al restringirse al subgrupo \( SO(3) \), contengan precisamente una representación de espín $1$.\\ \\
La representación vectorial de \( SO(1,3) \), correspondiente a cuadrivectores \( A^\mu(x) \), cumple esta propiedad: bajo el subgrupo \( SO(3) \) de rotaciones espaciales, el cuadrivector se descompone en una parte escalar (el componente temporal \( A^0 \)) y una parte vectorial espacial (los componentes \( A^i \)), que transforman como un triplete bajo \( SO(3) \), es decir, como una representación de espín 1. \\ \\
Por tanto, el campo \( A^\mu(x) \) transforma según la representación \( (\tfrac{1}{2}, \tfrac{1}{2}) \) del grupo de Lorentz, y constituye el objeto natural para describir partículas de espín 1 en teoría cuántica de campos. Este campo tiene cuatro componentes, pero como veremos, no todos son físicos: en la teoría de Proca para bosones masivos, una condición de transversidad (derivada de la ecuación de movimiento) elimina el grado de libertad no físico, dejando solo los tres esperados.\\ \\
Consideraremos el caso sencillo de que una partícula es su propia antipartícula, para ello, usaremos campos vectoriales reales, que explícitamente vienen dados por,
\begin{equation}
    V_{\mu}=\int\frac{d^3p}{(2\pi)^3}\frac{1}{\sqrt{2\omega_p}}\sum_{s=-,0+}\brackets{e^{-ipx}\mathcal{E}_{\mu}^s(p)a_s(p)+e^{ipx}\mathcal{E}_{\mu}^{s*}(p)a_s^{\dagger}(p)}
\end{equation}
donde $V_{\mu}$ se denomina \textbf{campo de Proca} y los $\mathcal{E}_{\mu}$ son \textbf{vectores de polarización}. Al imponer la covariancia Lorentz, deberemos ver que $V_{\mu}$ transforma como un cuadrivector, por lo que $\mathcal{E}_{\mu}$ transformará como un cuadrivector, tal que
\begin{equation}
    \mathcal{E}_{\mu}^s(p)=L(k\to p)_{\mu}^{\nu}\mathcal{E}_{\nu}^s(p)
\end{equation}
transformando en la representación vectorial.\\ \\
Análogamente al caso espinorial tenemos que
\begin{equation}
    \mathcal{E}^0(p)=\begin{pmatrix}
        P_z/m\\
        0\\
        0\\
        E/m
    \end{pmatrix};\hspace{7mm}\mathcal{E}^{\pm}=\frac{1}{\sqrt{2}}\begin{pmatrix}
        0\\
        1\\
        \pm i\\
        0
    \end{pmatrix}
\end{equation}
siendo $\mathcal{E}^0$ una polarización longitudinal, pues tomamos como dirección de referencia la de $P_z$. Obtenemos que $V_{\mu}$ transforma como un cuadrivector. Las relaciones de $\mathcal{E}_{\mu}$ son,
\begin{equation}
    P^{\mu}\mathcal{E}_{\mu}^s(p)=0;\hspace{7mm}\mathcal{E}^{s\mu}(p)\mathcal{E}_{\mu}^{s*}(p)=-1
\end{equation}
en la segunda expresión las $s$ no se suman (no se usa la notación de Einstein para $s$). Podemos hacer la derivada de $V_{\mu}$ obteniendo que
\begin{equation}
\partial_{\mu}V^{\mu}(x)=0
\end{equation}
Luego, podemos tomar $p$ \textit{on-shell} para obtener 
\begin{equation}
    (\square+m^2)V^{\mu}(x)=0
\end{equation}
que es la ecuación de Klein-Gordon. Ambas ecuaciones se pueden derivar del Lagrangiano
siguiente,
\begin{equation}
    \mathscr{L}=-\frac{1}{4}F_{\mu\nu}F^{\mu\nu}+\frac{1}{2}m^2V^{\mu}V_{\mu}
\end{equation}
donde $F_{\mu\nu}=\partial_{\mu}V_{\nu}-\partial_{\nu}V_{\mu}$, denominado \textbf{Lagrangiano de Proca}.\\ \\
A límites de muy altas energías (caso ultrarrelativista), tenemos que $E=pc$, por lo que el vector de polarizacón lineal queda
\begin{equation}
    \mathcal{E}^0\sim\frac{E}{m}\begin{pmatrix}
        1\\
        0\\
        0\\
        1
    \end{pmatrix}
\end{equation}
pero esto no es coherente, porque debería anulare. Para mantener consistencia, deberemos obtener términos que cancelen a $\mathcal{E}^0$, necesitando nuevos grados de libertad (como el Bosón de Higgs).\\ \\
Se puede comprobar que
\begin{equation}
    \sum_s\mathcal{E}_{\mu}^{s*}(p)\mathcal{E}_{\nu}^s(p)=-\eta_{\mu\nu}+\frac{1}{m^2}P_{\mu}P_{\nu}
\end{equation}
con esta relación podemos calcular objetos del tipo $\Braket{0|V_{\mu}(x)V_{\nu}(x)|0}$, obteniendo 
\begin{equation}
    \Braket{0|V_{\mu}(x)V_{\nu}(x)|0}=-\left(\eta_{\mu\nu}+\frac{1}{m^2}\partial_{\mu}\partial_{\nu}\right)D(x-y)
\end{equation}
Vemos que esta expresión es simétrica, por lo que necesitamos conmutadores para que $\brackets{V_{\mu},V_{\nu}}=0$ a distancias tipo espacio, concluyendo que las partículas son \textbf{bosones}.\\ \\
Podemos obtener el propagador de Feeynman como,
\begin{equation}
    \Braket{0|TV_{\mu}(x)V_{\nu}(x)|0}=\int\frac{d^4p}{(2\pi)^4}e^{-i(x-y)p}\brackets{\underbrace{\left(-\eta_{\mu\nu}+\frac{1}{m^2}P_{\mu}P_{\nu}\right)\frac{i}{p^2-m^2+i\epsilon}}_{\text{Tér,imo covariante}}-\underbrace{\frac{1}{m^2}\delta_{\mu0}\delta_{\nu0}}_{\text{Término no covariante}}
    }
\end{equation}
obteniendo un término no covariante, debido a que $T$ no conmuta con $\partial_0$. Se puede comprobar que los términos no covariantes del Hamiltoniano de Proca cancelan los términos no covariantes del propagador de Feynman, obteniendo únicamente términos covariantes, por lo que la función de Green será únicamente usando los términos covariantes, tal que
\begin{equation*}
    \begin{fmffile}{holaaa}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l1}
            \fmfright{l2}
            \fmf{boson}{l1,l2}
            \fmflabel{$i\mathscr{M}\to\hspace{4mm}\mu$}{l1}
            \fmflabel{$\nu\hspace{4mm}\to\left(-\eta_{\mu\nu}+\frac{P_{\mu}P_{\nu}}{m^2}\right)\frac{i}{p^2-m^2+i\epsilon}$}{l2}
        \end{fmfgraph*}
    \end{fmffile}
\end{equation*}
donde no hay flechas porque usamos campos reales. Las reglas de Feynman son,
\begin{itemize}
    \item No usaremos flechas siempre que tengamos campos reales.
    \item Los bosones \textit{in} van con $s$ y el vector de polarización $\mathcal{E}_{\mu}^s$.
    \item Los bosones \textit{out} van con $s'$ y el vector de polarización $\mathcal{E}_{\nu}^{s'*}$.
\end{itemize}
Tal que
\[\begin{fmffile}{dajhd}
    \begin{fmfgraph*}(100,60)
        \fmfleft{l}
        \fmfright{r}
        \fmf{boson,label=$\mathcal{E}_{\mu}^s\hspace{6mm}\mu$}{l,v}
        \fmf{boson,label=$\nu\hspace{6mm}\mathcal{E}_{\nu}^{s'*}$}{v,r}
        \fmfblob{.24w}{v}
        \fmflabel{$s$}{l}
        \fmflabel{$s'$}{r}
    \end{fmfgraph*}
\end{fmffile}\]
\begin{example}
    Vamos a calcular las reglas de Feynman para los siguientes casos:
    \begin{itemize}
        \item Consideramos el Lagrangiano de interacción siguiente,
        \begin{equation}
            \mathscr{L}_{int}=-ig\bar{\psi}\gamma^{\mu}V_{\mu}\psi
        \end{equation}
        donde $\psi$ representa un campo complejo y $V_{\mu}$ un campo vectorial. El diagrama de Feynman es el siguiente,
        \[\begin{fmffile}{mmm}
            \begin{fmfgraph*}(100,60)
                \fmfleft{l1}
                \fmfright{r1,r2}
                \fmf{boson,label=$q$}{l1,v}
                \fmf{fermion,label=$p$}{v,r1}
                \fmf{fermion,label=$p'$}{v,r2}
            \end{fmfgraph*}
        \end{fmffile}\]
        Luego, como tenemos un único vértice, estaremos a orden $g$. Entonces la función de Green a primer orden será,
        \begin{equation}\small
            G_3=\int d^4z\Braket{0|\bar{\psi}(y_1)V_{\mu}(x)\psi(y_2)\mathscr{L}_{int}|0}=(-ig)\int d^4z\Braket{0|\bar{\psi}(y_1)V_{\mu}(x)\psi(y_2)\bar{\psi}(z)\gamma^{\mu}V_{\mu}(z)\psi(z)|0}
        \end{equation}
        Luego, aplicando el Teorema de Wick, y sabiendo que $\psi\psi$ y $\bar{\psi}\bar{\psi}$ para un campo complejo se anula, nos queda,
        \begin{equation}
            G_3=(-ig)\gamma^{\mu}\int d^4zS(x-z)\brackets{D(y_1-y_2)D(z-z)+D(y_1-z)D(y_2-z)}
        \end{equation}
        donde $S$ representa el propagador del campo vectorial, $D$ los propagadores del campo fermiónico complejo y aparece un $\gamma^{\mu}$ que sacamos del producto escalar. Luego,la función de Green amputada (sin la integral), tras aplicar Fourier, queda,
        \begin{equation}
            \tilde{G}_3^{amp}=-ig\gamma^{\mu}
        \end{equation}
        Por tanto, la amplitud de colisión queda,
        \begin{equation}
            i\mathscr{M}=\tilde{G}_3^{amp}=-ig\gamma^{\mu}\Rightarrow\mathscr{M}=-g\gamma^{\mu}
        \end{equation}
        \item Consideramos el Lagrangiano de interacción siguiente,
        \begin{equation}
            \mathscr{L}_{int}=-igV_{\mu}\left(\phi^{\dagger}\partial^{\mu}\phi-(\partial_{\mu}\phi^{\dagger})\phi\right)
        \end{equation}
        donde $\phi$ es un campo escalar complejo. El diagrama de Feynman es el siguiente,
        \[\begin{fmffile}{lnslklk}
            \begin{fmfgraph*}(100,60)
                \fmfleft{l1}
                \fmfright{r1,r2}
                \fmf{boson,label=$q$}{l1,v}
                \fmf{scalar,label=$p'$}{v,r2}
                \fmf{scalar,label=$p$}{r1,v}
            \end{fmfgraph*}
        \end{fmffile}\]
        Como tenemos un solo vértice, estamos a orden $g$. Así, la función de Green queda,
        \begin{equation}
        \begin{array}{l}
            G_3=\int d^4z\Braket{0|\phi^{\dagger}(y_1)V_{\mu}(x)\phi(y_2)\mathscr{L}_{int}|0}=\\ \\
            =(-ig)\int d^4z\Braket{0|\phi^{\dagger}(y_1)V_{\mu}(x)\phi(y_2)V_{\mu}(z)\left(\phi^{\dagger}(z)\partial^{\mu}\phi(z)-(\partial_{\mu}\phi^{\dagger}(z))\phi(z)\right)|0}
        \end{array}
        \end{equation}
        Aplicando el Teorema de Wick tenemos,
        \begin{equation}
            G_3=(-ig)\int d^4zS(x-z)\brackets{D(y_2-z)\partial^{\mu}D(y_1-z)-D(y_1-z)\partial^{\mu}D(y_2-z)}
        \end{equation}
        Luego, aplicando Fourier a la parte de las derivadas tenemos,
        \begin{equation}
            \partial^{\mu}D(y-z)\overset{\mathscr{F}}{\to}-ip^{\mu}D(p)
        \end{equation}
        Por tanto, la función de Green amputada queda,
        \begin{equation}
            \tilde{G}^{amp}_3=(-ig)\brackets{p^{\mu}+p^{'\mu}}
        \end{equation}
        Así, la amplitud de colisión queda,
        \begin{equation}
            \mathscr{M}=-g\brackets{p^{\mu}+p^{'\mu}}
        \end{equation}
        \item Consideramos el Lagrangiano siguiente,
        \begin{equation}
            \mathscr{L}_{int}=-\frac{\lambda}{2}V_{\mu}V^{\mu}\phi^{\dagger}\phi
        \end{equation}
        cuyo diagrama de Feynman es,
        \[\begin{fmffile}{vavcmn}
            \begin{fmfgraph*}(100,60)
                \fmfleft{l1,l2}
                \fmfright{r1,r2}
                \fmf{boson}{l1,v}
                \fmf{boson}{l2,v}
                \fmf{scalar}{v,r2}
                \fmf{scalar}{r1,v}
            \end{fmfgraph*}
        \end{fmffile}\]
        Aplicando lo anterior, llegamos a que la función de Green amputada es,
        \begin{equation}
            \tilde{G}^{amp}_4=-i\lambda\eta_{\mu\nu}
        \end{equation}
        usando que $V_{\mu}V^{\mu}=V^{\mu}\eta_{\mu\nu}V^{\nu}$. Luego, la amplitud de colisión queda,
        \begin{equation}
            \mathscr{M}=-\lambda\eta_{\mu\nu}
        \end{equation}
    \end{itemize}
\end{example}
Para partículas sin masa, si imponemos invariancia bajo traslaciones, para tener representaciones finitas (como con los fermiones), no tenemos solución, pues tenemos la transformación,
\begin{equation}
    \mathcal{E}_{\mu}^{\pm}(p)\to\Lambda_{\mu}^{\nu}\mathcal{E}_{\nu}^{\pm}(p)+P_{\mu}\Omega^{\pm}(p,\Lambda)
\end{equation}
por lo que $\mathcal{E}_{\mu}$ ya no transforma como un cuadrivector, debido al sumando extra, y como consecuencia, el campo sin masa $A_{\mu}(x)$ no transformará como un cuadrivector, pues transforma como,
\begin{equation}
    U(\Lambda)A_{\mu}(x)U^{-1}(x)=\Lambda_{\mu}^{\nu}A_{\nu}(\Lambda x)+\partial_{\mu}\Omega(x,\Lambda)
\end{equation}
obteniendo un término extra que rompe la transformación vectorial. Por lo que es imposible describir una partícula sin masa con $h=\pm1$ usando un campo vectorial. Es posible describirlo usando un campo tensorial de rango $2$ antisimétrico, pero no tendremos interacciones a distancias muy grandes (por lo que no podremos describir el electromagnetismo). Como solución, podemos construir una teoría 'astuta', donde $V_{\mu}$ actúe como un cuadrivector y el término $\partial_{\mu}\Omega(x,\Lambda)$ se cancele, imponiendo una redundancia, que será \textbf{la invariancia gauge}.
\section{Invariancia Gauge}
Tenemos las transformaciones,
\begin{equation*}
    \mathcal{E}_{\mu}^{\pm}(p)\to\Lambda_{\mu}^{\nu}\mathcal{E}_{\nu}^{\pm}(p)+P_{\mu}\Omega^{\pm}(p,\Lambda)
\end{equation*}
\begin{equation*}
    A_{\mu}(x)\to\Lambda_{\mu}^{\nu}A_{\nu}(\Lambda x)+\partial_{\mu}\Omega(x)
\end{equation*}
donde los términos extras dependen del sistema de referencia. Ahora, queremos añadir una redundancia Gauge para que el resultado final no cambie con el observador.
\begin{note}
    \begin{itemize}
        \item Para partículas sin masa y helicidad, $h=\pm1$, tenemos invariancia Gauge para campos vectoriales.
        \item Para partículas sin masa y helicidad, $h=\pm2$, tenemos invariancia Gauge para $h_{\mu\nu}$.
    \end{itemize}
    Luego, esto será válido para cualquier $|h|\geq1$.
\end{note}
Centrémonos en el caso $m=0$ y $h=\pm1$, y tenemos,
\begin{equation}
    \mathcal{E}_0^{\pm}(p)=0;\hspace{10mm}P_i\mathcal{E}_{i}^{\pm}(p)=0
\end{equation}
y satisface (aplicando \textit{on-shell}, $p^2=0$),
\begin{equation}
    \square A_{\mu}=0;\hspace{10mm}A_0=0;\hspace{10mm}\partial_iA_i=0;\hspace{10mm}\partial_{\mu}A^{\mu}=0
\end{equation}
Estas ecuaciones pueden derivarse de un Lagrangiano. Es importante notar que no es invariante Lorentz como tal, sino que buscamos una equivalencia, para que $A_{\mu}\to A_{\mu}+\partial_{\mu}\Omega$, siendo la idea de la invariancia Gauge. Luego, $A_{\mu}(x)$ y $\Omega(x)$ deben ser invariante para esta transformación local.\\ \\
Tomamos $\brackets{A_{\mu}}$, fijando la elección de Gauge que no podemos cambiar.\\ \\
El Lagrangiano desde el que partimos es el Lagrangiano de Maxwell,
\begin{equation}
    \mathscr{L}=-\frac{1}{4}F_{\mu\nu}F^{\mu\nu};\hspace{6mm}F_{\mu\nu}=\partial_{\mu}A_{\nu}-\partial_{\nu}A_{\mu}
\end{equation}
para fotones. Como $A_0$ no tiene derivada temporal, entonces no es dinámico, por lo que no tiene momento conjugado.\\ \\
Pasamos a cuatro grados de libertad, quitando un grado de libertad porque $A_0$ no es dinámico y 
quitando otro por la redundancia Gauge, obteniendo dos grados de libertad. Se cumple que
\begin{equation}
    \partial^{\mu}F_{\mu\nu}=0;\hspace{10mm}\square A_{\nu}-\partial_{\nu}\partial^{\mu}A_{\mu}=0
\end{equation}
que es invariante de Gauge.\\ \\
Como $A_{\mu}$ está indeterminado, esto no son buenas condiciones iniciales para el problema, por lo que elegimos Gauge imponiendo,
\begin{equation}
    \partial_iA_i=0
\end{equation}
siendo el \textbf{Gauge de Coulomb}. Luego,
\begin{equation}
    \partial_i\partial^iA_0=0\rightarrow A_0=0
\end{equation}
Obteniendo finalmente que
\begin{equation}
    \square A_i=0
\end{equation}
para un tratamiento canónico, aunque esto rompe la covarianza. A partir de aquí, se puede desarrollar hasta obtener (de forma rigurosa), con integrales de camino, unas reglas de Feynman invariantes de Lorentz.\\ \\
Nosotros vamos a tratarlo de forma menos rigurosa (y menos intuitiva). Partimos de añadir un término al Lagrangiano, cambiando de gauge, que va a favorecer a aquellos campos que cumplan $\partial_{\mu}A^{\mu}=0$ (\textbf{gauge de Lorentz}), de forma dinámica (así evitaremos imponer la condición de manera rígida), tal que
\begin{equation}
    \mathscr{L}=-\frac{1}{4}F_{\mu\nu}F^{\mu\nu}-\frac{1}{2\xi}(\partial_{\mu}A^{\mu})^2\equiv\mathscr{L}_{gf}
\end{equation}
donde $\mathscr{L}_{gf}$ significa que tenemos un Lagrangiano \textbf{gauge fijado} y el término extra se puede generalizar como $G[A]^2$, permitiendo fijarse otras funciones. Este Lagrangiano NO es invariante gauge (es lo que ocurre al elegir un representante). En este caso, hemos elegido una familia entera de representantes, $\partial_{\mu}A^{\mu}=0$. Al romper la invariancia perdemos la indeterminación de $A_{\mu}$.\\ \\
Vamos a buscar la función de Green de nuestra ecuación de movimiento completa. Vemos que si obviamos el nuevo término tendríamos,
\begin{equation}
    \brackets{\square\delta_{\mu\nu}-\partial_{\mu}\partial_{\nu}}A^{\mu}=0
\end{equation}
con autovalor $0$, por lo que no es invertible y no podríamos encontrar solución.\\ \\
Usando el $\mathscr{L}_{gf}$ tenemos
\begin{equation}
    \Pi_{\mu\nu}(x-y)=\int\frac{d^4p}{(2\pi)^4}e^{-ip(x-y)}\Pi_{\mu\nu}(p)
\end{equation}
que pasando al espacio de momentos (usando Fourier), tenemos
\begin{equation}
    \Pi_{\mu\nu}(p)=\brackets{\eta_{\mu\nu}-(1-\xi)\frac{P_{\mu}P_{\nu}}{p^2}}\frac{-i}{p^2+i\epsilon}
\end{equation}
donde $\xi$ es el \textbf{parámetro gauge}, siendo un número arbitrario de la elección gauge. Los parámetros físicos no dependen del parámetro gauge, por lo que tenemos invariancia Gauge. Además, como no depende de $\xi$, podemos elegir cualquier valor de $\xi$ y tomaremos $\xi=1$, denominado \textbf{Gauge de Feynman}\footnote{Elegir $\xi=1$ no solo es conveniencia, sino que es especialmente útil, porque así, el propagador toma forma transversal $\eta_{\mu\nu}$, y en este gauge particular los cálculos suelen simplificarse.}, obteniendo el propagador,
\begin{equation}
    \Pi_{\mu\nu}(p)=\eta_{\mu\nu}\frac{-i}{p^2+i\epsilon}
\end{equation}
siendo el propagador que usaremos en los problemas.
\subsection*{Cuantización de Gupta-Bleuler}
La cuantización de Gupta-Bleuler es un procedimiento desarrollado para cuantizar campos vectoriales masivos o sin masa, como el campo electromagnético, de manera que:
\begin{itemize}
\item Se mantenga la invarianza gauge (cuando es necesaria),
\item Se respeten las condiciones relativistas (como la covariancia de Lorentz),
\item Se evite introducir grados de libertad no físicos (como polarizaciones longitudinales o escalares que no corresponden a fotones reales).
\end{itemize}
El procedimiento es el siguiente,
\begin{enumerate}
    \item Se permite trabajar en un espacio de Hilbert más grande, con estados no físicos (por ejemplo, con polarizaciones longitudinales o escalares).
\item Se impone la condición de Lorenz de forma débil como restricción sobre los estados físicos del sistema:
\begin{equation}
    \partial_{\mu}A^{\mu}(x)^{(+)}\ket{\text{físico}}=0
\end{equation}
  es la parte positiva del operador de campo.
\item Esto permite que:
\begin{itemize}
\item El formalismo siga siendo covariante,
\item El operador $A_{\mu}(x)$ siga teniendo 4 componentes,
\item Solo los estados que cumplen esa condición sean físicamente permitidos (tienen norma positiva y representan partículas reales).
 \end{itemize}
\end{enumerate}
En nuestro caso, las soluciones dan lugar a cuatro polarizaciones. Por lo que tomamos un espacio de Hilbert, $\mathscr{H}$, que tenga partes no físicas que se proyectan a cero. De forma que se retiran las polarizaciones no físicas y se llega a dos polarizaciones (que es lo que buscamos para $m=0$ y $h=\pm1$).\\ \\
Luego, para el caso \textit{massless}, tenemos el propagador,
\[\begin{fmffile}{dahd}
    \begin{fmfgraph*}(100,60)
        \fmfleft{l}
        \fmfright{r}
        \fmf{boson,label=$p$}{l,r}
        \fmflabel{$\mu$}{l}
        \fmflabel{$\nu\hspace{5mm}\to-i\eta_{\mu\nu}\frac{i}{p^2+i\epsilon}$}{r}
    \end{fmfgraph*}
\end{fmffile}\]
en el espacio de momentos. Luego, para calcular las amplitudes de colisión tenemos,
\[\begin{fmffile}{sas}
    \begin{fmfgraph*}(100,60)
        \fmfleft{l}
        \fmfright{r}
        \fmf{boson,label=$\mathcal{E}_{\mu}^{\pm}(p)\hspace{4mm}\mu$}{l,v}
        \fmf{boson,label=$\nu\hspace{1mm}\mathcal{E}_{\nu}^{\pm*}(p')$}{v,r}
        \fmfblob{.24w}{v}
        \fmflabel{$\xrightarrow{p}$}{l}
        \fmflabel{$\xrightarrow{p'}$}{r}
    \end{fmfgraph*}
\end{fmffile}\]
Por la condición gauge tenemos,
\begin{equation}
    \mathcal{E}^{\mu}\to\Lambda_{\nu}^{\mu}\mathcal{E}^{\nu}+P^{\mu}\Omega
\end{equation}
que cambia con el observador. Para que todo esto sea consistente, es necesario que
\begin{equation}
    \mathscr{M}(p,\pm,\dots)=\mathcal{E}_{\mu}^{\pm}(p)\mathscr{M}^{\mu}(p,\dots)
\end{equation}
es decir, sacamos la dependencia de la helicidad en la amplitud de colisión. Así, \textit{on-shell} tenemos la \textbf{identidad de Ward},
\begin{equation}
    P_{\mu}\mathscr{M}^{\mu}(p,\dots)=0
\end{equation}
para evitar cambios con $\mathcal{E}$ en la amplitud de colisión. Se puede comprobar que esta identidad sí se cumple.
\\ \\
Hemos visto cómo tener invarianzas gauge para transformaciones de los campos vectoriales. A estos campos podemos acoplarles una corriente de Noether, $J^{\mu}$, obteniendo una transformación
\begin{equation}
    A_{\mu}J^{\mu}\to(A_{\mu}+\partial_{\mu}\Omega)J^{\mu}
\end{equation}
que será invariante gauge solo si estamos \textit{on-shell}. $J^{\mu}$ se asocia a una simetría global abeliana, $U(1)$, que es
\begin{equation}
    \phi_j\to e^{iq_j\alpha}\phi_j
\end{equation}
donde $\alpha$ es el parámetro de la transformación y $q_j$ permite que la transformación de cada $\phi_j$ sea distinta.\\ \\
Si tomamos la $J^{\mu}$ correspondiente a esta transformación y se la acoplamos, siempre que estemos \textit{on-shell}, obtendremos la carga conservada, que es proporcional a $q_j$. Pero queremos que la obtención de la carga conservada sea independiente a como sea campo, es decir, que no influya si estamos \textit{on-shell} o no. Para ello, tomamos una transformación del campo compuesta, imponiendo que $\alpha\to\alpha(x)$, obteniendo que
\begin{equation}
    A_{\mu}(x)\to A_{\mu}(x)+\partial_{\mu}\alpha(x)
\end{equation}
por lo que la transformación de $U(1)$ queda,
\begin{equation}
    \partial_{\mu}\phi_j(x)\to e^{iq_j\alpha(x)}\partial_{\mu}\phi_j(x)+iq_j\brackets{\partial_{\mu}\alpha(x)}e^{iq_j\alpha(x)}\phi_j(x)
\end{equation}
Luego, combinando ambas transformaciones, podemos ver que los términos inhomogéneos se cancelan.
\begin{proof}
    Consideramos las transformaciones locales de simetría gauge:
\begin{align}
\phi_j(x) &\rightarrow e^{i q_j \alpha(x)} \phi_j(x) \\
A_\mu(x) &\rightarrow A_\mu(x) + \partial_\mu \alpha(x)
\end{align}
La derivada ordinaria del campo escalar transforma como:
\begin{align}
\partial_\mu \phi_j(x) &\rightarrow \partial_\mu \left( e^{i q_j \alpha(x)} \phi_j(x) \right) \\
&= e^{i q_j \alpha(x)} \partial_\mu \phi_j(x) + \left( \partial_\mu e^{i q_j \alpha(x)} \right) \phi_j(x) \\
&= e^{i q_j \alpha(x)} \partial_\mu \phi_j(x) + i q_j \left( \partial_\mu \alpha(x) \right) e^{i q_j \alpha(x)} \phi_j(x)
\end{align}
Por tanto, la derivada del campo adquiere un término adicional (inhomogéneo) proporcional a \(\partial_\mu \alpha(x)\).\\ \\
Ahora, si consideramos que el lagrangiano contiene un acoplamiento entre el campo vectorial y una corriente conservada, como en:
\begin{equation}
\mathcal{L}_{\text{int}} = i q_j A^\mu \left( \phi_j^* \partial_\mu \phi_j - \partial_\mu \phi_j^* \phi_j \right),
\end{equation}
entonces, al aplicar las transformaciones anteriores, también el campo \( A_\mu \) cambia:
\begin{equation}
A_\mu(x) \rightarrow A_\mu(x) + \partial_\mu \alpha(x)
\end{equation}
Este nuevo término \(\partial_\mu \alpha(x)\) introducido en \(A_\mu(x)\) se combina con el término inhomogéneo que apareció en \(\partial_\mu \phi_j(x)\), cancelándolo. Como resultado, el lagrangiano total permanece invariante bajo esta transformación local.\\ \\
Por tanto, aunque aparezcan términos inhomogéneos al transformar los campos por separado, al combinarlos correctamente dentro del lagrangiano, estos términos se cancelan y se mantiene la invariancia gauge.
\end{proof}
Para simplificar estos cálculos, introducimos la \textbf{derivada covariante}, que agrupa los términos de la derivada y el campo, tal que
\begin{equation}
    D_{\mu}\phi_j=(\partial_{\mu}-iq_jA_{\mu})\phi_j
\end{equation}
y dependerá del objeto sobre el que actúe. Luego, la transformación de la derivada covariante es
\begin{equation}
\begin{array}{rl}
    D_{\mu}\phi_j\to&\left(\partial_{\mu}-iq_j\brackets{A_{\mu}(x)+\partial_{\mu}\alpha(x)}\right)e^{iq_j\alpha(x)}\phi_j(x)=\\ \\
    &=\cancel{\partial_{\mu}\brackets{e^{iq_j\alpha(x)}\phi_j(x)}}-iq_jA_{\mu}(x)e^{iq_j\alpha(x)}\phi_j(x)-\cancel{iq_j(\partial_{\mu}\alpha(x))e^{iq_j\alpha(x)}\phi_j(x)}=\\ \\
    &=e^{iq_j\alpha(x)}\partial_{\mu}\phi_j(x)-iq_jA_{\mu}(x)e^{iq_j\alpha(x)}\phi_j(x)=\\ \\
    &=e^{iq_j\alpha(x)}(\partial_{\mu}-iq_jA_{\mu})\phi_j(x)=e^{iq_j\alpha(x)}D_{\mu}\phi_j(x)
\end{array}
\end{equation}
Gracias a esta derivada, podemos introducir términos cinéticos en el Lagrangiano que tengan la forma,
\begin{equation}
    D_{\mu}\phi^{\dagger}D^{\mu}\phi_j=(D_{\mu}\phi_j)^{\dagger}D^{\mu}\phi_j
\end{equation}
Siendo esto una forma general de añadir términos invariantes gauge dentro del Lagrangiano. También podemos usar las $F_{\mu\nu}$ dentro del Lagrangiano para añadir términos invariantes gauge, pues se relacionan con la derivada covariante de la forma,
\begin{equation}
    \begin{array}{rl}
        \brackets{D_{\mu},D_{\nu}}\phi_j &=\left(D_{\mu}D_{\nu}-D_{\nu}D_{\mu}\right)\phi_j=\brackets{(\partial_{\mu}-iq_jA_{\mu})(\partial_{\nu}-iq_jA_{\nu})-(\partial_{\nu}-iq_jA_{\nu})(\partial_{\mu}-iq_jA_{\mu})}\phi_j= \\  \\
         & =\brackets{\cancel{\partial_{\mu}\partial_{\nu}}-iq_j\partial_{\mu}A_{\nu}-\cancel{iq_jA_{\mu}\partial_{\nu}}+\cancel{q_j^2A_{\mu}A_{\nu}}-\cancel{\partial_{\nu}\partial_{\mu}}+\cancel{iq_j\partial_{\nu}A_{\mu}}+iq_jA_{\nu}\partial_{\mu}-\cancel{q_j^2A_{\nu}A_{\mu}}}\phi_j=\\ \\
         &=-iq_j\brackets{(\partial_{\mu}A_{\nu}+\partial_{\nu}A_{\mu})}\phi_j=-iq_jF_{\mu\nu}\phi_j
    \end{array}
\end{equation}
donde los términos del tipo $\partial_{\mu}\partial_{\nu}$ se cancelan porque las derivadas conmutan, los términos del tipo $\partial_{\mu}A_{\nu}$ se cancelan porque son simétricos y los términos del tipo $q_j^2A_{\mu}A_{\nu}$ se cancelan porque conmutan.
\\ \\
Por tanto, si solo usamos derivadas covariantes, tenemos todo contraído, el Lagrangiano es hermítico y, opcionalmente, usamos términos con $F_{\mu\nu}$, obtendremos invariantes Lorentz e invariantes gauge.\\ \\
Recordemos que los términos de masa del tipo $\frac{1}{2}m^2A_{\mu}A_{\nu}$ no son invariantes gauge, pero como necesitamos invariancia gauge para describir bosones sin masa, este término no influirá en la teoría.
\section{Electrodinámica Cuántica. QED}
La electrodinámica cuántica describe las interacciones de los fotones ($h=\pm1$ y $m=0$) y el resto de partículas elementales (leptones, quarks, etc.).
\subsection{Campos de Dirac}
Impondremos la simetría local $A_{\mu}(x)\to A_{\mu}(x)+\partial_{\mu}\alpha(x)$, considerando campos de Dirac cargados para campos masivos, haciendo después de los cálculos, el límite $m\to0$, obteniendo dos campos de Weyl. Estos campos de Dirac transforman como,
\begin{equation}
    \Psi_j(x)\to e^{iq_j\alpha(x)}\Psi_j(x)
\end{equation}
Vamos a proponer una acción invariante gauge, cuyo Lagrangiano hermítico más general (y sencillo), que sea invariante Lorentz (no necesariamente invariante gauge), será
\begin{equation}
    \mathscr{L}=-\frac{1}{4g^2}F_{\mu\nu}F^{\mu\nu}+\frac{\Theta}{32\pi^2}F_{\mu\nu}(*F^{\mu\nu})+\sum_j\left(\frac{1}{2}\bar{\Psi}_j(i\slashed{D}-m)\Psi_j+h.c.\right)
\end{equation}
donde $F_{\mu\nu}=\partial_{\mu}A_{\mu}+\partial_{\nu}A_{\mu}$, $*F^{\mu\nu}=\frac{i}{2}\epsilon^{\mu\nu\rho\sigma}F_{\rho\sigma}$ es el dual de $F^{\mu\nu}$, la derivada covariante actúa como $D_{\mu}\Psi_j=(\partial-iq_jA_{\mu})\Psi_j$ y el último término es el término de masa.\\ \\
Al integrar el Lagrangiano, para el tercer término usamos partes, obteniendo un término de superficie (que despreciamos) y otra integral, cuyo integrando se reduce a $\sum\limits_j\bar{\Psi}_j(i\slashed{D}-m^2)\Psi_j$ y también vemos que el segundo término es una derivada total, por lo que será un término de superficie que también despreciaremos. Por tanto, el Lagrangiano de QED será,
\begin{equation}
    \mathscr{L}^{QED}=-\frac{1}{4g^2}F_{\mu\nu}F^{\mu\nu}+\sum_j\bar{\Psi}_j(i\slashed{D}-m^2)\Psi_j
\end{equation}
Ahora vamos a hacer un reescalado del campo $A_{\mu}$ para quitar el término $1/g^2$ del Lagrangiano, tomamos
\begin{equation}
    A_{\mu}=g\bar{A}_{\mu}
\end{equation}
luego,
\begin{equation}
    \bar{F}_{\mu\nu}=\partial_{\mu}\bar{A}_{\nu}+\partial_{\nu}\bar{A}_{\mu};\hspace{7mm}D_{\mu}\Psi_j=(\partial_{\mu}-iq_jg\bar{A}_{\mu})
\end{equation}
Luego, tenemos el Lagrangiano reescalado siguiente,
\begin{equation}
    \mathscr{L}^{QED}=-\frac{1}{4}\bar{F}_{\mu\nu}\bar{F}^{\mu\nu}+\sum_j\bar{\Psi}_j(i\slashed{D}-m^2)\Psi_j
\end{equation}
y la transformación del campo reescalado será,
\begin{equation}
    \bar{A}_{\mu}\to\bar{A}_{\mu}+\frac{1}{g}\partial_{\mu}\alpha(x)
\end{equation}
\begin{note}
    Vemos que si usamos $\bar{A}_{\mu}$, el término $1/g$ no aparecerá en el Lagrangiano pero sí aparecerá en la transformación del campo. Mientras que si usamos el campo $A_{\mu}$, el término $1/g$ no aparecerá en la transformación, pero sí aparecerá en el Lagrangiano. Usaremos el campo $\bar{A}_{\mu}$ o el campo $A_{\mu}$ según nos convenga.
\end{note}
Para describir las reglas de Feynman usaremos el Lagrangiano $\mathscr{L}^{QED}(\bar{A}_{\mu},\dots)$, pero este Lagrangiano no es invariante gauge, por lo que aplicamos el \textit{fijado gauge}, como $\mathscr{L}^{QED}_{f.g.}=\mathscr{L}^{QED}-\frac{1}{2}(\partial_{\mu}\bar{A}^{\mu})^2$, que sí será invariante gauge.\footnote{Hemos tomado el gauge de Feynman, $\xi=1$.}
\subsubsection{Reglas de Feynman}
Las reglas de Feynman para los distintos propagadores, según su diagrama de Feynman, son
\begin{itemize}
\item \textbf{Propagador del fotón:}
\[\begin{fmffile}{cvacbc}
    \begin{fmfgraph*}(100,60)
        \fmfleft{l}
        \fmfright{r}
        \fmf{boson,label=$\xrightarrow{p}$}{l,r}
        \fmflabel{$\mu$}{l}
        \fmflabel{$\nu\hspace{5mm}\to\Pi_{\mu\nu}(p)=i\eta_{\mu\nu}\frac{1}{p^2+i\epsilon}$}{r}
    \end{fmfgraph*}
\end{fmffile}\]
\item \textbf{Propagador del campo de Dirac:}
\[\begin{fmffile}{iytsgifdn}
    \begin{fmfgraph*}(100,60)
        \fmfleft{l}
        \fmfright{r}
        \fmf{fermion,label=$\xrightarrow[j]{p}$}{l,r}
        \fmflabel{$\hspace{5mm}\to\tilde{S}_j(p)=\frac{i(\slashed{p}+m_j)}{p^2-m^2+i\epsilon}$}{r}
    \end{fmfgraph*}
\end{fmffile}\]
\item \textbf{Vértice fotón-2 fermiones:}
\[\begin{fmffile}{bvlisnlkd}
    \begin{fmfgraph*}(100,60)
        \fmfleft{l}
        \fmfright{r1,r2}
        \fmf{boson}{l,v}
        \fmf{fermion,label=$i$}{v,r1}
        \fmf{fermion,label=$j$}{r2,v}
        \fmflabel{$\mu$}{l}
        \fmflabel{$\hspace{10mm}\to i\delta_{ij}q_ig\gamma^{\mu}$}{v}
    \end{fmfgraph*}
\end{fmffile}\]
Este término, del vértice interno, sí deberíamos explicarlo un poco. La delta de Kronecker aparece debido a que consideramos dos campos distintos, la $g$ aparece del acoplamiento con el fotón y la $q_i$ representa la carga de las partículas, que será opuesta a la de las antipartículas.
\end{itemize}
\begin{example}
    Vamos a calcular la amplitud de colisión del proceso $e^-e^+\to\mu^-\mu^+$. El diagrama de Feynman a orden más bajo no trivial es el siguiente,
    \[\hspace{1mm}\]
    \[\begin{fmffile}{adflnjd}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l2,l1}
            \fmfright{r2,r1}
            \fmf{fermion,label=$e^-$}{l1,v1}
            \fmf{fermion,label=$e^+$}{v1,l2}
            \fmf{boson}{v1,v2}
            \fmf{fermion,label=$\mu^-$}{v2,r1}
            \fmf{fermion,label=$\mu^+$}{r2,v2}
            \fmflabel{$\mu$}{v1}
            \fmflabel{$\nu$}{v2}
            \fmflabel{$1$}{l1}
            \fmflabel{$2$}{l2}
            \fmflabel{$3$}{r1}
            \fmflabel{$4$}{r2}
        \end{fmfgraph*}
    \end{fmffile}\]
    Por las reglas de Feynman de los fermiones, sabemos que al electrón se le asocia la $u(s_1,p_1)$, al positrón se le asocia la $\bar{v}(s_2,p_2)$, al muón se le asocia la $\bar{u}(s_3,p_3)$ y al antimuón se le asocia la $v(s_4,p_4)$. Luego, siguiendo el sentido contrario de las flechas, la amplitud de colisión es
    \begin{equation}
i\mathscr{M}=G_4^{amp}=\left.i^2\delta_{ee}\delta_{\mu\mu}q_eq_{\mu}\brackets{\bar{v}(s_2,p_2)\gamma^{\mu}u(s_1,p_1)}\frac{-i\eta_{\mu\nu}}{(p_1+p_2)^2+i\epsilon}\brackets{\bar{u}(s_3,p_3)\gamma^{\nu}v(s_4,p_4)}\right|_{on-shell}
    \end{equation}
    Luego,
    \begin{equation}
        i\mathscr{M}=\left.-(-1)(-1)\brackets{\bar{v}(s_2,p_2)\gamma^{\mu}u(s_1,p_1)}\frac{-i\eta_{\mu\nu}}{(p_1+p_2)^2+i\epsilon}\brackets{\bar{u}(s_3,p_3)\gamma^{\nu}v(s_4,p_4)}\right|_{on-shell}
    \end{equation}
    y vemos que $p_3+p_4=p_1+p_2$, obteniendo la conservación del momento. (Falta ver si hay más diagramas de Feynman asociados a este orden)
\end{example}
\begin{note}
\begin{itemize}
\item Cuando tratamos con fotones pueden aparecer términos $+q$.
\item Cuando no conocemos la polarización de los fotones hacemos,
\begin{equation}
    \sum_{h=\pm}\mathcal{E}_{\mu}^{h}(p)^*\mathcal{E}_{\nu}^{h}(p)\to-\eta_{\mu\nu}+(P_{\mu}\dots+P_{\nu}\dots)
\end{equation}
\item Siempre podemos escribir la amplitud de colisión como,
\begin{equation}
    \mathscr{M}=\mathcal{E}_{\mu}\mathscr{M}^{\mu}
\end{equation}
y para que se cumpla la invariancia de Lorentz se debe satisfacer que,
\begin{equation}
    P_{\mu}\mathscr{M}^{\mu}=0
\end{equation}
De esta forma, se simplifica y elimina el último término (de antes).
\end{itemize}
\end{note}
\subsection{Campos escalares}
Estudiamos la electrodinámica cuántica en el caso en que las partículas cargadas son \textbf{campos escalares complejos} $\phi(x)$ en lugar de fermiones de Dirac.\\ \\
El lagrangiano invariante bajo simetría gauge local $U(1)$ es:
\begin{equation}
\mathcal{L} = -\frac{1}{4} F_{\mu\nu} F^{\mu\nu} + (D_\mu \phi)^\dagger (D^\mu \phi) - m^2 \phi^\dagger \phi,
\end{equation}
donde:
\begin{align*}
F_{\mu\nu} &= \partial_\mu A_\nu - \partial_\nu A_\mu, \\
D_\mu \phi &= (\partial_\mu - i q A_\mu) \phi.
\end{align*}
Este lagrangiano describe un campo escalar complejo con carga $q$ y masa $m$, acoplado a un fotón sin masa.
\subsubsection{Reglas de Feynman}
\begin{itemize}
    \item \textbf{Propagador del campo escalar $\phi$}:
    \[
    \begin{fmffile}{cabvcaj}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l}
            \fmfright{r}
            \fmf{scalar,label=$\xrightarrow{p}$}{l,r}
            \fmflabel{$\hspace{4mm}\to\frac{i}{p^2 - m^2 + i\varepsilon}$}{r}
        \end{fmfgraph*}
    \end{fmffile}
    \]

    \item \textbf{Propagador del fotón} (en gauge de Feynman con $\xi=1$):
    \[
    \begin{fmffile}{nachocan}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l}
            \fmfright{r}
            \fmf{boson}{l,r}
            \fmflabel{$\mu$}{l}
            \fmflabel{$\nu\hspace{4mm}\to-i \eta_{\mu\nu}\frac{1}{q^2 + i\varepsilon}$}{r}
        \end{fmfgraph*}
    \end{fmffile}
    \]

    \item \textbf{Vértice escalar-fotón (entrada/salida escalar y un fotón con índice $\mu$)}:
    \[\hspace{1mm}\]
    \[
    \begin{fmffile}{cabuh}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l}
            \fmfright{r1,r2}
            \fmf{boson}{l,v}
            \fmf{scalar,label=$p_1$}{r1,v}
            \fmf{scalar,label=$p_2$}{v,r2}
            \fmflabel{$\mu$}{l}
            \fmflabel{$i$}{r2}
            \fmflabel{$j$}{r1}
            \fmflabel{$\hspace{10mm}\to-i \delta_{ij}q_ig (p_1^{\mu} + p_2^{\mu})$}{v}
        \end{fmfgraph*}
    \end{fmffile}
    \]
    donde $p_1$ es el momento entrante del escalar, $p_2$ el saliente.

    \item \textbf{Vértice de dos fotones y dos escalares}:
    \[\begin{fmffile}{cabhbiu}
        \begin{fmfgraph*}(100,60)
            \fmfleft{l2,l1}
            \fmfright{r2,r1}
            \fmf{boson}{l1,v}
            \fmf{boson}{l2,v}
            \fmf{scalar,label=$p'$}{v,r1}
            \fmf{scalar,label=$p$}{r2,v}
            \fmflabel{$\hspace{10mm}\to2 i \delta_{ij}q_i^2 \eta^{\mu\nu}$}{v}
        \end{fmfgraph*}
    \end{fmffile}
    \]

    Este vértice aparece al expandir $(D_\mu \phi)^\dagger D^\mu \phi$ a segundo orden en $A_\mu$.
\end{itemize}
\begin{remark}
\[\hspace{1mm}\]
\begin{itemize}
    \item El modelo es renormalizable e invariante gauge.
    \item Las interacciones presentan vértices con 3 y 4 patas debido a la estructura cuadrática en el potencial gauge.
    \item En el límite clásico, este lagrangiano describe la interacción de una onda escalar con el campo electromagnético.
\end{itemize}
\end{remark}
\chapter{Modelo Estándar}
\section{Teorías de Yang-Mills}
Suponemos que tenemos un grupo de Lie $G$ compacto. Este grupo tiene un álgebra de Lie asociada $\mathfrak{g}$ (en un principio real, aunque se puede complexificar). Tenemos una base de generadores de este álgebra,
\begin{equation}
    \mathfrak{g}\to\curlybraces{T^a,a=1,\dots,M}
\end{equation}
cuyas reglas de conmutación son,
\begin{equation}
    \brackets{T^a,T^b}=if^{ab}_cT^c
\end{equation}
donde $f^{abc}$ se denomina \textbf{constante de estructura}. Un ejemplo sería el grupo $SU(2)$, cuyo álgebra es $su(2)$, y la constante de estructura se corresponde con $f^{ab}_c\equiv\mathscr{E}^{ab}_c$.\\ \\
Para la representación fundamental tenemos,
\begin{equation}
    Tr(T^a_FT^b_F)=\frac{1}{2}\delta^{ab}
\end{equation}
Vamos a mirar un campo $\phi$,
\begin{equation}
    \begin{array}{rcl}
        \phi & \to & \Omega_R\phi \\
        g & \mapsto & \Omega_R(g)
    \end{array}
\end{equation}
donde $g\in G$ y $\Omega_R(g)$ es la matriz de la representación $R$. Pero esto no representa una simetría, por lo que necesitaremos un campo Gauge, de la forma
\begin{equation}
    A_{\mu}:~~M_{\Psi}\to\mathfrak{g}
\end{equation}
donde $A_{\mu}$ es un elemento del álgebra de Lie, que podemos escribir como elementos de la base en forma matricial, tal que
\begin{equation}
    A_{\mu}(x)=A_{\mu}^a(x)T_F^a
\end{equation}
Por ejemplo, para el grupo $SU(2)$ es
\begin{equation}
    A_{\mu}=A_{\mu}^a\frac{\sigma^a}{2}
\end{equation}
La invariancia Gauge viene dada de la forma,
\begin{equation}
    A_{\mu}(x)\to\Omega_F(x)\brackets{A_{\mu}(x)+i\partial_{\mu}}\Omega_F^{-1}(x)
\end{equation}
donde $\Omega_F(x)$, $A_{\mu}(x)$ y $\Omega_F^{-1}(x)$ son matrices. La transformación adjunta es,
\begin{equation}
    \Omega_F(x)\brackets{A_{\mu}(x)}\Omega_F^{-1}(x)
\end{equation}
que no depende de $x$. Luego, tenemos entonces
\begin{equation}
    \begin{array}{rcl}
        \phi & \to & \Omega_R(x)\phi \\
        g & \mapsto & \Omega_R(g(x))
    \end{array}
\end{equation}
donde $\brackets{A_{\mu}}_R=A_{\mu}^aT^a_R$. Por tanto, la derivada covariante del campo es
\begin{equation}
    D_{\mu}\phi=(\partial_{\mu}-i\brackets{A_{\mu}}_R)\phi
\end{equation}
Luego, la derivada covariante del campo pasa a 
\begin{equation}
    D_{\mu}(x)\to\Omega_R(x)D_{\mu}\phi
\end{equation}
siendo covariante este término.\\ \\
Al ser grupos compactos, las representaciones son unitarias, por lo que los términos del tipo $D_{\mu}\phi^{\dagger}D^{\mu}\phi$ serán invariantes.\\ \\
Además, podemos calcular el conmutador de las derivadas covariantes como,
\begin{equation}
    \brackets{D_{\mu},D_{\nu}}\phi=-iF_{\mu\nu}\phi
\end{equation}
con $F_{\mu\nu}=\partial_{\mu}A_{\nu}-\partial_{\nu}A_{\mu}-i\brackets{A_{\mu},A_{\nu}}$, donde tenemos un término extra porque el grupo no es abeliano. En este caso, $F_{\mu\nu}$ no es invariante gauge, pero casi:
\begin{equation}
    F_{\mu\nu}(x)\to\Omega(x)F_{\mu\nu}(x)\Omega^{-1}(x)
\end{equation}
Luego, el producto queda
\begin{equation}
    F^{\mu\nu}F_{\mu\nu}\to\Omega(x)F^{\mu\nu}\cancelto{\mathds{1}}{\Omega^{-1}(x)\Omega(x)}F_{\mu\nu}(x)\Omega^{-1}(x)=\Omega(x)F^{\mu\nu}(x)F_{\mu\nu}(x)\Omega^{-1}(x)
\end{equation}
Por lo que podemos tomar este término normalizado,
\begin{equation}
    Tr(F^{\mu\nu}F_{\mu\nu})\left(\frac{-1}{2g^2}\right)
\end{equation}
que sí será invariante gauge.\\ \\
Tenemos la ecuación del movimiento siguiente,
\begin{equation}
    D_{\mu}F^{\mu\nu}=0
\end{equation}
Tenemos $M$ partículas de espín 1, pues tendremos tantas partículas como campos $A_{\mu}$, es decir, tendremos tantas como elementos del grupo.\\ \\
Podemos escribir $F_{\mu\nu}$ en función de los generadores tal que
\begin{equation}
    F_{\mu\nu}=F_{\mu\nu}^aT^a;\hspace{8mm}F_{\mu\nu}^a=\partial_{\mu}A_{\nu}^a-\partial_{\nu}A_{\mu}^a+f^{abc}A^b_{\mu}A^c_{\nu}
\end{equation}
El Lagrangiano de Yang-Mills queda como
\begin{equation}
    \mathscr{L}_{YM}=-\frac{1}{2g^2}Tr(F^{\mu\nu}F_{\mu\nu})=-\frac{1}{4g^2}\sum_a\left(\partial_{\mu}A_{\nu}^a-\partial_{\nu}A_{\mu}^a+f^{abc}A_{\mu}^bA_{\nu}^c\right)^2
\end{equation}
donde hemos usado la normalización de la traza y este Lagrangiano no es libre. Se puede tomar una base donde $f^{abc}$ es completamente antisimétrico.\\ \\
Tendremos acoplamientos del tipo:
\begin{multicols}{2}
\[\hspace{1mm}\]
\[\begin{fmffile}{sdhajd321n}
    \begin{fmfgraph*}(100,60)
        \fmfleft{l2,l1}
        \fmfright{r}
        \fmf{photon,label=$a$}{l1,v}
        \fmf{photon,label=$b$}{l2,v}
        \fmf{photon,label=$c$}{v,r}
        \fmflabel{$\mu$}{l1}
        \fmflabel{$\nu$}{l2}
        \fmflabel{$\sigma\hspace{4mm}\to igf^{abc}(P_{\mu}R_a\dots)$}{r}
    \end{fmfgraph*}
\end{fmffile}\]
\[\hspace{1mm}\]
\[\begin{fmffile}{ashncm}
    \begin{fmfgraph*}(100,60)
        \fmfleft{l1,l2}
        \fmfright{r1,r2}
        \fmf{photon}{l1,v}
        \fmf{photon}{l2,v}
        \fmf{photon}{v,r1}
        \fmf{photon}{v,r2}
        \fmflabel{$\hspace{14mm}\to ig^2ff\dots$}{v}
    \end{fmfgraph*}
\end{fmffile}\]
\end{multicols}
Podemos escribir,
\begin{equation}
    D_{\mu}\phi=(\partial_{\mu}-iA_{\mu}^aT_R^a)\phi
\end{equation}
que se podrán usar en el Lagrangiano de Yang-Mills para describir otro tipo de partículas.
\begin{note}
    Las teorías de Yang-Mills son teorías gauge no abelianas.
\end{note}
\begin{remark}
    Lo que hacemos para describir los Lagrangianos en esta teoría añadimos términos no covariantes al Lagrangiano y recuperamos la covariancia al final. Otra forma de hacerlo es añadir términos covariantes directamente al Lagrangiano, pero esto genera campos \textit{fantasmas} que son campos de fermiones escalares siendo puramente loops, pero como los loops no los discutimos en estos apuntes, esta forma de hacerlo la descartamos.
\end{remark}
\section{Modelo Estándar}
El Modelo Estándar (SM) es una teoría gauge en la que tenemos campos escalares, espinoriales y vectoriales, que corresponden a partículas sin masa de espín menor o igual a uno. Es una teoría que puede asemejarse con Relatividad General, que falla a gravedades muy fuertes. El Lagrangiano del Modelo Estándar es renormalizable, mientras que el de Relatividad General no lo es.\\ \\
El Modelo Estándar es una teoría que pertenece al grupo,
\begin{equation}
    SU(3)_C\times SU(2)_L\times U(1)_Y
\end{equation}
donde $C,L,Y$ son etiquetas (que no influyen en la definición de estos grupos), y $SU(3)$ se denomina \textbf{grupo del color}, tiene dimensión 8, es decir, tiene ocho generadores en la representación fundamental, que vienen dados por 
\begin{equation}
    T^a=\frac{\lambda^a}{2}
\end{equation}
donde $\lambda^a$ son las matrices de Gell-Mann y estos generadores tienen la normalización,
\begin{equation}
    tr(T^aT^b)=\frac{\delta^{ab}}{2}
\end{equation}
que nos fija las constantes de estructura, que pueden calcularse haciendo conmutadores. El grupo $SU(2)$ se denomina \textbf{grupo de isospín} y es de dimensión tres. El grupo $U(1)$ se denomina \textbf{grupo de hipercarga} y es de dimensión uno.
\begin{note}
    La dimensión de los grupos del tipo $SU(n)$ viene dada por,
    \begin{equation}
        dim SU(n)=n^2-1
    \end{equation}
\end{note}
Los campos gauge de estos grupos serán, $G_{\mu}$, $W_{\mu}$ y $B_{\mu}$ que pertenecen a $SU(2)$, $SU(2)$ y $U(1)$, respectivamente y se introducen en el Lagrangiano en forma matricial, es decir, $G_{\mu\nu}$, $W_{\mu\nu}$ y $B_{\mu\nu}$. La parte del Lagrangiano del Modelo Estándar puramente Gauge es la siguiente,
\begin{equation}
    \mathscr{L}_{SM}^{gauge}=-\frac{1}{2g_3^2}tr(G_{\mu\nu}G^{\mu\nu})-\frac{1}{2g_2^2}tr(W_{\mu\nu}W^{\mu\nu})-\frac{1}{4g_1^2}tr(B_{\mu\nu}B^{\mu\nu})
\end{equation}
donde las constantes de normalización se suelen escribir como, $g_3\equiv g_S$, $g_2\equiv g$ y $g_1\equiv g'$.\\ \\
Este Lagrangiano describe bosones sin masa con helicidad $\pm1$. El primer término se corresponde con ocho bosones $G$, denominados \textbf{gluones} y no es un término libre porque $SU(3)$ no es abeliano, luego tendremos interacciones entre los campos $G_{\mu\nu}$. El segundo término se corresponde con tres \textbf{bosones }$\mathbf{W}$ y tampoco es un término libre porque $SU(2)$ no es abeliano, luego tendremos interacciones entre los campos $W_{\mu\nu}$. El tercer término corresponde con un \textbf{bosón }$\mathbf{B}$, siendo un término libre, porque $U(1)$ sí es abeliano, luego no tendremos interacciones entre los campos $B_{\mu\nu}$.\\ \\
Podemos usar teoría de representaciones de los grupos para nuestro grupo del Modelo Estándar, $SU(3)\times SU(2)\times U(1)$, para simplificar la notación. Usaremos la representación siguiente,
\begin{equation}
    (R_3,R_2)_Y
\end{equation}
donde $R_3$ se corresponde con la representación del grupo $SU(3)$ y tomará los valores $R_3\in\curlybraces{1,3}$, que corresponde a un singlete y a un triplete de $SU(3)$, respectivamente. $R_2$ corresponde a la representación de $SU(2)$ y tomará los valores $R_2\in\curlybraces{1,2}$, que corresponde a un singlete y a un doblete de $SU(2)$, respectivamente. La $Y$ corresponde a la  representación de $U(1)$ que se relaciona con la hipercarga.\\ \\
Para seguir describiendo el Lagrangiano del Modelo Estándar nos falta incluir los campos escalares y los campos fermiónicos:
\begin{itemize}
    \item \textbf{Escalares:} La representación de los campos escalares es $H=(1,2)_{1/2}$, que se corresponde con un singlete de $SU(3)$, un doblete de $SU(2)$ y una hipercarga $Y=1/2$, que corresponde a campos complejos, porque $Y\neq0$. Esta representación también se denomina \textbf{representación de Higgs}.
    \item \textbf{Fermiones:} Para los fermiones tenemos tres familias ($i=1,2,3$), pero las representaciones son las mismas. Usaremos los subíndices $L$ y $R$ para decir si están en la representación $LH$ o en la $RH$. Podemos dividir los campos fermiónicos en dos grandes grupos:
    \begin{itemize}
        \item \textbf{Campos de quarks:} son fermiones donde la familia $i=1$ corresponde con los quarks up y down, la familia $i=2$ corresponde con los quarks charm y strange, y la familia $i=3$ corresponde con los quarks top y bottom. Vienen dados por,
        \begin{equation}
            q_L^i=(3,2)_{1/6}=\begin{pmatrix}
                u_L^i\\
                d_L^i
            \end{pmatrix};\hspace{6mm}u_R^i=(3,1)_{2/3};\hspace{6mm}d_R^i=(3,1)_{-1/3}
        \end{equation}
        donde el primer campo lo podemos separar porque los dobletes de $SU(2)$ son separables, pero los tripletes de $SU(3)$ y los singletes de $SU(2)$ no lo son.
        \item \textbf{Campos de leptones:} son fermiones donde la familia $i=1$ corresponde con los leptones electrónicos (electrón y neutrino electrónico), la familia $i=2$ corresponde con los leptones muónicos (muón y neutrino muónico) y la familia $i=3$ corresponde con los leptones tau (tau y neutrino tau). Vienen dados por,
        \begin{equation}
            l_L^i=(1,2)_{-1/2}=\begin{pmatrix}
                \nu_L^i\\
                e_L^i
            \end{pmatrix};\hspace{6mm}e_R^i=(1,1)_{-1}
        \end{equation}
        donde hemos separado el doblete de $SU(2)$ y $\nu_L^i$ se denomina \textbf{campo de neutrinos}. Cabe recalcar que el campo de neutrinos $RH$, $\nu_R^i$, no existe en el Modelo Estándar.
    \end{itemize}
    Vemos que los quarks transforman en el grupo $SU(3)$ porque tienen tripletes de este grupo, mientras que los leptones al ser singletes no transformarán en este grupo, por lo que los quarks interaccionarán con los gluones, mientras que los leptones no lo harán. Aquellos campos de quarks o leptones que sean singletes de $SU(2)$ no interaccionarán tampoco con los bosones $W$.
\end{itemize}
\begin{remark}
    Tenemos una teoría quiral susceptible a presentar anomalías, pero gracias al valor de los números cuánticos e hipercarga, estas anomalías se cancelan, obteniendo una teoría consistente y bien definida. Esto no es trivial.
\end{remark}
Al Lagrangiano del Modelo Estándar le podemos añadir el término de los campos escalares y fermiónicos, denominado término de materia, que vendrá dado por,
\begin{equation}
    \mathscr{L}_{SM}^{matter}=D_{\mu}\phi^{\dagger}D^{\mu}\phi-\mu^2\phi^{\dagger}\phi-\lambda(\phi^{\dagger}\phi)^4+\sum_f f^{\dagger}\bar{\sigma}^{\mu}\partial_{\mu}f+\mathscr{L}^{Yuk}
\end{equation}
donde $D_{\mu}$ es la derivada covariante, el término de $\mu^2$ es el término masivo de las partículas escalares, el sumatorio de $f$ tendrá $15$ sumandos, correspondiente a los 5 tipos de quarks y leptones, multiplicado por las tres familias de cada uno, donde $f\in\curlybraces{q_L^i,l_L^i,(u_R^{\dagger})^i,(d_r^{\dagger})^i,(e_R^{\dagger})^i}$, y el término $\mathscr{L}^{Yuk}$ se corresponde con el término de interacción de Yukawa, correspondiente a la interacción entre los campos escalares y fermiónicos y viene dado por,
\begin{equation}
    \mathscr{L}^{Yuk}=-\lambda^{ij}_d(q_L^{\dagger})^i\phi d_R^j-\lambda_u^{ij}(q_L^{\dagger})^i\tilde{\phi}u_R^j-\lambda_e^{ij}(l_L^{\dagger})^i\phi e_R^j
\end{equation}
 donde $\tilde{\phi}=\epsilon\phi^*=i\sigma_2\phi^*$.\\ \\
 Luego, el Lagrangiano del Modelo Estándar viene dado por,
 \begin{equation}
     \begin{array}{rl}
         \mathscr{L}_{SM} &=\mathscr{L}_{SM}^{gauge}+\mathscr{L}_{SM}^{matter}= \\ \\
          & =-\frac{1}{2g_S^2}tr(G_{\mu\nu}G^{\mu\nu})-\frac{1}{2g^2}tr(W_{\mu\nu}W^{\mu\nu})-\frac{1}{4g'^2}tr(B_{\mu\nu}B^{\mu\nu})+\\ \\
          &+D_{\mu}\phi^{\dagger}D^{\mu}\phi-\mu^2\phi^{\dagger}\phi-\lambda(\phi^{\dagger}\phi)^4+\sum\limits_f f^{\dagger}\bar{\sigma}^{\mu}\partial_{\mu}f-\\ \\
          &-\lambda^{ij}_d(q_L^{\dagger})^i\phi d_R^j-\lambda_u^{ij}(q_L^{\dagger})^i\tilde{\phi}u_R^j-\lambda_e^{ij}(l_L^{\dagger})^i\phi e_R^j
     \end{array}
 \end{equation}
Este Lagrangiano corresponde a la teoría sin gravedad, pero puede añadirse el término gravitatorio que viene dado por,
\begin{equation}
    \mathscr{L}_{SM}^{grav}=cte\sqrt{-g}R
\end{equation}
donde $\sqrt{-g}$ es la raíz del determinante negativo de la métrica $g_{\mu\nu}$, $R$ es el escalar de Ricci y tenemos una constante de normalización.
\begin{remark}
    Todo el mundo sabe que existen cuatro fuerzas (o interacciones) fundamentales en la naturaleza, que son la gravitatoria, la electromagnética, la nuclear fuerte y la nuclear débil. Pero en este Lagrangiano se introduce una interacción nueva (empíricamente probada) que es la interacción de Yukawa, por lo que esta interacción sería la quinta fuerza de la naturaleza.
\end{remark}
Este Lagrangiano representa dos partículas con espín cero, los bosones gauge y los fermiones de Weyl (sin masa), además de todas sus antipartículas.\\ \\
Los bosones de gauge median interacciones a largo alcance, pues no tienen masa, cosa que no cuadra con las observaciones pero se puede solucionar gracias a que los quarks son estados ligados y no se pueden observar libres en la naturaleza. Los fermiones sin masa tampoco cuadran con las observaciones, por lo que se soluciona añadiendo el mecanismo de Higgs. Además, los estados ligados de los quarks son sin color y corresponden con los hadrones (mesones, bariones, etc.) Lo explicamos mejor en la siguiente nota:
\[\hspace{1mm}\]
\[\hspace{1mm}\]
\begin{note}
Este Lagrangiano describe los ingredientes fundamentales del Modelo Estándar:

\begin{itemize}
    \item Un campo escalar complejo de espín cero en la representación $(1,2)_{1/2}$, conocido como \textbf{campo de Higgs}. Esta representación se denomina así porque permite explicar cómo las partículas adquieren masa a través de la ruptura espontánea de simetría.
    
    \item Bosones gauge sin masa, asociados a los grupos $SU(3)_C$, $SU(2)_L$ y $U(1)_Y$, que son responsables de mediar las tres interacciones fundamentales incluidas en el Modelo Estándar: la interacción fuerte, la débil y la electromagnética (tras la mezcla de $W^3$ y $B$).
    
    \item Fermiones de Weyl (quirales) sin masa: estos representan a los quarks y leptones en su versión más básica, organizados en representaciones izquierdas y derechas que no son equivalentes, lo que da lugar al carácter quiral del Modelo Estándar. Naturalmente, también se incluyen sus antipartículas.
\end{itemize}

Ahora bien, aunque este Lagrangiano está bien construido desde el punto de vista teórico, no reproduce por sí solo todos los fenómenos observados en la naturaleza. Por ejemplo:

\begin{itemize}
    \item Los bosones gauge $W^\pm$ y $Z$ se predicen inicialmente sin masa, lo cual entra en conflicto con los datos experimentales. Esto se soluciona mediante el \textbf{mecanismo de Higgs}, que rompe espontáneamente la simetría electrodébil $SU(2)_L \times U(1)_Y$ hacia el grupo electromagnético $U(1)_{\text{em}}$. Como resultado, algunas partículas adquieren masa (de forma natural y sin perder renormalizabilidad), mientras que otras, como el fotón y los gluones, permanecen sin masa.

    \item Del mismo modo, los fermiones tampoco tienen masa en el Lagrangiano original. Para remediarlo, se introducen términos de \textbf{acoplamiento de Yukawa} entre los fermiones y el campo de Higgs, los cuales generan masas proporcionales al valor esperado en el vacío del campo escalar.

    \item Por último, los quarks, aunque aparecen en el Lagrangiano como partículas fundamentales, nunca se detectan de forma aislada. Esto se debe a que están sometidos a la \textbf{interacción fuerte}, que los mantiene confinados en estados ligados sin color, conocidos como \textbf{hadrones} (como los mesones y bariones). Esta propiedad, llamada \textit{confinamiento}, es una característica esencial de la cromodinámica cuántica (QCD).
\end{itemize}

En resumen, el Lagrangiano del Modelo Estándar está formulado inicialmente en términos de partículas sin masa y simetrías gauge, pero reproduce con éxito la física observada gracias al campo de Higgs, los acoplamientos de Yukawa y las propiedades no perturbativas del grupo $SU(3)_C$.
\end{note}
\begin{note}
    Las interacciones fuertes son de corto alcance y son las que hacen que los quarks formen hadrones.
\end{note}
\section{Mecanismo de Higgs}
El mecanismo de Higgs será el responsable de otorgar masa a los fermiones que en Lagrangiano del Modelo Estándar nos salían sin masa.\\ \\
Primero vamos a tratar con un modelo más simple, denominado \textbf{modelo de Higgs abeliano} y usaremos el Lagrangiano siguiente,
\begin{equation}
    \mathscr{L}=-\frac{1}{4}F_{\mu\nu}F^{\mu\nu}+D_{\mu}\phi^{\dagger}D^{\mu}\phi-V(|\phi|^2)
\end{equation}
con $D_{\mu}\phi=(\partial_{\mu}-igA_{\mu})\phi$ tomando de carga la unidad y $\phi$ es un campo escalar complejo.\\ \\
Para esta teoría los campos escalares transforman como,
\begin{equation}
    \phi(x)\to e^{i\alpha(x)}\phi(x)
\end{equation}
teniendo la simetría local de $U(1)$. También tendremos la transformación gauge de los campos $A_{\mu}$, tal que
\begin{equation}
    A_{\mu}(x)\to A_{\mu}(x)+\frac{1}{g}\partial_{\mu}\alpha(x)
\end{equation}
Por otro lado, el potencial $V(|\phi|^2)$ tendrá distintas formas, la más simple es la que se muestra en la figura \ref{fig8-1} siguiente,
\begin{Figura}
    \centering
    \includegraphics[width=0.5\textwidth]{imagenes/Fig8-1.png}
    \captionof{figure}{Forma del potencial $V(|\phi|^2)$.}
    \label{fig8-1}
\end{Figura}
donde solo tomamos la rama positiva porque tenemos $V(|\phi|^2)=\mu^2|\phi|^2$. Vemos que este potencial tiene una simetría de revolución, gracias a la simetría $U(1)$, y podemos hacer el cambio de variable $y=|\phi|^2$, obteniendo el potencial siguiente,
\begin{Figura}
    \centering
    \includegraphics[width=0.5\textwidth]{imagenes/Fig8-2.png}
    \captionof{figure}{Forma del potencial $V(y)$.}
    \label{fig8-2}
\end{Figura}
Por lo que este potencial tendrá un mínimo en $y=0$, siendo el estado fundamental del sistema, y vemos que en este punto, $\Braket{\Omega|\phi(y=0)|\Omega}=0$. Para este caso, la masa vendrá dada por
\begin{equation}
   m^2= \frac{1}{2}\left.\frac{\partial^2V}{\partial\phi^2}\right|_{\phi=\phi_0}
\end{equation}
donde $\phi_0$ es el mínimo del potencial, para nuestro caso, $y=0$.\\ \\
Pero este potencial puede tener más formas. Vamos a considerar ahora el caso donde el potencial $V(|\phi|^2)$ tenga forma de \textit{sombrero mexicano},
\begin{Figura}
    \centering
    \includegraphics[width=0.5\textwidth]{imagenes/Fig8-3.png}
    \captionof{figure}{Forma del potencial tipo sombrero mexicano.}
    \label{fig8-3}
\end{Figura}
que viene dado por,
\begin{equation}
    V(|\phi|^2)=\lambda\left(|\phi|^2-\frac{v^2}{2}\right)^2
\end{equation}
Para este potencial se produce un fenómeno denominado \textbf{ruptura espontánea de la simetría (global)}, obteniendo que el estado de vacío no es simétrico. Esto se debe a que tenemos dos mínimos de potencial, que los tomaremos en $|\phi_0|=\frac{v^2}{2}$, con $v>0$., luego, $\phi_0=\frac{v}{\sqrt{2}}e^{i\varphi}$. Por tanto, para este caso, los mínimos ya no representan el estado fundamental del sistema, y por consecuencia, tenemos que
\begin{equation}
    \Braket{\Omega|\phi_{0}|\Omega}=\frac{v}{\sqrt{2}}e^{i\varphi}
\end{equation}
donde $\varphi$ es el ángulo de revolución del potencial, por lo que el vacío será una circunferencia, obteniendo un vacío continuo degenerado.\\ \\
Vamos a suponer ahora que tenemos una simetría global de $U(1)$, en vez de que sea simetría local. Gracias a esto, podemos tomar un único punto del vacío, por lo que tomaremos $\varphi=0$, tal que
\begin{equation}
    \Braket{\Omega|\phi_0|\Omega}=\frac{v}{\sqrt{2}}
\end{equation}
pero por culpa de tomar un único punto del vacío perderemos la invariancia bajo simetría. \\ \\
Para ver esto, tomaremos la transformación $U_{\alpha}$ que implementa la simetría global $U(1)$, tal que
\begin{equation}
    \Braket{\Omega|U^{\dagger}_{\alpha}\underbrace{U_{\alpha}\phi_0U_{\alpha}}_{\phi_0e^{i\alpha}}U^{\dagger}_{\alpha}|\Omega}=\Braket{\Omega|U_{\alpha}^{\dagger}\phi_0U_{\alpha}|\Omega}e^{i\alpha}
\end{equation}
Luego, como la transformación $U_{\alpha}$ implementa una simetría global, podemos suponer que el vacío $\ket{\Omega}$ es invariante bajo esta transformación, es decir,
\begin{equation}
    U_{\alpha}\ket{\Omega}=\ket{\Omega};\hspace{6mm}\bra{\Omega}U_{\alpha}^{\dagger}=\bra{\Omega}
\end{equation}
Luego, tenemos
\begin{equation}
    \Braket{\Omega|\phi_0|\Omega}=\Braket{\Omega|\phi_0|\Omega},\forall\alpha
\end{equation}
Entonces, esta ecuación se cumple solo si $\Braket{\Omega|\phi_0|\Omega}=0$.\\ \\
Ahora, usando lógica, sabemos que si $A$ implica $B$, $A\Rightarrow B)$, entonces no-$A$ implica no-$B$, $(\neg A\Rightarrow\neg B)$. Por tanto, como en nuestro caso tenemos que $\Braket{\Omega|\phi_0|\Omega}\neq0$ esto implicará que $U_{\alpha}\ket{\Omega}\neq\ket{\Omega}$, es decir, nuestro vacío no es invariante bajo la transformación $U_{\alpha}$, por lo que perdemos la invariancia bajo la simetría global $U(1)$.\\ \\
Vemos que si $\ket{\Omega}$ es el vacío de Fock, sí o sí debemos tener que $\phi\ket{\Omega}=0$, cosa que en nuestro caso no se cumple. Además, si consideramos que $\ket{{\Omega}}$ es el vacío físico, sí tendríamos que $\phi\ket{\Omega}\neq0$, pero la distancia de separación entre el cero y el valor obtenido por el vacío físico sería infinitesimal, y no como en nuestro caso, que es $v/\sqrt{2}$, por tanto, tenemos también una contradicción.\\ \\
La solución a esto será reescribir el campo complejo $\phi$ en función de dos campos reales, tal que
\begin{equation}
    \phi(x)=\frac{1}{\sqrt{2}}\left(v+h(x)\right)e^{i\pi(x)/v}
\end{equation}
donde $h(x)$ y $\pi(x)$ son los campos escalares reales, y hemos supuesto que el campo es invertible, es decir, $h(x)\neq-v$.\\ \\
Aplicando teoría de perturbaciones en el punto del vacío que hemos tomado, obtenemos que
\begin{equation}
    \Braket{\Omega|h(x)|\Omega}=0;\hspace{6mm}\Braket{\Omega|\pi(x)|\Omega}
\end{equation}
y las transformaciones de estos campos, bajo la simetría global $U(1)$ son,
\begin{equation}
    h\to h\hspace{8mm}\pi\to\pi+\alpha
\end{equation}
Luego, sustituimos la expresión de $\phi(x)$ en el Lagrangiano, veamos primero el término de las derivadas covariantes,
\begin{equation}\small
    \begin{array}{rl}
        \mathscr{L} & \propto D_{\mu}\left[\frac{1}{\sqrt{2}}\left(v+h(x)\right)e^{i\pi(x)/v}\right]D^{\mu}\brackets{\frac{1}{\sqrt{2}}\left(v+h(x)\right)e^{-i\pi(x)/2}}= \\ \\
         & =\frac{1}{2}\curlybraces{e^{i\pi/v}D_{\mu}(v+h(x))+(v+h(x))D_{\mu}e^{i\pi/v}}\curlybraces{e^{-i\pi/v}D^{\mu}(v+h(x))+(v+h(x))D^{\mu}e^{-i\pi/v}}=\\ \\
         &=\frac{1}{2}\curlybraces{e^{i\pi/v}D_{\mu}h(x)+(v+h(x))\frac{i}{v}e^{i\pi/v}D_{\mu}\pi(x)}\curlybraces{e^{-i\pi/v}D^{\mu}h(x)-\frac{i}{v}(v+h(x))e^{-i\pi/v}D^{\mu}\pi(x)}=\\ \\
         &=\frac{1}{2}\curlybraces{D_{\mu}h(x)D^{\mu}h(x)-\cancel{\frac{i}{v}(v+h(x))D_{\mu}h(x)D^{\mu}\pi(x)}+\cancel{\frac{i}{v}(v+h(x))D_{\mu}\pi(x)D^{\mu}h(x)}+\frac{(v+h(x))^2}{v^2}D_{\mu}\pi(x)D^{\mu}\pi(x)}=\\ \\
         &=\frac{1}{2}\curlybraces{D_{\mu}h(x)D^{\mu}h(x)+\frac{(v+h(x))^2}{v^2}D_{\mu}\pi(x)D^{\mu}\pi(x)}
    \end{array}
\end{equation}
donde anulamos los términos cruzados porque 
\begin{equation}
    D_{\mu}h(x)D^{\mu}\pi(x)=\eta^{\mu\nu}D^{\nu}h(x)\eta_{\mu\nu}D_{\mu}\pi(x)=\underbrace{\eta^{\mu\nu}\eta_{\mu\nu}}_{\mathds{1}}D^{\nu}h(x)D_{\nu}\pi(x)=D_{\nu}\pi(x)D^{\nu}h(x)\equiv D_{\mu}\pi(x)D^{\mu}h(x)
\end{equation}
donde usamos que las derivadas conmutan.\\ \\
Veamos ahora el término del potencial del Lagrangiano,
\begin{equation}
    \begin{array}{rl}
        \mathscr{L} & \propto V(|\phi|^2)=\lambda\left(|\phi|^2-\frac{v^2}{2}\right)^2= \\ \\
         & =\lambda\left(\brackets{\frac{1}{2}(v+h(x))e^{i\pi(x)/v}}\brackets{\frac{1}{\sqrt{2}}(v+h(x))e^{-i\pi(x)/v}}^*-\frac{v^2}{2}\right)^2=\\ \\
         &=\frac{\lambda}{4}\left[(v+h(x))^2\cancel{e^{i\pi(x)/v}}\cancel{e^{-i\pi(x)/v}}-v^2\right]^2=\\ \\
         &=\frac{\lambda}{4}\left[(v+h(x))^2-v^2\right]^2
    \end{array}
\end{equation}
Luego, tenemos el Lagrangiano,
\begin{equation}
    \mathscr{L}=-\frac{1}{4}F_{\mu\nu}F^{\mu\nu}+\frac{1}{2}\curlybraces{D_{\mu}h(x)D^{\mu}h(x)+\frac{(v+h(x))^2}{v^2}D_{\mu}\pi(x)D^{\mu}\pi(x)}+\frac{\lambda}{4}\left[(v+h(x))^2-v^2\right]^2
\end{equation}
donde vemos que el campo $h(x)$ representa partículas escalares masivas, porque tenemos un término de masa, mientras que el campo $\pi(x)$ representa partículas escalares sin masa, porque solo aparece en las derivadas.\\ \\
El Teorema de Goldstone nos dice que siempre que exista rotura de simetría global, aparecerán partículas escalares sin masa, denominadas \textbf{bosones de Goldstone}, en cada dirección donde se rompa la simetría global.\\ \\
Como el Lagrangiano nuestro no tiene simetría global (la hemos supuesto), sino que presenta simetría local, la transformación de los campos es,
\begin{equation}
    h(x)\to h(x);\hspace{8mm}\pi(x)\to\pi(x)+\alpha(x)
\end{equation}
Por lo que podemos tomar el \textbf{gauge unitario} $\pi(x)=0$, por lo que no aparecerán los bosones de Goldstone, pues,
\begin{equation}
    \phi=\frac{1}{\sqrt{2}}(v+h(x))e^{i\pi(x)/2}\xrightarrow{\pi(x)=0}\phi=\frac{1}{\sqrt{2}}(v+h(x))
\end{equation}
Luego, debemos volver a calcular el Lagrangiano inicial tomando ahora la simetría local, que podemos expandir con $D_{\mu}\phi=(\partial_{\mu}-igA_{\mu})\phi$, tal que
\begin{equation}
\begin{array}{rl}
     
    D_{\mu}\phi D^{\mu}\phi&=|D_{\mu}\phi|^2=|\partial_{\mu}\phi-igA_{\mu}\phi|^2=(\partial_{\mu}\phi)^2+g^2(A_{\mu}\phi)^2=  \\ \\
     & =\frac{1}{2}\brackets{[\partial_{\mu}(v+h(x))]^2+g^2(v+h(x))^2A_{\mu}A^{\mu}}=\\ \\
     &\frac{1}{2}\brackets{\partial_{\mu}h(x)\partial^{\mu}h(x)+g^2v^2A_{\mu}A^{\mu}+2g^2vh(x)A_{\mu}A^{\mu}+g^2h(x)^2A_{\mu}A^{\mu}}
\end{array}
\end{equation}
Luego, el Lagrangiano queda,
\begin{equation}
    \mathscr{L}=-\frac{1}{4}F_{\mu\nu}F^{\mu\nu}+\frac{1}{2}\partial_{\mu}h(x)\partial^{\mu}h(x)+\frac{g^2v^2}{2}A_{\mu}A^{\mu}+g^2vh(x)A_{\mu}A^{\mu}+\frac{g^2}{2}h(x)^2A_{\mu}A^{\mu}+\frac{\lambda}{4}\left[(v+h(x))^2-v^2\right]^2
\end{equation}
donde le término $\frac{g^2v^2}{2}A_{\mu}A^{\mu}$ es el término masivo del bosón gauge $A_{\mu}$, denominado término masivo de Procca, y representa partículas masivas de espín 1 y seguimos teniendo el término masivo de $h(x)$ que representa partículas masivas de espín 0.
\begin{note}
    Aunque el vacío no sea invariante, el Lagrangiano sigue siendo invariante gauge.
\end{note}
Podemos notar que los grados de libertad son los mismos que teníamos antes de hacer $\pi(x)=0$, dado que los grados de libertad de $\pi(x)$ se convierten en los grados de libertad de la componente longitudinal de la partícula masiva de espín 1.\\ \\
Vamos a pasar ahora al Modelo Estándar, Tenemos que los escalares $H\in(1,2)_{1/2}$ forman un duplete de $SU(2)$. El Lagrangiano tiene el término,
\begin{equation}
    \mathscr{L}\supset-\mu^2H^{\dagger}H-\lambda(H^{\dagger}H)^2
\end{equation}
donde si tomamos $\mu^2<0$ tenemos el potencial tipo sombrero mexicano, por lo que tenemos una rotura de la simetría local, pues el Lagrangiano del Modelo Estándar presenta simetría local $U(1)$. Luego, tenemos
\begin{equation}
    \Braket{\Omega|H|\Omega}=\frac{v}{\sqrt{2}}e^{ie_iT^i}\begin{pmatrix}
        0\\
        1
    \end{pmatrix}
\end{equation}
y como tenemos simetría local, podemos tomar un único punto del vacío, 
\begin{equation}
    \Braket{\Omega|H|\Omega}=\frac{v}{\sqrt{2}}\begin{pmatrix}
        0\\
        1
    \end{pmatrix}
\end{equation}
Por tanto, para solucionar las inconsistencias con el vacío, reescribimos el campo $H(x)$ como,
\begin{equation}
    H(x)=\frac{v}{\sqrt{2}}(v+h(x))e^{i\pi_a(x)T^a/v}\begin{pmatrix}
        0\\
        1
    \end{pmatrix}
\end{equation}
donde $\pi_a(x)$ es un campo real y $h(x)$ es también un campo real, que corresponde con el \textbf{campo de Higgs}, cuya partícula asociada será el \textbf{bosón de Higgs}.\\ \\
Este vacío presenta una invariancia a la simetría global para $SU(3)\times U(1)_Q$, donde $U(1)_Q$ es subgrupo de $SU(2)\times U(1)$, luego, tendremos bosones de Goldstone, que vendrán dados en la dirección donde se rompe la simetría global, que es
\begin{equation}
    \frac{SU(2)\times U(1)}{U(1)_Q}
\end{equation}
obteniendo tres tipos de bosones, los \textbf{bosones }$\mathbf{W^{\pm}_{\mu}}$ y el \textbf{bosón }$\mathbf{Z_{\mu}}$, que serán bosones masivos que median las interacciones débiles (de los fermiones).\\ \\
Recordando que los términos de Yukawa son del tipo,
\begin{equation}
    \lambda_e^{ij}(l_L^{\dagger})^i\phi e_R^j
\end{equation}
sustituyendo la reescritura de $\phi$,
\begin{equation}
    \lambda_e^{ij}(l_L^{\dagger})^i\brackets{\frac{1}{\sqrt{2}}(v+h(x))e^{i\pi_aT^a/v}\begin{pmatrix}
        0\\
        1
    \end{pmatrix}}e_R^j=\frac{\lambda_e^{ij}}{\sqrt{2}}\brackets{v(l_L^{\dagger})^ie_R^j+(l_L^{\dagger})^ih(x)e_R^j}e^{i\pi_aT^a}\begin{pmatrix}
        0\\
        1
    \end{pmatrix}
\end{equation}
donde vemos que tenemos un término $(l_L^{\dagger})^ie_R^j$, luego, como tenemos un campo fermiónico \textit{left} multiplicando a un campo fermiónico \textit{right}, obtenemos un término de masa, por lo que obtenemos la masa de los fermiones. De hecho, la interacción de cada fermión es proporcional a su masa. Además, como no tenemos el campo $\nu_R$, no podremos obtener términos masivos para los neutrinos, luego los neutrinos serán los únicos fermiones sin masa del Modelo Estándar.


\appendix
\chapter{Espacios topológicos}
\label{ApendiceA}
\lhead{Ap\'endice A. \emph{Espacios topológicos}}
\section{Espacios Topológicos}
El principal interés de explicar los Espacios Topológicos surge del hecho de que el espacio-tiempo en Relatividad General tiene la estructura de un espacio topológico, además, la estructura de los grupos de Lie que estudiamos en QFT tienen también estructura de espacio topológico. En este apéndice recogemos varias definiciones y teoremas clave relativos a los espacios topológicos. 
\begin{definition}
    Un \textit{espacio topológico} $(X, \mathcal{T})$ se trata de un conjunto $X$ con una colección $\mathcal{T}$ de subconjuntos de $X$ que satisface las siguientes propiedades:
    \begin{enumerate}
        \item La unión de un colección arbitraria finita o infinita de subespacios pertenecientes a $\mathcal{T}$, también pertenece a $\mathcal{T}$, es decir, si $O_{\alpha}\in\mathcal{T}$ para todo $\alpha$, entonces $\bigcup\limits_{\alpha}O_{\alpha}\in\mathcal{T}$.
        \item La intersección de un número finito de subespacios de $\mathcal{T}$ pertenece también a $\mathcal{T}$, es decir, si $O_1,\dots O_n\in\mathcal{T}$, entonces $\bigcap\limits_{i=1}^{n}O_i\in\mathcal{T}$.
        \item El conjunto completo $X$ y el conjunto vacío $\emptyset$, pertenecen a $\mathcal{T}$.
    \end{enumerate}
    \label{def-A-0-1}
\end{definition}
\begin{note}
    $\mathcal{T}$ es referido a una \textit{topología} sobre $X$, y los subconjuntos de $X$, que se enumeran en la colección $\mathcal{T}$, se denominan \textit{conjuntos abiertos}.
\end{note}
Cualquier conjunto $X$ se puede convertir fácilmente en un espacio topológico tomando $\mathcal{T}=\curlybraces{\text{todos los subconjuntos de }X}$, denominado \textit{topología discreta}, o tomando $\mathcal{T}=\curlybraces{X,\emptyset}$, denominado \textit{topología indiscreta}.\\
Un ejemplo mucho más interesante es el espacio topológico que se obtiene tomando $\mathcal{T}=\mathbb{R}$, el conjunto de los números reales, y definiendo $\mathcal{T}$ para que esté formado por todos los subconjuntos de $\mathbb{R}$, que puede ser expresado como la unión de intervalos abiertos $(a,b)$. Así, tomando $\mathcal{T}$ de esta forma sobre $\mathbb{R}$, un intervalo abierto es un conjunto abierto; históricamente, este ejemplo es la razón por la que la terminología de 'conjunto abierto' se usa en la discusión de un espacio topológico abstracto.\\ \\
También podemos definir topologías inducidas, pues la definición de espacio topológico nos permite jugar con los subconjuntos de subconjuntos.
\begin{definition}
    Si $(X, \mathcal{T})$ es un espacio topológico y $A$ es un subconjunto cualquiera de $X$, podemos convertir $A$ en un espacio topológico definiendo la topología $\mathcal{S}$ en $A$, que consiste en todos los subconjuntos de $A$ que pueden expresarse como intersecciones de elementos de $\mathcal{T}$ con $A$, es decir, $\mathcal{S} = \{ U \mid U = A \cap O, \, O \in \mathcal{T} \}$. $\mathcal{S}$ se llama la '\textbf{topología inducida}' (o '\textbf{topología relativa}').
\end{definition}
En estos espacios topológicos también podemos definir un producto cartesiano, pues al trabajar con conjuntos está bien definido. De hecho, si $(X_1,\mathcal{T}_1)$ y $(X_2,\mathcal{T}_2)$ son espacios topológicos, entonces podemos introducir el producto cartesiano, \[X_1\times X_2=\curlybraces{(x_1,x_2)\mid x_1\in X_1,x_2\in X_2}\] dentro de un espacio topológico $(X_1\times X_2,\mathcal{T})$, definiendo $\mathcal{T}$ para que esté compuesto por todos los subconjuntos de $X_1\times X_2$, que pueden ser expresados como uniones de la forma $O_1\times O_2$ con $O_1\in\mathcal{T}_1$ y $O_2\in\mathcal{T}_2$. $\mathcal{T}$ se denomina \textbf{\textit{producto topológico}}, y usando esta definición de topología en $\mathbb{R}$, por construcción de topologías producto, podemos definir una topología en $\mathbb{R}^n$ La topología que obtenemos es la misma que se obtendría directamente definiendo $\mathcal{T}$ para que esté formado por todos los subconjuntos de $\mathbb{R}^n$, que pueden ser expresados por uniones de bolas abiertas.\\ \\
También podemos definir la continuidad de las funciones de los conjuntos de los espacios topológicos,
\begin{definition}
    Sean \( (X, \mathcal{T}) \) un espacio topológico con topología \( \mathcal{T} \), y \( (Y, \mathcal{S}) \) un espacio topológico con topología \( \mathcal{S} \). Decimos que una función \( f : X \to Y \) es continua si para todo conjunto abierto \( O \in \mathcal{S} \) (es decir, cualquier conjunto abierto en \( Y \)), la imagen inversa de \( O \) bajo \( f \), denotada como 
\[
f^{-1}[O] = \{ x \in X \mid f(x) \in O \},
\]
es un conjunto abierto en \( X \) (es decir, \( f^{-1}[O] \in \mathcal{T} \)).
\end{definition}
Para funciones de $\mathbb{R}$ en $\mathbb{R}$, es fácil verificarlo usando la definición de topología sobre $\mathbb{R}$, esta definición de continuidad es equivalente a la definición usual $\epsilon-\delta$.
\begin{definition}
    Si $f$ es continua, inyectiva, sobreyectiva y su inversa es continua, entonces $f$ se denomina \textbf{\textit{homeomorfismo}}, y $(X,\mathcal{T})$ y $(Y,\mathcal{S})$ se dice que son homemorfos. Los espacios topológicos homeomorfos tienen las mismas propiedades que los espacios topológicos.
\end{definition}
Antes hemos usado el concepto de 'conjunto abierto', pero también podemos definir los 'conjuntos cerrados', de forma que si $(X,\mathcal{T})$ es un espacio topológico, un subconjunto $C$ de $X$ se dice que es \textit{cerrado} si su complemento $X-C\equiv\curlybraces{x\in X\mid x\notin C}$ es abierto. Así, por ejemplo, un intervalo cerrado $\brackets{a,b}$ de $\mathbb{R}$ (con la topología estándar sobre $\mathbb{R}$) es un conjunto cerrado. A partir de los axiomas de los espacios topológicos, es inmediato ver que la intersección de cualquier colección arbitraria de conjuntos cerrados es cerrada y que la unión de un número finito de conjuntos cerrados es también cerrada. Cabe resaltar que un conjunto puede ser ni abierto y ni cerrado, por ejemplo, el intervalo medio-abierto $[a,b)$ en $\mathbb{R}$; o puede ser abierto y cerrado al mismo tiempo, como son todos los subconjuntos de la topología discreta. De hecho, la posibilidad de tener subconjuntos abiertos y cerrados a la vez da origen a la definición de \textbf{conectividad},
\begin{definition}
    Un espacio topológico $(X,\mathcal{T})$ se dice que es \textit{conexo} (o conectado) si el único subconjunto que es abierto y cerrado al mismo tiempo es el conjunto completo $X$ y el conjunto vacío $\emptyset$.
\end{definition}
Tenemos que $\mathbb{R}^n$, con la topología estándar definida, es conexo.\\ \\
En topología, uno de los conceptos fundamentales asociados a un subconjunto de un espacio es el de su adhesión. Este concepto permite formalizar la idea de los puntos donde el conjunto 'se acumula' dentro del espacio, incluyendo tanto los puntos que pertenecen al conjunto como aquellos que se encuentran arbitrariamente cerca de él. Formalmente, podemos definir la adhesión de la siguiente manera,
\begin{definition}
    Sea $(X,\mathcal{T})$ es un espacio topológico y $A$ es un subconjunto arbitrario de $X$, la \textit{adhesión} (o \textit{cierre}), $\overline{A}$, de $A$ se define como la intersección de todos los conjuntos cerrados que contienen a $A$.
\end{definition}
Claramente, $\overline{A}$ es cerrado, contiene a $A$, y es igual a $A$ si y solo si $A$ es cerrado.
\begin{definition}
    Sea $(X,\mathcal{T})$ es un espacio topológico y $A$ es un subconjunto arbitrario de $X$, el \textit{interior} de $A$ se define como la unión todos los conjuntos abiertos contenidos dentro de $A$.
\end{definition}
Claramente, el interior de $A$ es abierto, está contenido en $A$, y es igual a $A$ si y solo si $A$ es abierto. 
\begin{definition}
    $(X,\mathcal{T})$ es un espacio topológico y $A$ es un subconjunto arbitrario de $X$, la \textit{frontera} de $A$, denotada como $\mathring{A}$, se define como todos los puntos que se encuentran en $\overline{A}$, pero no están en el interior de $A$.
\end{definition}

\begin{definition}
    Sea $(X,\mathcal{T})$ un espacio topológico, un \textit{entorno} de $x\in X$ es cualquier $A\subset X$ tal que $x$ pertenece al interior de $A$. 
\end{definition}
En particular, cualquier conjunto abierto conteniendo $x$ es un entorno de $x$.
\begin{definition}
    Una \textit{base de entornos} en $x$ es una colección de entornos de $x$ tal que todo entorno de \( x \) contiene a algún elemento de esta colección.
\end{definition}
En particular, la colección de todos los conjuntos abiertos conteniendo $x$ es una base de entornos sobre $x$, aunque generalmente hay muchas otras posibilidades para bases de entornos. 
\begin{definition}
Una \textit{base de entornos} de $X$ es una especificación de una base de entornos para cada $x\in X$
\end{definition}
Las topologías suelen definirse especificando una base de entornos. El procedimiento es el siguiente:
\begin{enumerate}
    \item Un entorno de $x$ es cualquier conjunto que contiene a algún entorno base de $x$.

    \item Un conjunto es abierto si es un entorno de cada uno de sus puntos.
\end{enumerate}
Este proceso asegura que todos los conjuntos abiertos se generan a partir de la base de entornos, cumpliendo con las propiedades necesarias para definir una topología en el espacio. También es interesante ver que los conjuntos cerrados, los puntos de adherencia y de frontera pueden definirse directamente en términos de la base de entornos,
\begin{definition}
        Un conjunto \( G \) es \textit{cerrado} si y solo si, para cada punto \( x \) que no pertenece a \( G \), existe una base de entornos de \( x \) que no interseca a \( G \). La \textit{adherencia} de un conjunto \( A \) consiste en aquellos puntos \( x \) tales que cada base de entornos de \( x \) interseca a \( A \). La \textit{frontera} de \( A \) consiste en aquellos puntos \( x \) tales que cada base de entornos de \( x \) interseca tanto a \( A \) como a \( X - A \).
\end{definition}
\subsection{Espacios métricos}
Las bases de entornos, y por tanto las topologías, frecuentemente se definen en términos de una \textit{métrica} o \textit{función distancia}, que es la función $d:\hspace{2mm}X\times X\to\mathbb{R}$, que verifica:
\begin{enumerate}
    \item Para todo $x,y\in X$, $d(x,y)\geq 0$ (positividad).
    \item Si $d(x,y)=0$, entonces $x=y$ (no degeneración).
    \item Para todo $x,y\in X$, $d(x,y)=d(y,x)$ (simetría).
    \item Para todo $x,y,z\in X$, $d(x,y)+d(y,z)\geq d(x,z)$ (desigualdad triangular).
\end{enumerate}
No hay ningún cambio esencial si también añadimos $+\infty$ como un valor de $d$. Un conjunto con función métrica se denomina \textbf{\textit{espacio métrico}}.
\begin{definition}
    La \textit{bola abierta} con centro en $x$ y radio $r>0$ con respecto a $d$ se define como 
    \[
    B(x,r)=\curlybraces{y\mid d(x,y)<r}
    \]
\end{definition}
Entonces, puede demostrarse que cada bola abierta serviría como base de entornos para una topología $X$, la \textit{topología métrica} de $d$.
\\ \\
De forma más general: \textbf{\textit{Para cualquier espacio métrico, la colección de todos los subconjuntos que pueden expresarse como uniones de bolas abiertas define una topología}}.\\ \\
\subsection{Espacio Hausdorff}
Vamos a introducir los espacios Hausdorff, pues nos permiten definir las variedades y son muy útiles en Geometría Diferencial. 
\begin{definition}
    Un espacio topológico $(X,\mathcal{T})$ se dice que es \textit{Hausdorff} si para cada par de puntos distintos $p,q\in X$, $p\neq q$, existen conjuntos abiertos $O_p$, $O_q\in\mathcal{T}$ tal que $p\in O_p$, $q\in O_q$, y $O_p\cap O_q=\emptyset$.
\end{definition}
Es fácil comprobar que $\mathbb{R}^n$, con la topología estándar, es Hausdorff. También tenemos que una topología métrica siempre es Hausdorff.
\subsection{Compacidad}
Una de las nociones más importantes en topología es es la de la \textit{compacidad}, que se define como,
\begin{definition}
    Sea $(X,\mathcal{T})$ un espacio topológico y $A$ un subconjunto de $X$, una colección $\curlybraces{O_{\alpha}}$ de conjuntos abiertos se denomina \textit{recubrimiento abierto} de $A$ si la unión de estos conjuntos contiene a $A$, i.e. $A\subseteq\bigcup\limits_{\alpha}O_{\alpha}$. Una subcolección de estos conjuntos $\curlybraces{O_{\alpha}}$ que también recubren $A$ es referida como un \textit{sub-recubrimiento}. El conjunto $A$ se denomina \textit{compacto} si cada recubrimiento abierto de $A$ tiene un sub-recubrimiento finito (i.e., un sub-recubrimiento que consiste solo en un número finito de conjuntos).
\end{definition}
Así, por ejemplo, en cualquier espacio topológico, un conjunto formado por un solo punto, es compacto. Por otro lado, el intervalo abierto $(0,1)$ en $\mathbb{R}$ (con la topología estándar) no es compacto ya que los conjuntos $O_n=(1/n,1)$ para $n=2,3,\dots$, ceden un recubrimiento abierto de $(0,1)$ el cuál admite sub-recubrimientos no finitos.\\ \\
Los siguientes teoremas describen las implicaciones de la compacidad y muestran la utilidad de esta noción. Las demostraciones pueden encontrarse en cualquier texto de topología (e.g., Hocking and Young 1961; Kelley 1955).\\ \\
Quizás, el teorema más importante relativo a subconjuntos compactos de $\mathbb{R}$ es el Teorema de Heine-Borel,
\begin{theorem}[\textbf{Heine-Borel}]
    Un intervalo cerrado $[a,b]$ de números reales es compacto (con la topología estándar sobre $\mathbb{R}$).
\end{theorem}
La relación general entre conjuntos compactos y cerrados se describe con los siguientes dos teoremas, las demostraciones son directas,
\begin{theorem}
    Sea $(X,\mathcal{T})$ un espacio topológico de Hausdorff y sea $A\subset X$ compacto. Entonces $A$ es cerrado.
\end{theorem}
\begin{theorem}
    Sea $(X,\mathcal{T})$ compacto y $A\subset X$ cerrado. Entonces $A$ es compacto.
\end{theorem}
Combinando los tres teoremas anteriores, llegamos al siguiente enunciado importante sobre la compacidad de subconjuntos de $\mathbb{R}$,
\begin{theorem}
    Un subconjuntos $A$ de los números reales es compacto si y solo si es cerrado y acotado.
\end{theorem}
Se demuestra fácilmente que la propiedad de compacidad se conserva en mapas continuos. Tenemos,
\begin{theorem}
    Una función continua de un espacio topológico compacto en $\mathbb{R}$ es acotada y alcanza sus valores máximo y mínimo.
\end{theorem}
El siguiente teorema proporciona una extensión inmediata de los resultados de compacidad de $\mathbb{R}$ para $\mathbb{R}^n$.
\begin{theorem}[\textbf{Teorema de Tychonoff}]
    Sea $(X_1,\mathcal{T}_1)$ y $(X_2,\mathcal{T}_2)$ espacios topológicos compactos. Entonces, el producto cartesiano $X_1\times X_2$ es compacto en el producto topológico.
\end{theorem}
\begin{theorem}
    El teorema anterior puede generalizarse para aplicar el producto de infinitos productos topológicos, pero el axioma de elección es necesario para esta generalización.
\end{theorem}
Un corolario de este teorema y el anterior es
\begin{corollary}
    Un subconjunto, $A$, de $\mathbb{R}^n$ es compacto si y solo si es cerrado y acotado.
\end{corollary}
Así, por ejemplo, la esfera $n$-dimensional $S^n$ (definida como el conjunto de puntos en $\mathbb{R}^{n+1}$ satisfaciendo $x_1^2+\dots+x_n{n+1}^2=1$) en la topología inducida es compacta, así que es fácil ver que es un conjunto cerrado y acotado de $\mathbb{R}^{n+1}$.
\subsection{Convergencia de sucesiones}
Otra noción que necesitaremos es la de convergencia de sucesiones. 
\begin{definition}
Una sucesión $\curlybraces{x_n}$ de puntos en un espacio topológico $(X,\mathcal{T})$ se dice que \textit{converge} a un punto $x$ si en cualquier entorno abierto $O$ de $x$ (i.e., un conjunto abierto $O$ que contiene $x$), hay un $N$ tal que $x_n\in O$, para todo $n>N$.
\end{definition}
El punto $x$ se dice que es el \textit{límite} de la sucesión. Es fácil comprobar que para $\mathbb{R}$ (con la topología estándar) esto lleva a la definición usual de convergencia.
\begin{definition}
    Un punto $y\in X$ se dice que es un \textit{punto de acumulación} (o \textit{punto límite}) de $\curlybraces{x_n}$ si cada entorno abierto de $y$ contiene infinitos números de la sucesión.
\end{definition}
Sin embargo, en un espacio topológico general, si $y$ es un punto de acumulación de $\curlybraces{x_n}$, podría no ser posible encontrar una sucesión $\curlybraces{y_n}$ de puntos de la sucesión $\curlybraces{x_n}$ tal que $\curlybraces{y_n}$ converge hacia $y$. No obstante, el sentido de la convergencia de sucesiones hacia $y$ siempre será posible si $(X,\mathcal{T})$ es \textit{primero numerable}, esto es, si para cada $p\in X$ hay una colección numerable $\curlybraces{O_n}$ de conjuntos abiertos tal que cada entorno abierto, $O$, de $p$ contiene al menos un miembro de esta colección. Para $\mathbb{R}^n$, las bolas abiertas con radio racional centradas en puntos con coordenadas racionales, componen una colección numerable de conjuntos abiertos.\\ \\
Una relación importante entre compacidad y convergencia de sucesiones está expresada en el Teorema de Bolzano-Weiestrass,
\begin{theorem}[\textbf{Teorema de Bolzano-Weiestrass}]
    Sea $(X,\mathcal{T})$ un espacio topológico y sea $A\subset X$. Si $A$ es compacto, entonces cada sucesión $\curlybraces{x_n}$ de puntos de $A$ tiene un punto de acumulación en $A$. Inversamente, si $(X,\mathbb{T})$ es segundo numerable y cada sucesión en $A$ tiene un punto de acumulación en $A$, entonces $A$ es compacto. Así, en particular, si $(X,\mathcal{T})$ es segundo numerable, $A$ es compacto si y solo si cada sucesión en $A$ tiene una convergencia de sucesiones cuyo límite está en $A$.
\end{theorem}
\subsection{Para-compacidad}
Finalmente, definimos la noción de \textit{para-compacidad}, una propiedad que las variedades deben satisfacer para evitar que sean "demasiado grandes".
\begin{definition}
    -Sea $(X,\mathcal{T})$ un espacio topológico y sea $\curlybraces{O_{\alpha}}$ un recubrimiento abierto de $X$. Un recubrimiento abierto $\curlybraces{V_{\beta}}$ se dice que es un \textit{refinamiento} de $\curlybraces{O_{\alpha}}$ si para cada $V_{\beta}$ existe un $O_{\alpha}$ tal que $V_{\beta}\subset O_{\alpha}$.\\
    -El recubrimiento $\curlybraces{V_{\beta}}$ se dice que es \textit{localmente finito} si cada $x\in X$ tiene un entorno abierto $W$ tal que solo un número finito de $V_{\beta}$ satisfacen que $W\cap V_{\beta}\neq\emptyset$.\\
    -El espacio topológico $(X,\mathcal{T})$ se dice que es \textit{para-compacto} si cada recubrimiento abierto $\curlybraces{O_{\alpha}}$ de $X$ tiene un recubrimiento localmente finito $\curlybraces{V_{\beta}}$.
\end{definition}
\subsection{Variedades}
No es difícil ver que (verlo en e.g., Hocking and Young 1961) que cualquier espacio topológico de Hausdorff que sea localmente compacto (i.e., tal que cada punto tiene un entorno abierto con adherencia compacta) y que pueda ser expresado como una unión numerable de subconjuntos, es para-compacto. Así, $\mathbb{R}^n$, $S^m$ y sus productos verifican fácilmente ser para-compactos. En efecto, no es fácil construir ejemplos de espacios topológicos que satisfagan todos los requisitos de una variedad pero que no sean para-compactos; la 'recta larga' (ver Hocking and Young 1961) es quizás el ejemplo más simple, aunque para definirla se requiere el axioma de elección.

\chapter{Grupos de Lie}
\label{ApendiceB}
\lhead{Ap\'endice B. \emph{Grupos de Lie}}

\section{Preliminares}
Antes de profundizar en los grupos de Lie, veamos las definiciones necesarias para caracterizar los grupos de Lie. 
% Es aconsejable ver el apéndice anterior para entender bien las definiciones de topología.
\begin{definition}
    Sea $X$ un conjunto, se llama operación interna:
    \[\begin{matrix}
         *: & X\times X & \longrightarrow & X \\
            & (a,b)     & \mapsto     & a*b
    \end{matrix}
   \]
   Si no usamos el mismo conjunto, la operación no es interna.
\end{definition}
\begin{definition}
    Se dice que un conjunto $G$, dotado de una operación interna "$*$", es un grupo si $(G,*)$ verifica:
    \begin{enumerate}[label=(\roman*)]
        \item \textit{Propiedad asociativa}: $\forall x,y,z\in G$; $(x*y)*z=x*y*z=x*(y*z)$
        \item \textit{Existencia de elemento neutro}: $\exists e\in X$, tal que $\forall x\in G$; $x*e=e*x=x$
        \item \textit{Existencia de elemento simétrico}: $\forall x\in G$, $\exists x^{-1}\in G$ tal que $x*x^{-1}=x^{-1}*x=e$
    \end{enumerate}
    Si se verifica la propiedad \textit{conmutativa}, es decir, $\forall x,y\in G$; $x*y=y*x$, se dice que el grupo es \textbf{abeliano}.
\end{definition}
\begin{definition}
    Un \textbf{grupo continuo} $G$ es un conjunto que es grupo en sentido algebraico y al mismo tiempo un espacio topológico tal que la aplicación de $G\times G\to G$ definida por $(g_1,g_2)\mapsto g_1g_2^{-1}$ es continua.
\end{definition}
Se dice que dos espacio topológicos son \textbf{homeomorfos} si existe una aplicación \textbf{biyectiva y bicontinua} entre ellos, y en este caso se consideran topológicamente equivalentes. Por tanto, dos grupos continuos serán \textbf{isomorfos} si los son como grupo en sentido algebraico y además son homeomorfos como espacio topológico.
\begin{definition}
    Un espacio topológico $X$ que sea localmente euclídeo es una \textbf{variedad topológica}. Esto quiere decir que admite un atlas de coordenadas locales. Cada carta local del atlas es un abierto de $X$ homeomorfo a un abierto $\mathbb{R}^n$, siendo $n$ la dimensión de la variedad topológica.
\end{definition}
\section{Grupos de Lie}
Con estas definiciones preliminares ya podemos definir lo que es un grupo de Lie.
\begin{definition}
    Un grupo continuo localmente euclídeo es un \textbf{grupo de Lie}. Además, un grupo de Lie es un grupo cuyos elementos $g$ dependen de un modo continuo y diferenciable de un conjunto de parámetros reales, $\theta^a$, $a=1,\dots,N$.
\end{definition}
Escribimos un elemento general del grupo de Lie como $g(\theta)$ y, sin pérdida de generalidad, elegimos las coordenadas $\theta^a$ tal que el elemento neutro $e$ del grupo corresponda con $\theta^a=0$, es decir, $g(0)=e$.

\subsection{Representaciones}
    Una \textbf{representación} lineal $R$ de un grupo, es una operación que asigna a un elemento genérico y abstracto $g$ de un grupo, un operador lineal $D_R(g)$ definido en un espacio vectorial lineal $V$,
    \begin{equation}
        g\mapsto D_R(g):V\to V
    \end{equation}
    que satisfaga,
    \begin{enumerate}[label=(\roman*)]
        \item $D_R(e)=1$, donde 1 es el operador identidad.
        \item $D_R(g_1)D_R(g_2)=D_R(g_1g_2)$, luego, el mapeo (asignación) preserva la estructura de grupo.
    \end{enumerate}

El espacio donde actúa el operador $D_R$ se denomina la \textbf{base} de la representación $R$.\\ \\
Un ejemplo habitual de representaciones es la \textit{representación matricial}. En este caso, la base es un espacio vectorial de dimensión finita $n$, y un elemento abstracto $g$ del grupo se representa por una matriz $n\times n$, $(D_R(g))^i_j\equiv M_j^i$, con $i,j=1,\dots,n$.\\ \\
La \textbf{dimensión} de la representación se define como la dimensión $n$ del espacio base. Escribiendo un elemento genérico del espacio base $(\phi^1,\dots,\phi^n)$, un elemento $g$ del grupo induce una transformación del espacio vectorial, tal que
\begin{equation}
    \phi^i\mapsto M_j^i\phi^j
    \label{eqB.2}
\end{equation}
con $M_j^i\equiv(D_R(g))^i_j$. Esta ecuación nos permite dotar de un sentido físico al elemento de un grupo: antes de introducir el concepto de representaciones, el elemento $g$ de un grupo es solamente un objeto abstracto matemático, definido por sus reglas de composición con los otros elementos del grupo. Tomando una representación específica en cambio, nos permite interpretar los elementos $g$ como una transformación en un cierto espacio. Por ejemplo, tomando el grupo $SO(3)$ y como espacio base los vectores espaciales $\vec{v}$, un elemento $g\in SO(3)$ puede ser interpretado físicamente como una rotación en el espacio tridimensional.
\subsection{Tipos de representaciones}
Una representación $R$ se llama \textit{reducible} si posee un subespacio invariante, es decir, si la acción de cualquier operador lineal $D_R(g)$ sobre los vectores del subespacio proporciona otro vector del subespacio. Por el contrario, una representación con ningún subespacio invariante se denomina \textit{irreducible}.\\ \\
Una representación es \textit{completamente reducible} si, para todo $g$, las matrices $D_R(g)$ pueden escribirse, (con una elección de base adecuada), como matrices por bloques diagonales. En otras palabras, en una representación completamente reducible, la base de vectores $\phi^i$ pueden elegirse de modo que se dividan en subconjuntos que no se mezclan entre sí bajo la ecuación \ref{eqB.2}. Esto significa que una representación completamente reducible puede escribirse, con una elección adecuada de base, como la suma directa de representaciones irreducibles.\\ \\
Dos representaciones $R$, $R'$ se denominan \textit{equivalentes} si existe una matriz $S$, independiente de $g$, tal que para todo $g$ tengamos $D_R(g)=S^{-1}D_{R'}(g)S$. Comparando con la ecuación \ref{eqB.2}, vemos que las representaciones equivalentes corresponden al \textbf{cambio de base} en el espacio vectorial formado por los $\phi^i$.
\subsection{Álgebra de Lie}
Cuando cambiamos la representación, en general la forma explícita e incluso la dimensión de las matrices $D_R(g)$ cambiará. Sin embargo, existe una propiedad importante que dice que los grupos de Lie son \textbf{independientes} de la representación. Esto es el \textit{álgebra de Lie} que ahora introduciremos.\\ \\
Por la suposición de suavidad, para $\theta^a$ infinitesimal, es decir, en el entorno del elemento neutro, tenemos
\begin{equation}
    D_R(\theta)\approx1+i\theta_aT^a_R
    \label{eqB.3}
\end{equation}
con
\begin{equation}
    T_R^a\equiv-i\left.\frac{\partial D_R}{\partial\theta_a}\right|_{\theta=0}
    \label{eqB.4}
\end{equation}
Las $T_R^a$ se denominan \textit{generadores} del grupo en la representación $R$. Puede demostrarse que, con una elección adecuada de parametrización lejos de la identidad, los elementos generales $g(\theta)$ del grupo pueden siempre ser representados con
\begin{equation}
    D_R(g(\theta))=e^{i\theta_aT_R^a}
    \label{eqB.5}
\end{equation}
cuya forma infinitesimal reproduce la ecuación \ref{eqB.3}. El factor $i$ en la definición \ref{eqB.4} se toma tal que, si los generadores de la representación $R$ son hermíticos, entonces las matrices $D_R(g)$ son unitarias. En este caso $R$ es una \textit{representación unitaria}.\\ \\
Dadas dos matrices $D_R(g_1)=e^{i\alpha_aT_R^a}$ y $D_R(g_2)=e^{i\beta_aT_R^a}$, su producto es igual a $D(g_1g_2)$ y por lo tanto deberá ser de la forma $e^{i\delta_aT_R^a}$ para algún $\delta_a(\alpha,\beta)$, es decir,
\begin{equation}   D_R(g_1)D_R(g_2)=e^{i\alpha_aT_R^a}e^{i\beta_aT_R^a}=e^{i\delta_aT_R^a} 
\label{eqB.6}
\end{equation}
Observamos que $T_R^a$ es una matriz. Si $A,B$ son matrices, en general $e^Ae^B\neq e^{A+B}$, entonces, en general $\delta_a\neq\alpha_a+\beta_a$. Tomando el logaritmo y expandiendo a segundo orden en $\alpha$ y $\beta$ tenemos,
\begin{equation}
    \begin{array}{rcl}
        i\delta_aT_R^a & = & \ln\curlybraces{\brackets{1+i\alpha_aT_R^a+\frac{1}{2}\left(i\alpha_aT_R^a\right)^2}\brackets{1+i\beta_aT_R^a+\frac{1}{2}\left(i\beta_aT_R^a\right)^2}} \\
         & = & \ln\curlybraces{1+i\left(\alpha_a+\beta_a\right)T_R^a-\frac{1}{2}\left(\alpha_aT_R^a\right)^2-\frac{1}{2}\left(\beta_aT_R^a\right)^2-\alpha_a\beta_bR_T^aT_R^b}
         \label{eqB.7}
    \end{array}
\end{equation}
Expandiendo el logaritmo, $\ln(1+x)\approx x-x^2/2$, y teniendo en cuenta que $T_R^a$ no conmuta, tenemos
\begin{equation}
    \alpha_a\beta_b\brackets{T_R^a,T_R^b}=i\gamma_c(\alpha,\beta)T_R^c
    \label{eqB.8}
\end{equation}
con $\gamma_c(\alpha,\beta)=-2(\delta_x(\alpha,\beta)-\alpha_c-\beta_c)$. Como esto debe ser cierto para todos $\alpha$ y $\beta$, entonces $\gamma_c$ debe ser lineal en $\alpha_a$ y en $\beta_a$, tal que la relación entre $\gamma$ y $\alpha,\beta$ debe ser de la forma general $\gamma_c=\alpha_a\beta_bf^{ab}_c$ para algunas constantes $f^{ab}_c$. Por lo tanto,
\begin{equation}
    \brackets{T^a,T^b}=if^{ab}_cT^c
    \label{eqB.9}
\end{equation}
Esto se denomina el \textit{álgebra de Lie} del grupo en consideración.
\begin{note}
    Deberemos notar dos puntos importantes: 
    \begin{itemize}
        \item \textbf{Si la forma explícita de los generadores $T^a$ dependen de la representación empleada, las \textit{constantes de estructuras} $f^{ab}_c$ son independientes de la representación.} 
        \begin{proof}
        Si $f^{ab}_c$ dependiera de la representación, $\gamma^a$ y, por tanto, $\delta^a$ dependería también de $R$, entonces debería ser de la forma $\delta_R^a(\alpha,\beta)$. Entonces, de la ecuación \ref{eqB.6} concluiríamos que el producto de los elementos $g_1$ y $g_2$ del grupo proporciona un resultado que depende de la representación. Esto es imposible, ya que el resultado de la multiplicación de dos elementos abstractos del grupo $g_1g_2$ es una propiedad del grupo definida a nivel abstracto sin ninguna referencia a las representaciones. Por lo tanto, concluimos que las constantes de estructura $f_c^{ab}$ son independientes de la representación.\footnote{En realidad, los generadores de un grupo de Lie pueden definirse incluso sin hacer referencia a una representación específica. Se hace uso del hecho de que un grupo de Lie es también una variedad, parametrizada por las coordenadas $\theta^a$, y se definen los generadores como una base del espacio tangente en el origen. Luego se demuestra que su conmutador (definido como un corchete de Lie) es nuevamente un vector tangente y, por lo tanto, debe ser una combinación lineal de los vectores base. En este enfoque, nunca se menciona una representación específica, por lo que se vuelve evidente que las constantes de estructura son independientes de la representación.}
        \end{proof}
        \item \textbf{La ecuación \ref{eqB.9} se ha derivado exigiendo la consistencia de la ecuación \ref{eqB.6} hasta segundo orden; sin embargo, una vez que esto se satisface, se puede demostrar que no se requiere ninguna condición adicional a partir de la expansión en órdenes superiores.}
    \end{itemize}
\end{note}
\begin{remark}
    Las constantes de estructura definen el álgebra de Lie, y el problema de encontrar todas las representaciones matriciales de un álgebra de Lie equivale a el problema algebraico de encontrar todas las posibles soluciones matriciales $T_R^a$ de la ecuación \ref{eqB.9}
\end{remark}
Para los \textbf{grupos abelianos de Lie} las constantes de estructura desaparecen, ya que en este caso en la ecuación \ref{eqB.9} tenemos $\delta_a=\alpha_a+\beta_a$. La teoría de representaciones en álgebras de Lie abelianas es muy simple: cualquier álgebra de Lie abeliana $d-$dimensional es isomorfa a la suma directa de $d-$álgebras de Lie unidimensionales. En otras palabras, todas las representaciones irreducibles de grupos abelianos son unidimensionales. La parte no trivial de la teoría de representaciones de álgebras de Lie está relacionada con la estructura no abeliana.\\ \\
En el estudio de las representaciones, un papel importante lo juegan los \textit{operadores de Casimir}. Estos son operadores construidos a partir de los $T^a$ que conmutan con todos los $T^a$. En cada representación irreducible, los operadores de Casimir son proporcionales a la matriz identidad, y la constante de proporcionalidad caracteriza la representación. Por ejemplo, el álgebra del momento angular está dada por 
\begin{equation}
    \brackets{J^i,J^j}=i\epsilon^{ijk}J^k
\end{equation}
y el operador de Casimir es $J^2$. En una representación irreducible, $J^2$ es igual a $j(j+1)$ multiplicado por la matriz identidad, donde $j=0,\frac{1}{2},1,\dots$.\\ \\
Un grupo de Lie que, considerado como una variedad, es una \textbf{variedad compacta}, se denomina \textbf{grupo compacto}. Las rotaciones espaciales son un ejemplo de un grupo de Lie compacto, mientras que veremos que el grupo de Lorentz es \textbf{no compacto}.\\ \\
Un teorema establece que los grupos no compactos no tienen representaciones unitarias de dimensión finita, excepto para aquellas representaciones en las que los generadores no compactos se representan trivialmente, es decir, como cero.\\ \\
La relevancia física de este teorema se debe al hecho de que, en una representación unitaria, los generadores son operadores \textbf{hermíticos} y, de acuerdo con las reglas de la mecánica cuántica, solo los operadores hermíticos pueden identificarse con \textbf{observables físicos}.



% \chapter{Análisis Funcional}
% \label{ApendiceC}
% \lhead{Ap\'endice C. \emph{Análisis funcional}}



\end{document}
